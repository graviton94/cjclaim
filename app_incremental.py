"""
Streamlit í†µí•© í’ˆì§ˆ í´ë ˆì„ ê´€ë¦¬ ì‹œìŠ¤í…œ
EWS ì¡°ê¸°ê²½ë³´ | ì›”ë³„ ë°ì´í„° ì—…ë¡œë“œ | Lag í•„í„°ë§ | ì˜ˆì¸¡ ë¹„êµ | ì¬í•™ìŠµ
"""
import streamlit as st
import pandas as pd
from src.io_utils import _read_csv_any_encoding
import numpy as np
import subprocess
import json
import time
from pathlib import Path
from datetime import datetime
import sys
import plotly.express as px
import plotly.graph_objects as go

st.set_page_config(page_title="í’ˆì§ˆ í´ë ˆì„ ê´€ë¦¬ ì‹œìŠ¤í…œ", layout="wide", page_icon="ğŸ“Š")

st.title("ğŸ“Š í’ˆì§ˆ í´ë ˆì„ ì˜ˆì¸¡ ê´€ë¦¬ ì‹œìŠ¤í…œ")
st.markdown("**EWS ì¡°ê¸°ê²½ë³´ | ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ | ì›”ë³„ ë°ì´í„° ì—…ë¡œë“œ | ì¦ë¶„í•™ìŠµ | Reconcile ë³´ì •**")

# ì‚¬ì´ë“œë°” - ì„¤ì •
st.sidebar.header("âš™ï¸ ì‹œìŠ¤í…œ ì •ë³´")

# Lag í†µê³„ íŒŒì¼ í™•ì¸
lag_stats_path = Path("artifacts/metrics/lag_stats_from_raw.csv")
if lag_stats_path.exists():
    st.sidebar.success(f"âœ… Lag í†µê³„ íŒŒì¼ ì¡´ì¬")
    lag_stats = pd.read_csv(lag_stats_path)
    st.sidebar.caption(f"ì œí’ˆë²”ì£¼2: {len(lag_stats):,}ê°œ")
else:
    st.sidebar.error("âŒ Lag í†µê³„ íŒŒì¼ ì—†ìŒ")
    st.error("lag_stats_from_raw.csv íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤. tools/lag_analyzer.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    st.stop()

# ë©”ì¸ ì˜ì—­
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "âš ï¸ EWS ì¡°ê¸°ê²½ë³´", 
    "ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ", 
    "ğŸ“ˆ ì²˜ë¦¬ ê²°ê³¼", 
    "ğŸ”§ Reconcile ë³´ì •", 
    "ğŸ“Š í†µê³„"
])

# Tab 1: EWS ì¡°ê¸°ê²½ë³´
with tab1:
    st.header("âš ï¸ EWS ì¡°ê¸°ê²½ë³´ ì‹œìŠ¤í…œ")
    st.markdown("**6ê°œì›” ì˜ˆì¸¡ ê¸°ë°˜ ê³ ìœ„í—˜ í´ë ˆì„ ì‹œë¦¬ì¦ˆ ì‹ë³„**")
    
    # EWS ë°ì´í„° ë¡œë“œ
    import re
    def get_latest_file(folder, pattern, ext):
        files = list(Path(folder).glob(pattern))
        # Extract YYYY_MM from filename
        def extract_ym(f):
            m = re.search(r'(\d{4})[_.-]?(\d{2})', f.name)
            return int(m.group(1)) * 100 + int(m.group(2)) if m else 0
        files = [f for f in files if f.suffix == ext]
        files.sort(key=extract_ym, reverse=True)
        return files[0] if files else None

    @st.cache_data
    def load_ews_scores():
        latest_ews = get_latest_file("artifacts/metrics", "ews_scores_*.csv", ".csv")
        if not latest_ews or not latest_ews.exists():
            return None
        return pd.read_csv(latest_ews)

    @st.cache_data
    def load_forecast_data():
        latest_forecast = get_latest_file("artifacts/forecasts/2024", "forecast_2024_*.parquet", ".parquet")
        if not latest_forecast or not latest_forecast.exists():
            return None
        return pd.read_parquet(latest_forecast)

    df_ews = load_ews_scores()
    df_forecast_ews = load_forecast_data()
    
    if df_ews is None:
        st.error("âŒ EWS ìŠ¤ì½”ì–´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.info("ë¨¼ì € EWS ìŠ¤ì½”ì–´ë§ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        st.code("python -m src.ews_scoring_v2 --forecast artifacts/forecasts/2024/forecast_2024_01.parquet --output artifacts/metrics/ews_scores_2024_01.csv", language="bash")
    else:
        # ì˜ˆì¸¡ ìœ„í—˜ ì›” ê³„ì‚°
        @st.cache_data
        def calculate_risk_months(df_ews, df_forecast):
            """ê° ì‹œë¦¬ì¦ˆì˜ ìµœëŒ€ ìœ„í—˜ ì›” ê³„ì‚°"""
            if df_forecast is None:
                return {}
            
            risk_months = {}
            for _, row in df_ews.iterrows():
                series_id = row['series_id']
                series_forecast = df_forecast[df_forecast['series_id'] == series_id]
                
                if len(series_forecast) > 0:
                    # ì˜ˆì¸¡ê°’ì´ ê°€ì¥ ë†’ì€ ì›” ì°¾ê¸°
                    max_idx = series_forecast['y_pred'].idxmax()
                    max_row = series_forecast.loc[max_idx]
                    risk_month = f"{int(max_row['year'])}-{int(max_row['month']):02d}"
                    max_value = max_row['y_pred']
                    risk_months[series_id] = {'month': risk_month, 'value': max_value}
                else:
                    risk_months[series_id] = {'month': 'N/A', 'value': 0}
            
            return risk_months
        
        risk_months_dict = calculate_risk_months(df_ews, df_forecast_ews)
        
        # ìœ„í—˜ ì›” ì •ë³´ë¥¼ DataFrameì— ì¶”ê°€
        df_ews['ìœ„í—˜_ì›”'] = df_ews['series_id'].map(lambda x: risk_months_dict.get(x, {}).get('month', 'N/A'))
        df_ews['ìœ„í—˜_ì›”_ì˜ˆì¸¡ê°’'] = df_ews['series_id'].map(lambda x: risk_months_dict.get(x, {}).get('value', 0))
        
        # LOW_CONF ì„¤ëª… ì¶”ê°€
        st.info("ğŸ’¡ **ë ˆë²¨ ì„¤ëª…**: HIGH(ì‹ ë¢°ë„ ë†’ìŒ), MEDIUM(ì¤‘ê°„), LOW(ë‚®ì€ ìœ„í—˜), **LOW_CONF(ì¦ê°€ìœ¨ ë†’ì§€ë§Œ ì‹ ë¢°ë„ ë‚®ìŒ - ë°ì´í„° ë¶€ì¡±)**")
        # í•„í„° ì»¨íŠ¸ë¡¤
        col_filter1, col_filter2, col_filter3, col_filter4 = st.columns(4)
        
        with col_filter1:
            level_filter = st.multiselect(
                "EWS ë ˆë²¨",
                ["ì „ì²´"] + sorted(df_ews['level'].unique().tolist()),
                default=["ì „ì²´"]
            )
        
        with col_filter2:
            conf_min = st.slider("ìµœì†Œ ì‹ ë¢°ë„ (F2)", 0.0, 1.0, 0.0, 0.1)
        
        with col_filter3:
            ratio_min = st.slider("ìµœì†Œ ì¦ê°€ìœ¨ (F1)", 0.0, 5.0, 0.0, 0.1)
        
        with col_filter4:
            score_min = st.slider("ìµœì†Œ EWS ìŠ¤ì½”ì–´", 0.0, 1.0, 0.0, 0.1)
        
        # í•„í„° ì ìš©
        df_ews_filtered = df_ews.copy()
        
        if "ì „ì²´" not in level_filter:
            df_ews_filtered = df_ews_filtered[df_ews_filtered['level'].isin(level_filter)]
        
        df_ews_filtered = df_ews_filtered[
            (df_ews_filtered['f2_conf'] >= conf_min) &
            (df_ews_filtered['f1_ratio'] >= ratio_min) &
            (df_ews_filtered['ews_score'] >= score_min)
        ]
        
        # ë©”íŠ¸ë¦­ í‘œì‹œ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì´ ì‹œë¦¬ì¦ˆ", f"{len(df_ews):,}ê°œ")
        
        with col2:
            high_count = (df_ews['level'] == 'HIGH').sum()
            st.metric("HIGH ìœ„í—˜", f"{high_count:,}ê°œ", 
                      delta=f"{high_count/len(df_ews)*100:.1f}%")
        
        with col3:
            valid_count = df_ews['candidate'].sum()
            st.metric("ìœ íš¨ í›„ë³´", f"{valid_count:,}ê°œ",
                      delta=f"{valid_count/len(df_ews)*100:.1f}%")
        
        with col4:
            st.metric("í•„í„° ê²°ê³¼", f"{len(df_ews_filtered):,}ê°œ")
        
        st.markdown("---")
        
        # Top ìœ„í—˜ ì‹œë¦¬ì¦ˆ (ë‹¨ì¼ í™”ë©´)
        st.markdown("### ğŸ† ê³ ìœ„í—˜ ì‹œë¦¬ì¦ˆ (ë³€ë³„ë ¥ ê°œì„ )")
        
        # ë³€ë³„ë ¥ ê°œì„  ì˜µì…˜
        col_option1, col_option2 = st.columns(2)
        
        with col_option1:
            use_weighted_score = st.checkbox(
                "ê°€ì¤‘ ìŠ¤ì½”ì–´ ì‚¬ìš© (ì‹ ë¢°ë„Ã—ì¦ê°€ìœ¨ ë°˜ì˜)",
                value=True,
                help="EWS ìŠ¤ì½”ì–´ì— ì‹ ë¢°ë„ì™€ ì¦ê°€ìœ¨ì„ ê³±í•˜ì—¬ ë³€ë³„ë ¥ í–¥ìƒ"
            )
        
        with col_option2:
            exclude_low_conf = st.checkbox(
                "LOW_CONF ì œì™¸",
                value=True,
                help="ì‹ ë¢°ë„ê°€ ë‚®ì€ ì‹œë¦¬ì¦ˆ ì œì™¸"
            )
        
        # í•„í„° ì ìš©
        df_display = df_ews_filtered.copy()
        
        if exclude_low_conf:
            df_display = df_display[df_display['level'] != 'LOW_CONF']
        
        # ê°€ì¤‘ ìŠ¤ì½”ì–´ ê³„ì‚°
        if use_weighted_score:
            df_display['ë³€ë³„_ìŠ¤ì½”ì–´'] = (
                df_display['ews_score'] * 0.4 + 
                df_display['f1_ratio'] * 0.3 + 
                df_display['f2_conf'] * 0.3
            )
            # ë³€ë³„ ìŠ¤ì½”ì–´ë¡œ ì¬ì •ë ¬í•˜ê³  ìˆœìœ„ ì¬ê³„ì‚°
            df_display = df_display.sort_values('ë³€ë³„_ìŠ¤ì½”ì–´', ascending=False).reset_index(drop=True)
            df_display['rank'] = range(1, len(df_display) + 1)
            sort_default = 'ë³€ë³„_ìŠ¤ì½”ì–´'
        else:
            sort_default = 'ews_score'
        
        top_n = st.slider("í‘œì‹œí•  ì‹œë¦¬ì¦ˆ ìˆ˜", 10, 100, 20, 10, key="ews_top_n")
        
        sort_by = st.selectbox(
            "ì •ë ¬ ê¸°ì¤€",
            ["ë³€ë³„ ìŠ¤ì½”ì–´", "EWS ìŠ¤ì½”ì–´", "ì¦ê°€ìœ¨", "ì‹ ë¢°ë„", "ê³„ì ˆì„±", "ì§„í­", "ë³€ê³¡"],
            key="ews_sort_by"
        )
        
        sort_col_map = {
            "ë³€ë³„ ìŠ¤ì½”ì–´": "ë³€ë³„_ìŠ¤ì½”ì–´" if use_weighted_score else "ews_score",
            "EWS ìŠ¤ì½”ì–´": "ews_score",
            "ì¦ê°€ìœ¨": "f1_ratio",
            "ì‹ ë¢°ë„": "f2_conf",
            "ê³„ì ˆì„±": "f3_season",
            "ì§„í­": "f4_ampl",
            "ë³€ê³¡": "f5_inflect"
        }
        
        df_ews_top = df_display.nlargest(top_n, sort_col_map[sort_by])
        
        # ì»¬ëŸ¼ëª… í•œê¸€í™”
        display_columns = {
            'rank': 'ìˆœìœ„',
            'series_id': 'ì‹œë¦¬ì¦ˆ',
            'ews_score': 'EWSì ìˆ˜',
            'ë³€ë³„_ìŠ¤ì½”ì–´': 'ë³€ë³„ì ìˆ˜',
            'level': 'ë ˆë²¨',
            'f1_ratio': 'ì¦ê°€ìœ¨',
            'f2_conf': 'ì‹ ë¢°ë„',
            'f3_season': 'ê³„ì ˆì„±',
            'f4_ampl': 'ì§„í­',
            'f5_inflect': 'ë³€ê³¡',
            'ìœ„í—˜_ì›”': 'ìœ„í—˜ì›”',
            'ìœ„í—˜_ì›”_ì˜ˆì¸¡ê°’': 'ì˜ˆì¸¡ê°’'
        }
        
        # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ
        if use_weighted_score:
            show_cols = ['rank', 'series_id', 'ews_score', 'ë³€ë³„_ìŠ¤ì½”ì–´', 'level', 
                        'f1_ratio', 'f2_conf', 'f3_season', 'f4_ampl', 'f5_inflect',
                        'ìœ„í—˜_ì›”', 'ìœ„í—˜_ì›”_ì˜ˆì¸¡ê°’']
        else:
            show_cols = ['rank', 'series_id', 'ews_score', 'level', 
                        'f1_ratio', 'f2_conf', 'f3_season', 'f4_ampl', 'f5_inflect',
                        'ìœ„í—˜_ì›”', 'ìœ„í—˜_ì›”_ì˜ˆì¸¡ê°’']
        
        df_display_table = df_ews_top[show_cols].copy()
        df_display_table = df_display_table.rename(columns=display_columns)
        
        # ìŠ¤íƒ€ì¼ ì ìš©
        styled_df = df_display_table.style.background_gradient(
            subset=['EWSì ìˆ˜'] if not use_weighted_score else ['ë³€ë³„ì ìˆ˜'], 
            cmap='YlOrRd'
        ).format({
            'EWSì ìˆ˜': '{:.3f}',
            'ë³€ë³„ì ìˆ˜': '{:.3f}' if use_weighted_score else None,
            'ì¦ê°€ìœ¨': '{:.2f}x',
            'ì‹ ë¢°ë„': '{:.2f}',
            'ê³„ì ˆì„±': '{:.2f}',
            'ì§„í­': '{:.2f}',
            'ë³€ê³¡': '{:.2f}',
            'ì˜ˆì¸¡ê°’': '{:.1f}ê±´'
        })
        
        st.dataframe(styled_df, width='stretch', height=400)

        # ì‹œë¦¬ì¦ˆ ì„ íƒ ë° ìƒì„¸ ì •ë³´ + ì˜ˆì¸¡ ì¶”ì´ ê·¸ë˜í”„
        if len(df_ews_top) > 0:
            st.markdown("---")
            st.subheader("ğŸ“‹ ì‹œë¦¬ì¦ˆ ìƒì„¸ ì •ë³´ ë° ì˜ˆì¸¡ ì¶”ì´")
            
            selected_series_ews = st.selectbox(
                "ì‹œë¦¬ì¦ˆ ì„ íƒ (ì•„ë˜ ìƒì„¸ ì •ë³´ ë° ê·¸ë˜í”„ í™•ì¸)",
                df_ews_top['series_id'].tolist(),
                key="ews_detail_select"
            )
            
            if selected_series_ews:
                series_info = df_ews_top[df_ews_top['series_id'] == selected_series_ews].iloc[0]
                
                # ìƒì„¸ ì •ë³´ í‘œì‹œ
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown("**ê¸°ë³¸ ì •ë³´**")
                    st.write(f"- **ì‹œë¦¬ì¦ˆ**: {series_info['series_id']}")
                    st.write(f"- **EWS ë ˆë²¨**: {series_info['level']}")
                    st.write(f"- **EWS ìŠ¤ì½”ì–´**: {series_info['ews_score']:.3f}")
                    if use_weighted_score:
                        st.write(f"- **ë³€ë³„ ìŠ¤ì½”ì–´**: {series_info['ë³€ë³„_ìŠ¤ì½”ì–´']:.3f}")
                    st.write(f"- **ìˆœìœ„**: {int(series_info['rank'])}")
                
                with col2:
                    st.markdown("**5-Factor ì ìˆ˜**")
                    st.write(f"- **ì¦ê°€ìœ¨ (F1)**: {series_info['f1_ratio']:.2f}x")
                    st.write(f"- **ì‹ ë¢°ë„ (F2)**: {series_info['f2_conf']:.2f}")
                    st.write(f"- **ê³„ì ˆì„± (F3)**: {series_info['f3_season']:.2f}")
                    st.write(f"- **ì§„í­ (F4)**: {series_info['f4_ampl']:.2f}")
                    st.write(f"- **ë³€ê³¡ (F5)**: {series_info['f5_inflect']:.2f}")
                
                with col3:
                    st.markdown("**ì˜ˆì¸¡ ìœ„í—˜ ì •ë³´**")
                    st.write(f"- **ìœ„í—˜ ì›”**: {series_info['ìœ„í—˜_ì›”']}")
                    st.write(f"- **ì˜ˆìƒ í´ë ˆì„**: {series_info['ìœ„í—˜_ì›”_ì˜ˆì¸¡ê°’']:.1f}ê±´")
                    
                    # ìœ„í—˜ë„ í‘œì‹œ
                    if series_info['level'] == 'HIGH':
                        st.error("ğŸ”´ **ë†’ì€ ìœ„í—˜**")
                    elif series_info['level'] == 'MEDIUM':
                        st.warning("ğŸŸ¡ **ì¤‘ê°„ ìœ„í—˜**")
                    elif series_info['level'] == 'LOW_CONF':
                        st.info("ğŸ”µ **ë°ì´í„° ë¶€ì¡± (ì‹ ë¢°ë„ ë‚®ìŒ)**")
                    else:
                        st.success("ğŸŸ¢ **ë‚®ì€ ìœ„í—˜**")
                
                # ì›”ë³„ ì˜ˆì¸¡ ì¶”ì´ ê·¸ë˜í”„ (ë°”ë¡œ ì•„ë˜ í‘œì‹œ)
                st.markdown("---")
                st.markdown("### ğŸ“ˆ ì›”ë³„ ì˜ˆì¸¡ ì¶”ì´")
                
                if df_forecast_ews is not None:
                    # ì˜ˆì¸¡ ë°ì´í„°
                    series_forecast = df_forecast_ews[df_forecast_ews['series_id'] == selected_series_ews].copy()
                    
                    if len(series_forecast) > 0:
                        # month_label ìƒì„± (year-month í˜•ì‹)
                        series_forecast['month_label'] = series_forecast['year'].astype(str) + '-' + series_forecast['month'].astype(str).str.zfill(2)
                        series_forecast = series_forecast.sort_values(['year', 'month'])
                        
                        # ê³¼ê±° ë°ì´í„° ë¡œë“œ
                        @st.cache_data
                        def load_historical_for_series(series_id, forecast_start_year, forecast_start_month):
                            """ì‹œë¦¬ì¦ˆì˜ ê³¼ê±° 12ê°œì›” ë°ì´í„° ë¡œë“œ (ì˜ˆì¸¡ ì‹œì‘ ì „ 12ê°œì›”)"""
                            try:
                                # JSON íŒŒì¼ì—ì„œ ê³¼ê±° ë°ì´í„° ë¡œë“œ
                                json_dir = Path("data/features")
                                safe_filename = (series_id.replace('/', '_').replace('\\', '_').replace(':', '_')
                                                .replace('|', '_').replace('?', '_').replace('*', '_')
                                                .replace('<', '_').replace('>', '_').replace('"', '_'))
                                json_path = json_dir / f"{safe_filename}.json"
                                
                                if json_path.exists():
                                    with open(json_path, 'r', encoding='utf-8') as f:
                                        data = json.load(f)
                                    
                                    df_hist = pd.DataFrame(data.get('data', []))
                                    if len(df_hist) > 0:
                                        # ì˜ˆì¸¡ ì‹œì‘ ì „ 12ê°œì›” ê³„ì‚°
                                        from datetime import datetime
                                        from dateutil.relativedelta import relativedelta
                                        
                                        forecast_start = datetime(forecast_start_year, forecast_start_month, 1)
                                        hist_end = forecast_start - relativedelta(months=1)  # ì˜ˆì¸¡ ì§ì „ ì›”
                                        hist_start = hist_end - relativedelta(months=11)  # 12ê°œì›” ì „
                                        
                                        # í•´ë‹¹ ê¸°ê°„ì˜ ë°ì´í„°ë§Œ í•„í„°ë§
                                        df_hist = df_hist[
                                            ((df_hist['year'] > hist_start.year) | 
                                             ((df_hist['year'] == hist_start.year) & (df_hist['month'] >= hist_start.month))) &
                                            ((df_hist['year'] < hist_end.year) | 
                                             ((df_hist['year'] == hist_end.year) & (df_hist['month'] <= hist_end.month)))
                                        ].copy()
                                        
                                        if len(df_hist) > 0:
                                            df_hist['month_label'] = df_hist['year'].astype(str) + '-' + df_hist['month'].astype(str).str.zfill(2)
                                            return df_hist[['year', 'month', 'month_label', 'claim_count']].sort_values(['year', 'month'])
                            
                            except Exception as e:
                                st.warning(f"ê³¼ê±° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                            
                            return pd.DataFrame()
                        
                        # ì˜ˆì¸¡ ì‹œì‘ ì‹œì  ì¶”ì¶œ
                        forecast_start_year = int(series_forecast['year'].min())
                        forecast_start_month = int(series_forecast['month'].min())
                        
                        df_historical = load_historical_for_series(selected_series_ews, forecast_start_year, forecast_start_month)
                        
                        # ê³¼ê±° ë°ì´í„° ë¡œë“œ ìƒíƒœ í‘œì‹œ
                        if len(df_historical) > 0:
                            hist_start = df_historical['month_label'].iloc[0]
                            hist_end = df_historical['month_label'].iloc[-1]
                            st.info(f"ğŸ“Š ê³¼ê±° ë°ì´í„°: {hist_start} ~ {hist_end} ({len(df_historical)}ê°œì›”)")
                        else:
                            st.warning("âš ï¸ ê³¼ê±° 12ê°œì›” ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ˆì¸¡ ë°ì´í„°ë§Œ í‘œì‹œë©ë‹ˆë‹¤.")
                        
                        # ìŒìˆ˜ í´ë ˆì„ ì œê±°
                        if len(df_historical) > 0:
                            df_historical = df_historical[df_historical['claim_count'] >= 0].copy()
                        
                        series_forecast = series_forecast[
                            (series_forecast['y_pred'] >= 0) &
                            (series_forecast['y_pred_lower'] >= 0) &
                            (series_forecast['y_pred_upper'] >= 0)
                        ].copy()
                        
                        # ë°ì´í„° ìœ íš¨ì„± ì²´í¬
                        if len(series_forecast) == 0:
                            st.warning("âš ï¸ ëª¨ë“  ì˜ˆì¸¡ê°’ì´ ìŒìˆ˜ë¡œ í•„í„°ë§ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì‹œë¦¬ì¦ˆëŠ” ë°ì´í„° ì˜¤ë¥˜ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        else:
                            # ê·¸ë˜í”„
                            fig = go.Figure()
                            
                            # ê³¼ê±° ì‹¤ì œ ë°ì´í„° (ì˜ˆì¸¡ ì „ 12ê°œì›”)
                            if len(df_historical) > 0:
                                fig.add_trace(go.Scatter(
                                    x=df_historical['month_label'],
                                    y=df_historical['claim_count'],
                                    mode='lines+markers',
                                    name=f'ì‹¤ì œê°’ (ê³¼ê±° 12ê°œì›”)',
                                    line=dict(color='gray', width=2),
                                    marker=dict(size=8, symbol='circle')
                                ))
                            
                            # ì˜ˆì¸¡ê°’ (6ê°œì›”)
                            fig.add_trace(go.Scatter(
                                x=series_forecast['month_label'],
                                y=series_forecast['y_pred'],
                                mode='lines+markers',
                                name=f'ì˜ˆì¸¡ê°’ (6ê°œì›”)',
                                line=dict(color='blue', width=2, dash='dash'),
                                marker=dict(size=8, symbol='diamond')
                            ))
                            
                            # ì‹ ë¢°êµ¬ê°„
                            fig.add_trace(go.Scatter(
                                x=series_forecast['month_label'],
                                y=series_forecast['y_pred_upper'],
                                mode='lines',
                                line=dict(width=0),
                                showlegend=False,
                                hoverinfo='skip'
                            ))
                            
                            fig.add_trace(go.Scatter(
                                x=series_forecast['month_label'],
                                y=series_forecast['y_pred_lower'],
                                mode='lines',
                                line=dict(width=0),
                                fillcolor='rgba(0,100,255,0.2)',
                                fill='tonexty',
                                name='95% ì‹ ë¢°êµ¬ê°„'
                            ))
                            
                            # ì˜ˆì¸¡ ì‹œì‘ êµ¬ë¶„ì„ 
                            if len(df_historical) > 0 and len(series_forecast) > 0:
                                forecast_start = series_forecast['month_label'].iloc[0]
                                
                                fig.add_shape(
                                    type="line",
                                    x0=forecast_start,
                                    x1=forecast_start,
                                    y0=0,
                                    y1=1,
                                    yref="paper",
                                    line=dict(color="red", width=2, dash="dot")
                                )
                                
                                fig.add_annotation(
                                    x=forecast_start,
                                    y=1,
                                    yref="paper",
                                    text="ì˜ˆì¸¡ ì‹œì‘",
                                    showarrow=False,
                                    font=dict(size=10, color="red"),
                                    yshift=10
                                )
                            
                            fig.update_layout(
                                title=f'ì‹œê³„ì—´ ì¶”ì´: {selected_series_ews}<br><sub>ê³¼ê±° 12ê°œì›” + ì˜ˆì¸¡ 6ê°œì›”</sub>',
                                xaxis_title='ì›”',
                                yaxis_title='í´ë ˆì„ ìˆ˜',
                                height=450,
                                hovermode='x unified'
                            )
                            
                            st.plotly_chart(fig, width='stretch')
                            
                            # í†µê³„
                            col1, col2, col3, col4 = st.columns(4)
                            
                            with col1:
                                if len(df_historical) > 0:
                                    st.metric("ê³¼ê±° 12ê°œì›” í‰ê· ", f"{df_historical['claim_count'].mean():.2f}ê±´")
                                else:
                                    st.metric("ê³¼ê±° í‰ê· ", "N/A")
                            
                            with col2:
                                st.metric("ì˜ˆì¸¡ 6ê°œì›” í‰ê· ", f"{series_forecast['y_pred'].mean():.2f}ê±´")
                            
                            with col3:
                                max_pred = series_forecast['y_pred'].max()
                                max_month = series_forecast.loc[series_forecast['y_pred'].idxmax(), 'month_label']
                                st.metric("ìµœëŒ€ ì˜ˆì¸¡", f"{max_pred:.2f}ê±´", delta=max_month)
                            
                            with col4:
                                st.metric("6ê°œì›” í•©ê³„", f"{series_forecast['y_pred'].sum():.0f}ê±´")
                            
                            # ìƒì„¸ í…Œì´ë¸”
                            st.markdown("**ï¿½ ìƒì„¸ ì˜ˆì¸¡ ë°ì´í„°**")
                            detail_cols = st.columns([1, 1])
                            
                            with detail_cols[0]:
                                if len(df_historical) > 0:
                                    st.markdown("**ê³¼ê±° 12ê°œì›” ì‹¤ì œ**")
                                    st.dataframe(
                                        df_historical[['month_label', 'claim_count']].rename(columns={
                                            'month_label': 'ì›”',
                                            'claim_count': 'ì‹¤ì œê°’'
                                        }).style.format({'ì‹¤ì œê°’': lambda x: f"{int(x)}ê±´" if x is not None else "N/A"}),
                                        width='stretch',
                                        height=300
                                    )
                            
                            with detail_cols[1]:
                                st.markdown("**ì˜ˆì¸¡ 6ê°œì›”**")
                                st.dataframe(
                                    series_forecast[['month_label', 'y_pred', 'y_pred_lower', 'y_pred_upper']].rename(columns={
                                        'month_label': 'ì›”',
                                        'y_pred': 'ì˜ˆì¸¡ê°’',
                                        'y_pred_lower': 'í•˜í•œ',
                                        'y_pred_upper': 'ìƒí•œ'
                                    }).style.format({
                                        'ì˜ˆì¸¡ê°’': lambda x: f"{x:.2f}ê±´" if x is not None else "N/A",
                                        'í•˜í•œ': lambda x: f"{x:.2f}ê±´" if x is not None else "N/A",
                                        'ìƒí•œ': lambda x: f"{x:.2f}ê±´" if x is not None else "N/A"
                                    }),
                                    width='stretch',
                                    height=300
                                )
                else:
                    st.warning("ì„ íƒí•œ ì‹œë¦¬ì¦ˆì˜ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.error("ì˜ˆì¸¡ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# Tab 2: ë°ì´í„° ì—…ë¡œë“œ
with tab2:
    st.header("1ï¸âƒ£ ì›”ë³„ ë°ì´í„° ì—…ë¡œë“œ")
    
    # í•™ìŠµ ë°ì´í„° í˜„í™© í…Œì´ë¸”
    st.subheader("ğŸ“Š í•™ìŠµ ë°ì´í„° í˜„í™©")
    
    features_dir = Path("data/features")
    if features_dir.exists() and any(features_dir.glob("*.json")):
        with st.spinner("í•™ìŠµ ë°ì´í„° ë¶„ì„ ì¤‘..."):
            # ë…„/ì›”ë³„ ë°ì´í„° ìˆ˜ì§‘
            year_month_data = {}
            total_series = 0
            for json_file in features_dir.glob("*.json"):
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    records = data.get('data', [])
                    if not records:
                        continue
                    total_series += 1
                    for record in records:
                        year = record.get('year')
                        month = record.get('month')
                        if year and month:
                            key = (year, month)
                            if key not in year_month_data:
                                year_month_data[key] = 0
                            year_month_data[key] += 1
                except Exception as e:
                    continue
            if year_month_data:
                years = sorted(set(year for year, month in year_month_data.keys()))
                months = list(range(1, 13))
                table_data = []
                for month in months:
                    row = {'ì›”': f"{month}ì›”"}
                    for year in years:
                        count = year_month_data.get((year, month), 0)
                        threshold = total_series * 0.8
                        if count >= threshold:
                            status = "âœ…"
                        elif count >= threshold * 0.5:
                            status = "âš ï¸"
                        else:
                            status = "âŒ"
                        row[f"{year}ë…„"] = f"{status} {count}"
                    table_data.append(row)
                df_status = pd.DataFrame(table_data)
                st.dataframe(
                    df_status.style.format({
                        col: (lambda x: f"{int(x)}" if isinstance(x, (int, float)) and not isinstance(x, bool) else str(x))
                        for col in df_status.columns if col != 'ì›”'
                    }),
                    width='stretch',
                    hide_index=True
                )
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.caption(f"**ì´ ì‹œë¦¬ì¦ˆ**: {total_series:,}ê°œ")
                with col2:
                    st.caption("**âœ… ì¶©ë¶„**: â‰¥80% ì‹œë¦¬ì¦ˆ")
                with col3:
                    st.caption("**âš ï¸ ë³´í†µ**: 40-80% ì‹œë¦¬ì¦ˆ")
                with col4:
                    st.caption("**âŒ ë¶€ì¡±**: <40% ì‹œë¦¬ì¦ˆ")
            else:
                st.info("í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("Feature JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € Base í•™ìŠµì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    st.markdown("---")
    
    # ì—…ë¡œë“œí•  ë°ì´í„°ì˜ ë…„/ì›”ì€ CSVì—ì„œ ìë™ ê°ì§€
    st.subheader("2ï¸âƒ£ ì›”ë³„ ë°ì´í„° ì—…ë¡œë“œ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        uploaded_file = st.file_uploader(
            f"**CSV íŒŒì¼ ì—…ë¡œë“œ**",
            type=['csv'],
            help="ë°œìƒì¼ì ê¸°ì¤€ 1ê°œì›” ë°ì´í„° (í”ŒëœíŠ¸, ì œí’ˆë²”ì£¼2, ì¤‘ë¶„ë¥˜, ë°œìƒì¼ì, ì œì¡°ì¼ì, count ì»¬ëŸ¼ í•„ìˆ˜)"
        )
    
    with col2:
        st.markdown("**í•„ìˆ˜ ì»¬ëŸ¼**")
        st.code("""
í”ŒëœíŠ¸
ì œí’ˆë²”ì£¼2
ì¤‘ë¶„ë¥˜
ë°œìƒì¼ì
ì œì¡°ì¼ì
count
        """, language="text")
    
    if uploaded_file is not None:
        # ì„ì‹œ ì €ì¥
        temp_dir = Path("artifacts/temp")
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ë° ë…„/ì›” ìë™ ê°ì§€
        st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
        
        try:
            df_preview = pd.read_csv(uploaded_file, encoding='utf-8-sig', nrows=10)
            df_preview.columns = df_preview.columns.str.strip()
            
            # ì „ì²´ ë°ì´í„° ë¡œë“œ
            uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ì´ˆê¸°í™”
            df_full = pd.read_csv(uploaded_file, encoding='utf-8-sig')
            df_full.columns = df_full.columns.str.strip()
            
            # ë°œìƒì¼ìì—ì„œ ë…„/ì›” ìë™ ê°ì§€
            if 'ë°œìƒì¼ì' in df_full.columns:
                df_full['ë°œìƒì¼ì'] = pd.to_datetime(df_full['ë°œìƒì¼ì'])
                detected_year = int(df_full['ë°œìƒì¼ì'].dt.year.mode()[0])  # ìµœë¹ˆê°’
                detected_month = int(df_full['ë°œìƒì¼ì'].dt.month.mode()[0])  # ìµœë¹ˆê°’
                month_key = f"{detected_year}-{detected_month:02d}"
                
                st.info(f"ğŸ“… **ê°ì§€ëœ ëŒ€ìƒ ì›”:** {month_key}")
            else:
                st.error("'ë°œìƒì¼ì' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()
            
            # ì„ì‹œ íŒŒì¼ ì €ì¥
            temp_path = temp_dir / f"upload_{month_key.replace('-', '')}.csv"
            df_full.to_csv(temp_path, index=False, encoding='utf-8-sig')
            st.subheader("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            st.dataframe(df_preview, width='stretch')
            
            # ì „ì²´ ë°ì´í„° í†µê³„
            df_full = pd.read_csv(temp_path, encoding='utf-8-sig')
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                run_pipeline = st.button("ğŸš€ íŒŒì´í”„ë¼ì¸ ìë™ ì‹¤í–‰", help="ì—…ë¡œë“œ í›„ ë¼ê·¸ í•„í„°ë§, feature/parquet ìƒì„±, ì˜ˆì¸¡, EWS, ì¦ë¶„ ì¬í•™ìŠµê¹Œì§€ ìë™ ì‹¤í–‰")
            if run_pipeline:
                st.info(f"[ìë™í™”] {month_key} íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
                # 1. ë¼ê·¸ í•„í„°ë§/ì£¼ê°„ ì§‘ê³„/feature JSON ìƒì„±
                process_cmd = [sys.executable, "process_monthly_incremental.py", "--new-csv", str(temp_path), "--year", str(detected_year), "--month", str(detected_month), "--output-list", f"artifacts/temp/updated_series_{detected_year}{detected_month:02d}.txt"]
                result1 = subprocess.run(process_cmd, capture_output=True, text=True)
                st.code(result1.stdout)
                if result1.returncode != 0:
                    st.error(f"[ì˜¤ë¥˜] ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {result1.stderr}")
                    st.stop()
                # 2. feature parquet ìƒì„±
                feature_cmd = [sys.executable, "tools/generate_cycle_features_parquet.py"]
                result2 = subprocess.run(feature_cmd, capture_output=True, text=True)
                st.code(result2.stdout)
                if result2.returncode != 0:
                    st.error(f"[ì˜¤ë¥˜] feature/parquet ìƒì„± ì‹¤íŒ¨: {result2.stderr}")
                    st.stop()
                # 3. ì˜ˆì¸¡
                forecast_cmd = [sys.executable, "batch.py", "forecast", "--month-new", month_key]
                result3 = subprocess.run(forecast_cmd, capture_output=True, text=True)
                st.code(result3.stdout)
                if result3.returncode != 0:
                    st.error(f"[ì˜¤ë¥˜] ì˜ˆì¸¡ ì‹¤íŒ¨: {result3.stderr}")
                    st.stop()
                # 4. EWS ìŠ¤ì½”ì–´ë§
                forecast_parquet = f"artifacts/forecasts/{detected_year}/forecast_{detected_year}_{detected_month:02d}.parquet"
                ews_output = f"artifacts/metrics/ews_scores_{detected_year}_{detected_month:02d}.csv"
                ews_cmd = [sys.executable, "-m", "src.ews_scoring_v2", "--forecast", forecast_parquet, "--output", ews_output]
                result4 = subprocess.run(ews_cmd, capture_output=True, text=True)
                st.code(result4.stdout)
                if result4.returncode != 0:
                    st.error(f"[ì˜¤ë¥˜] EWS ìŠ¤ì½”ì–´ë§ ì‹¤íŒ¨: {result4.stderr}")
                    st.stop()
                # 5. ì¦ë¶„ ì¬í•™ìŠµ
                retrain_cmd = [sys.executable, "batch.py", "retrain", "--month", month_key]
                result5 = subprocess.run(retrain_cmd, capture_output=True, text=True)
                st.code(result5.stdout)
                if result5.returncode != 0:
                    st.error(f"[ì˜¤ë¥˜] ì¦ë¶„ ì¬í•™ìŠµ ì‹¤íŒ¨: {result5.stderr}")
                    st.stop()
                st.success(f"âœ… {month_key} íŒŒì´í”„ë¼ì¸ ìë™ ì‹¤í–‰ ì™„ë£Œ!")
                st.metric("ì´ ë ˆì½”ë“œ", f"{len(df_full):,}ê±´")
            with col2:
                series_count = int(df_full.groupby(['í”ŒëœíŠ¸', 'ì œí’ˆë²”ì£¼2', 'ì¤‘ë¶„ë¥˜']).ngroups)
                st.metric("ì‹œë¦¬ì¦ˆ ìˆ˜", f"{series_count:,}ê°œ")
            with col3:
                if 'ë°œìƒì¼ì' in df_full.columns:
                    df_full['ë°œìƒì¼ì'] = pd.to_datetime(df_full['ë°œìƒì¼ì'])
                    date_range = f"{df_full['ë°œìƒì¼ì'].min().date()} ~ {df_full['ë°œìƒì¼ì'].max().date()}"
                    st.metric("ë°œìƒì¼ì ë²”ìœ„", date_range)
            with col4:
                if 'count' in df_full.columns:
                    total_claims = int(df_full['count'].sum())
                    st.metric("ì´ í´ë ˆì„ ê±´ìˆ˜", f"{total_claims:,}ê±´")
            
            st.markdown("---")
            
            # ì²˜ë¦¬ ë²„íŠ¼
            st.subheader("2ï¸âƒ£ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
            
            col1, col2, col3 = st.columns([1, 1, 2])
            
            with col1:
                run_pipeline = st.button("ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰", type="primary", width='stretch', key="run_pipeline")
            
            with col2:
                show_command = st.checkbox("ëª…ë ¹ì–´ í‘œì‹œ", value=False)
            
            if show_command:
                with col3:
                    st.code(f"python batch.py process --upload {temp_path} --month {month_key}", language="bash")
            
            if run_pipeline:
                st.markdown("---")
                
                # ì²˜ë¦¬ ìƒíƒœ í‘œì‹œ (ë™ì  ì—…ë°ì´íŠ¸)
                status_placeholder = st.empty()
                status_placeholder.subheader("â³ ì²˜ë¦¬ ì¤‘...")
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                status_text = st.empty()
                
                # ë¡œê·¸ ì¶œë ¥ ì»¨í…Œì´ë„ˆ
                log_container = st.expander("ğŸ” ì‹¤ì‹œê°„ ë¡œê·¸", expanded=True)
                log_output = log_container.empty()
                
                try:
                    # batch.py process ì‹¤í–‰
                    status_text.info("ğŸ”„ íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
                    
                    cmd = [
                        sys.executable, "batch.py", "process",
                        "--upload", str(temp_path),
                        "--month", month_key
                    ]
                    
                    log_container.code(f"ì‹¤í–‰: {' '.join(cmd)}", language="bash")
                    
                    # ì‹¤ì‹œê°„ ì¶œë ¥ì„ ìœ„í•œ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
                    import io
                    process = subprocess.Popen(
                        cmd,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.STDOUT,
                        text=True,
                        cwd=Path.cwd(),
                        bufsize=1,
                        universal_newlines=True
                    )
                    
                    # ì‹¤ì‹œê°„ ë¡œê·¸ ìˆ˜ì§‘
                    output_lines = []
                    for line in iter(process.stdout.readline, ''):
                        if line:
                            output_lines.append(line.rstrip())
                            # ë§ˆì§€ë§‰ 50ì¤„ë§Œ í‘œì‹œ
                            display_lines = output_lines[-50:]
                            log_output.code('\n'.join(display_lines), language="text")
                            
                            # ìƒíƒœ ì—…ë°ì´íŠ¸
                            if "Step 1" in line or "Lag í•„í„°ë§" in line:
                                status_text.info("ğŸ”„ Step 1/4: Lag í•„í„°ë§ ì¤‘...")
                            elif "Step 2" in line or "ì£¼ê°„ ì§‘ê³„" in line:
                                status_text.info("ğŸ”„ Step 2/4: ì£¼ê°„ ì§‘ê³„ ë° JSON ì—…ë°ì´íŠ¸ ì¤‘...")
                            elif "Step 3" in line or "ì˜ˆì¸¡ ë¹„êµ" in line:
                                status_text.info("ğŸ”„ Step 3/4: ì˜ˆì¸¡ vs ì‹¤ì œ ë¹„êµ ì¤‘...")
                            elif "Step 4" in line or "ì¬í•™ìŠµ" in line:
                                status_text.info("ğŸ”„ Step 4/4: ëª¨ë¸ ì¬í•™ìŠµ ì¤‘...")
                    
                    process.wait()
                    result_code = process.returncode
                    
                    if result_code == 0:
                        status_placeholder.success("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
                        status_text.success("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
                        st.success("ğŸ‰ ì›”ë³„ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì™„ë£Œ!")
                        
                        # ê²°ê³¼ í‘œì‹œ (ìë™ ê°ì§€ëœ ë…„/ì›” ì‚¬ìš©)
                        month_dir = Path(f"artifacts/incremental/{detected_year}{detected_month:02d}")
                        summary_file = month_dir / f"summary_{detected_year}{detected_month:02d}.json"
                        
                        if summary_file.exists():
                            with open(summary_file, 'r', encoding='utf-8') as f:
                                summary = json.load(f)
                            
                            st.subheader("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("ì´ ë ˆì½”ë“œ", f"{summary.get('total_records', 0):,}ê±´")
                            with col2:
                                st.metric("ì‹œë¦¬ì¦ˆ ìˆ˜", f"{summary.get('series_count', 0):,}ê°œ")
                            with col3:
                                if summary.get('mean_error') is not None:
                                    st.metric("í‰ê·  ì˜¤ì°¨", f"{summary['mean_error']:.2f}")
                            with col4:
                                if summary.get('mae') is not None:
                                    st.metric("MAE", f"{summary['mae']:.2f}")
                            
                            st.info(f"ì²˜ë¦¬ ì‹œê°„: {summary.get('processed_at', 'N/A')}")
                    else:
                        status_placeholder.error("âŒ ì²˜ë¦¬ ì‹¤íŒ¨")
                        status_text.error("âŒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨")
                        st.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨ (exit code: {result_code})")
                        st.info("ğŸ’¡ ìœ„ì˜ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”.")
                
                except Exception as e:
                    status_placeholder.error("âŒ ì˜¤ë¥˜ ë°œìƒ")
                    status_text.error("âŒ ì˜¤ë¥˜ ë°œìƒ")
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                    import traceback
                    with log_container:
                        st.code(traceback.format_exc(), language="text")
        
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

# Tab 3: ì²˜ë¦¬ ê²°ê³¼
with tab3:
    st.header("ğŸ“ˆ ì²˜ë¦¬ ê²°ê³¼")
    
    # ì„œë¸Œíƒ­ ìƒì„±
    tabs_result = st.tabs(["ğŸ“‹ ì²˜ë¦¬ ê²°ê³¼ ì¡°íšŒ", "ğŸ¯ ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€", "ğŸ”„ ì¦ë¶„ ì¬í•™ìŠµ"])
    result_tab1, result_tab2, result_tab3 = tabs_result
    
    # ì²˜ë¦¬ ê²°ê³¼ ì¡°íšŒ
    with result_tab1:
        # ë…„/ì›” ì„ íƒ
        col_date1, col_date2, col_date3 = st.columns([1, 1, 2])
        with col_date1:
            current_year = datetime.now().year
            view_year = st.selectbox("ì—°ë„", range(2024, current_year + 2), key="view_year")
        with col_date2:
            view_month = st.selectbox("ì›”", range(1, 13), key="view_month")
        with col_date3:
            st.info(f"**ì¡°íšŒ ëŒ€ìƒ ì›”:** {view_year}-{view_month:02d}")
        
        month_key = f"{view_year}-{view_month:02d}"
        
        # ì›”ë³„ ê²°ê³¼ ë””ë ‰í† ë¦¬
        month_dir = Path(f"artifacts/incremental/{view_year}{view_month:02d}")
        if month_dir.exists():
            st.success(f"âœ… {month_key} ì²˜ë¦¬ ê²°ê³¼ ì¡´ì¬")
            files = list(month_dir.glob("*"))
            # ì£¼ìš” íŒŒì¼ ìë™ ë¶„ë¥˜
            summary_file = month_dir / f"summary_{view_year}{view_month:02d}.json"
            eval_file = month_dir / f"{view_year}{view_month:02d}_predict_vs_actual.csv"
            retrain_file = month_dir / f"{view_year}{view_month:02d}_incremental_training_results.csv"
            # ìš”ì•½ ì •ë³´ í‘œì‹œ
            if summary_file.exists():
                with open(summary_file, 'r', encoding='utf-8') as f:
                    summary = json.load(f)
                st.subheader("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ì´ ë ˆì½”ë“œ", f"{summary.get('total_records', 0):,}ê±´")
                with col2:
                    st.metric("ì‹œë¦¬ì¦ˆ ìˆ˜", f"{summary.get('series_count', 0):,}ê°œ")
                with col3:
                    if summary.get('mean_error') is not None:
                        st.metric("í‰ê·  ì˜¤ì°¨", f"{summary['mean_error']:.2f}")
                with col4:
                    if summary.get('mae') is not None:
                        st.metric("MAE", f"{summary['mae']:.2f}")
                st.info(f"ì²˜ë¦¬ ì‹œê°„: {summary.get('processed_at', 'N/A')}")
            # í‰ê°€ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
            if eval_file.exists():
                st.subheader("ğŸ“ˆ ì˜ˆì¸¡ vs ì‹¤ì œ í‰ê°€ ê²°ê³¼")
                if st.button("í‰ê°€ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°", key="preview_eval"):
                    df_eval = _read_csv_any_encoding(eval_file)
                    st.dataframe(df_eval.head(100), width='stretch')
            # ì¬í•™ìŠµ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
            if retrain_file.exists():
                st.subheader("ï¿½ ì¦ë¶„ ì¬í•™ìŠµ ê²°ê³¼")
                if st.button("ì¬í•™ìŠµ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°", key="preview_retrain"):
                    df_retrain = _read_csv_any_encoding(retrain_file)
                    st.dataframe(df_retrain.head(100), width='stretch')
            # ê¸°íƒ€ íŒŒì¼ ëª©ë¡
            st.subheader("ğŸ“ ê¸°íƒ€ ìƒì„±ëœ íŒŒì¼")
            for file in sorted(files):
                # ì£¼ìš” íŒŒì¼ì€ ìœ„ì—ì„œ ì´ë¯¸ í‘œì‹œ
                if file in [summary_file, eval_file, retrain_file]:
                    continue
                col1, col2, col3 = st.columns([3, 1, 1])
                with col1:
                    st.text(f"ğŸ“„ {file.name}")
                with col2:
                    st.caption(f"{file.stat().st_size / 1024:.1f} KB")
                with col3:
                    if file.suffix == '.csv':
                        if st.button(f"ë³´ê¸°", key=f"view_{file.name}"):
                            df = _read_csv_any_encoding(file)
                            st.dataframe(df.head(100), width='stretch')
                    elif file.suffix == '.json':
                        if st.button(f"ë³´ê¸°", key=f"view_{file.name}"):
                            with open(file, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                            st.json(data)
                    elif file.suffix == '.parquet':
                        if st.button(f"ë³´ê¸°", key=f"view_{file.name}"):
                            df = pd.read_parquet(file)
                            st.dataframe(df.head(100), width='stretch')
                        elif file.suffix == '.json':
                            if st.button(f"ë³´ê¸°", key=f"view_{file.name}"):
                                with open(file, 'r', encoding='utf-8') as f:
                                    data = json.load(f)
                                st.json(data)
                
                # ì˜ˆì¸¡-ì‹¤ì¸¡ ë¹„êµ íŒŒì¼ ìˆìœ¼ë©´ ì‹œê°í™”
                predict_vs_actual = month_dir / f"predict_vs_actual_{view_year}{view_month:02d}.csv"
                if predict_vs_actual.exists():
                    st.markdown("---")
                    st.subheader("ğŸ“Š ì˜ˆì¸¡ vs ì‹¤ì¸¡ ë¹„êµ")
                    
                    df_compare = pd.read_csv(predict_vs_actual, encoding='utf-8-sig')
                    
                    # í†µê³„
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("í‰ê·  ì˜¤ì°¨", f"{df_compare['error'].mean():.2f}")
                    with col2:
                        st.metric("ì ˆëŒ€ ì˜¤ì°¨ í‰ê· ", f"{df_compare['abs_error'].mean():.2f}")
                    with col3:
                        st.metric("í¼ì„¼íŠ¸ ì˜¤ì°¨ í‰ê· ", f"{df_compare['pct_error'].mean():.2f}%")
                    with col4:
                        st.metric("ë¹„êµ ë ˆì½”ë“œ", f"{len(df_compare):,}ê±´")
                    
                    # ìƒìœ„ ì˜¤ì°¨ ì‹œë¦¬ì¦ˆ
                    st.markdown("**ìƒìœ„ ì˜¤ì°¨ ì‹œë¦¬ì¦ˆ (Top 10)**")
                    display_cols = ['series_id']
                    if 'month' in df_compare.columns:
                        display_cols.append('month')
                    display_cols.extend(['claim_count', 'y_pred', 'error', 'abs_error'])
                    top_errors = df_compare.nlargest(10, 'abs_error')[display_cols]
                    st.dataframe(top_errors, width='stretch')
            else:
                st.info("íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info(f"{month_key} ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê³  íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    # ì„œë¸Œíƒ­ 2: ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€
    with result_tab2:
        st.markdown("### ğŸ¯ ì˜ˆì¸¡ vs ì‹¤ì œ ì„±ëŠ¥ í‰ê°€")
        st.caption("ì—…ë¡œë“œëœ ì‹¤ì œ ë°ì´í„°ì™€ ì˜ˆì¸¡ê°’ì„ ë¹„êµí•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.")

        # í‰ê°€ ëŒ€ìƒ ì›” ì„ íƒ
        col1, col2 = st.columns(2)
        with col1:
            eval_year = st.selectbox("í‰ê°€ ì—°ë„", range(2024, current_year + 2), key="eval_year_accuracy")
        with col2:
            eval_month = st.selectbox("í‰ê°€ ì›”", range(1, 13), key="eval_month_accuracy")

        eval_month_key = f"{eval_year}-{eval_month:02d}"

        # ì˜ˆì¸¡ íŒŒì¼ì€ (í‰ê°€ì›”-1)ë¡œ ìë™ ì„ íƒ, ë‹¨ 2024-01ì›”ì€ ìµœì´ˆ ë² ì´ìŠ¤ íŒŒì¼ ì‚¬ìš©
        from dateutil.relativedelta import relativedelta
        if eval_year == 2024 and eval_month == 1:
            forecast_file = Path("artifacts/forecasts/base_monthly/forecast_base_monthly.parquet")
        else:
            eval_date = datetime(eval_year, eval_month, 1)
            forecast_date = eval_date - relativedelta(months=1)
            forecast_year = forecast_date.year
            forecast_month = forecast_date.month
            forecast_file = Path(f"artifacts/forecasts/{forecast_year}/forecast_{forecast_year}_{forecast_month:02d}.parquet")
        actual_file = Path("data/curated/claims_monthly.parquet")

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        col_check1, col_check2 = st.columns(2)
        with col_check1:
            if forecast_file.exists():
                st.success(f"âœ… ì˜ˆì¸¡ íŒŒì¼ ì¡´ì¬: {forecast_file.name}")
            else:
                st.error(f"âŒ ì˜ˆì¸¡ íŒŒì¼ ì—†ìŒ: {forecast_file.name}")

        with col_check2:
            if actual_file.exists():
                # ì‹¤ì œ ë°ì´í„°ì— í•´ë‹¹ ì›”ì´ ìˆëŠ”ì§€ í™•ì¸
                df_actual_check = pd.read_parquet(actual_file)
                has_month = ((df_actual_check['year'] == eval_year) & 
                            (df_actual_check['month'] == eval_month)).any()
                if has_month:
                    st.success(f"âœ… ì‹¤ì œ ë°ì´í„° ì¡´ì¬: {eval_month_key}")
                else:
                    st.warning(f"âš ï¸ {eval_month_key} ì‹¤ì œ ë°ì´í„° ì—†ìŒ")
            else:
                st.error("âŒ ì‹¤ì œ ë°ì´í„° íŒŒì¼ ì—†ìŒ")

        # í‰ê°€ ì‹¤í–‰ ë²„íŠ¼
        if st.button("ğŸ¯ ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰", type="primary", width='stretch', key="eval_accuracy_tab2"):
            if not forecast_file.exists():
                st.error("ì˜ˆì¸¡ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì˜ˆì¸¡ì„ ìƒì„±í•˜ì„¸ìš”.")
            elif not actual_file.exists():
                st.error("ì‹¤ì œ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                with st.spinner("í‰ê°€ ì¤‘..."):
                    try:
                        # ë°ì´í„° ë¡œë“œ
                        df_forecast = pd.read_parquet(forecast_file)
                        df_actual = pd.read_parquet(actual_file)
                        # í•´ë‹¹ ì›” í•„í„°ë§
                        df_forecast_month = df_forecast[
                            (df_forecast['year'] == eval_year) & 
                            (df_forecast['month'] == eval_month)
                        ].copy()
                        df_actual_month = df_actual[
                            (df_actual['year'] == eval_year) & 
                            (df_actual['month'] == eval_month)
                        ].copy()
                        if len(df_actual_month) == 0:
                            st.error(f"{eval_month_key} ì‹¤ì œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            # ë³‘í•©
                            df_compare = pd.merge(
                                df_actual_month[['series_id', 'year', 'month', 'claim_count']],
                                df_forecast_month[['series_id', 'year', 'month', 'y_pred', 'y_pred_lower', 'y_pred_upper']],
                                on=['series_id', 'year', 'month'],
                                how='inner'
                            )
                            if len(df_compare) == 0:
                                st.warning("ì˜ˆì¸¡ê³¼ ì‹¤ì œ ë°ì´í„° ê°„ ë§¤ì¹­ë˜ëŠ” ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                # ê²°ê³¼ ì „ì²´ë¥¼ ì»¨í…Œì´ë„ˆë¡œ ë¬¶ìŒ
                                with st.container():
                                    # ì˜¤ì°¨ ê³„ì‚°
                                    df_compare['error'] = df_compare['y_pred'] - df_compare['claim_count']
                                    df_compare['abs_error'] = df_compare['error'].abs()
                                    df_compare['abs_pct_error'] = (df_compare['abs_error'] / (df_compare['claim_count'] + 1)) * 100
                                    # ì „ì²´ ë©”íŠ¸ë¦­ ê³„ì‚°
                                    mae = df_compare['abs_error'].mean()
                                    rmse = np.sqrt((df_compare['error'] ** 2).mean())
                                    mape = df_compare['abs_pct_error'].mean()
                                    # WMAPE (Weighted MAPE)
                                    wmape = (df_compare['abs_error'].sum() / df_compare['claim_count'].sum()) * 100
                                    # Bias (í‰ê·  ì˜¤ì°¨)
                                    bias = df_compare['error'].mean()
                                    # ê²°ê³¼ í‘œì‹œ
                                    st.success(f"âœ… í‰ê°€ ì™„ë£Œ: {len(df_compare)}ê°œ ì‹œë¦¬ì¦ˆ ë¹„êµ")
                                    # ë©”íŠ¸ë¦­ ì¹´ë“œ
                                    st.markdown("### ğŸ“Š ì „ì²´ ì„±ëŠ¥ ë©”íŠ¸ë¦­")
                                    col1, col2, col3, col4, col5 = st.columns(5)
                                    with col1:
                                        st.metric("MAE", f"{mae:.2f}ê±´", help="Mean Absolute Error (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨)")
                                    with col2:
                                        st.metric("RMSE", f"{rmse:.2f}ê±´", help="Root Mean Square Error")
                                    with col3:
                                        st.metric("MAPE", f"{mape:.1f}%", help="Mean Absolute Percentage Error")
                                    with col4:
                                        st.metric("WMAPE", f"{wmape:.1f}%", help="Weighted MAPE (ì´ëŸ‰ ê¸°ì¤€)")
                                    with col5:
                                        bias_delta = "ê³¼ëŒ€ì˜ˆì¸¡" if bias > 0 else "ê³¼ì†Œì˜ˆì¸¡"
                                        st.metric("Bias", f"{bias:+.2f}ê±´", delta=bias_delta, help="í‰ê·  ì˜¤ì°¨ (+ = ê³¼ëŒ€ì˜ˆì¸¡)")
                                    # ì˜¤ì°¨ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
                                    st.markdown("### ğŸ“ˆ ì˜¤ì°¨ ë¶„í¬")
                                    fig_hist = go.Figure()
                                    fig_hist.add_trace(go.Histogram(
                                        x=df_compare['error'], nbinsx=50, name='ì˜¤ì°¨ ë¶„í¬', marker_color='lightblue'))
                                    fig_hist.update_layout(
                                        title='ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„í¬ (ì˜ˆì¸¡ - ì‹¤ì œ)', xaxis_title='ì˜¤ì°¨ (ê±´)', yaxis_title='ë¹ˆë„', height=400)
                                    st.plotly_chart(fig_hist, width='stretch')
                                    # Top ì˜¤ì°¨ ì‹œë¦¬ì¦ˆ
                                    st.markdown("### âš ï¸ ì˜¤ì°¨ê°€ í° ì‹œë¦¬ì¦ˆ (ì¬í•™ìŠµ ìš°ì„ ìˆœìœ„)")
                                    df_top_errors = df_compare.nlargest(20, 'abs_error')[
                                        ['series_id', 'claim_count', 'y_pred', 'error', 'abs_error', 'abs_pct_error']].copy()
                                    df_top_errors.columns = ['ì‹œë¦¬ì¦ˆ', 'ì‹¤ì œ', 'ì˜ˆì¸¡', 'ì˜¤ì°¨', 'ì ˆëŒ€ì˜¤ì°¨', 'ì˜¤ì°¨ìœ¨(%)']
                                    st.dataframe(
                                        df_top_errors.style.format({
                                            'ì‹¤ì œ': lambda x: f"{int(x)}" if x is not None else "N/A",
                                            'ì˜ˆì¸¡': lambda x: f"{x:.1f}" if x is not None else "N/A",
                                            'ì˜¤ì°¨': lambda x: f"{x:+.1f}" if x is not None else "N/A",
                                            'ì ˆëŒ€ì˜¤ì°¨': lambda x: f"{x:.1f}" if x is not None else "N/A",
                                            'ì˜¤ì°¨ìœ¨(%)': lambda x: f"{x:.1f}%" if x is not None else "N/A"
                                        }).background_gradient(subset=['ì ˆëŒ€ì˜¤ì°¨'], cmap='Reds'),
                                        width='stretch',
                                        height=400
                                    )
                                    # ì¬í•™ìŠµ í•„ìš” ì‹œë¦¬ì¦ˆ ì‹ë³„ í•¨ìˆ˜
                                    def identify_retrain_candidates(df_compare, mae, wmape):
                                        """ì¬í•™ìŠµì´ í•„ìš”í•œ ì‹œë¦¬ì¦ˆ ì‹ë³„"""
                                        return df_compare[
                                            ((df_compare['abs_error'] > mae * 2) |
                                             (df_compare['abs_pct_error'] > wmape * 1.5) |
                                             (df_compare['error'] > df_compare['claim_count'] * 0.5) |
                                             (df_compare['error'] < -df_compare['claim_count'] * 0.5) |
                                             ((df_compare['claim_count'] >= 10) & (df_compare['abs_pct_error'] > 30)))].copy()
                                    high_error_series = identify_retrain_candidates(df_compare, mae, wmape)
                                    if len(high_error_series) > 0:
                                        st.warning(f"âš ï¸ **ì¬í•™ìŠµ ê¶Œì¥**: {len(high_error_series)}ê°œ ì‹œë¦¬ì¦ˆê°€ ê³¼ì†Œ, ê³¼ëŒ€ ì˜ˆì¸¡ëœ ìƒíƒœì…ë‹ˆë‹¤.")
                                        st.session_state.high_error_series = high_error_series.copy()
                                        st.session_state.current_eval_metrics = {
                                            'mae': float(mae), 'rmse': float(rmse), 'mape': float(mape), 'wmape': float(wmape), 'bias': float(bias)
                                        }
                                        st.info("ğŸ‘‰ 'ì¦ë¶„ ì¬í•™ìŠµ' íƒ­ì—ì„œ ì¬í•™ìŠµì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    
                    except Exception as e:
                        st.error(f"í‰ê°€ ì‹¤íŒ¨: {e}")
                        import traceback
                        st.code(traceback.format_exc())
    
    # ì„œë¸Œíƒ­ 3: ì¦ë¶„ ì¬í•™ìŠµ
    with result_tab3:
        st.markdown("### ğŸ”„ ì¦ë¶„ ì¬í•™ìŠµ")
        
        # ì¬í•™ìŠµ ëŒ€ìƒ í™•ì¸
        if 'high_error_series' not in st.session_state or st.session_state.high_error_series is None:
            st.warning("âš ï¸ ë¨¼ì € 'ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€' íƒ­ì—ì„œ ì„±ëŠ¥ í‰ê°€ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            st.stop()
        
        # í˜„ì¬ ì„ íƒëœ ì—°ì›” í‘œì‹œ
        st.info(f"**ì¬í•™ìŠµ ëŒ€ìƒ ì›”:** {eval_year}-{eval_month:02d}")
        
        # ì¬í•™ìŠµ ëŒ€ìƒ ì •ë³´
        st.subheader("1ï¸âƒ£ ì¬í•™ìŠµ ëŒ€ìƒ")
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.markdown(f"""
            **ì„ íƒëœ ì‹œë¦¬ì¦ˆ:**
            - ê³¼ì†Œ/ê³¼ëŒ€ ì˜ˆì¸¡ëœ ì‹œë¦¬ì¦ˆ: {len(st.session_state.high_error_series):,}ê°œ
            - í˜„ì¬ ë©”íŠ¸ë¦­:
              - WMAPE: {st.session_state.current_eval_metrics['wmape']:.1f}%
              - MAE: {st.session_state.current_eval_metrics['mae']:.2f}
              - Bias: {st.session_state.current_eval_metrics['bias']:+.2f}
            
            **ì²˜ë¦¬ ë‚´ìš©:**
            - ë³€ê³¡ì  ê°ì§€ & ì˜µí‹°ë§ˆì´ì € ì¬ì‹¤í–‰
            - ì†Œìš” ì‹œê°„: ì‹œë¦¬ì¦ˆë‹¹ ì•½ 2-3ë¶„
            """)
        
        with col2:
            rerun = st.button("ğŸ”„ ì¬í•™ìŠµ ì‹œì‘", type="primary", width='stretch')
        
        if rerun:
            # ì•± ì „ì²´ ë°ì´í„° ìƒˆë¡œê³ ì¹¨ í•¨ìˆ˜
            def refresh_app_data():
                st.cache_data.clear()
                st.rerun()
            
            # ìƒíƒœ í‘œì‹œ ì»¨í…Œì´ë„ˆ
            status = st.empty()
            progress = st.empty()
            log = st.empty()
            
            try:
                # ì¬í•™ìŠµ ëŒ€ìƒ ì‹œë¦¬ì¦ˆ ì €ì¥
                retrain_dir = Path(f"artifacts/incremental/{eval_year}{eval_month:02d}")
                retrain_dir.mkdir(parents=True, exist_ok=True)
                
                retrain_file = retrain_dir / f"retrain_series_{eval_year}{eval_month:02d}.txt"
                st.session_state.high_error_series['series_id'].to_csv(
                    retrain_file,
                    index=False,
                    header=False
                )
                
                # ì¬í•™ìŠµ ëª…ë ¹ ì‹¤í–‰
                cmd = [
                    sys.executable,
                    "train_incremental_models.py",
                    "--train-until", str(eval_year),
                    "--max-workers", "4"
                ]
                
                # í”„ë¡œì„¸ìŠ¤ ì‹œì‘
                with status.container():
                    st.info("ğŸ”„ ì¬í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì¤‘...")
                
                process = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True,
                    bufsize=1,
                    universal_newlines=True
                )
                
                # ì§„í–‰ ìƒíƒœ ì´ˆê¸°í™”
                progress_bar = progress.progress(0)
                log_output = []
                completed_series_set = set()
                skipped_series_set = set()
                total_series = None
                start_time = time.time()

                # ì‹¤ì‹œê°„ ì¶œë ¥ ì²˜ë¦¬
                while True:
                    output = process.stdout.readline()
                    if output == '' and process.poll() is not None:
                        break

                    if output:
                        log_output.append(output.strip())

                        import re
                        # ì™„ë£Œëœ ì‹œë¦¬ì¦ˆ ì§‘ê³„
                        if "[PROGRESS] Completed training for series" in output:
                            match = re.search(r"series ([^\s]+)", output)
                            if match:
                                series_id = match.group(1)
                                completed_series_set.add(series_id)
                        # ìŠ¤í‚µëœ ì‹œë¦¬ì¦ˆ ì§‘ê³„
                        if "[PROGRESS] Skipped series" in output:
                            match = re.search(r"series ([^\s]+)", output)
                            if match:
                                series_id = match.group(1)
                                skipped_series_set.add(series_id)
                        # total_seriesê°€ Noneì´ë©´ ì¶”ì • (ìµœì´ˆ ë©”ì‹œì§€ì—ì„œ ì¶”ì¶œ)
                        if total_series is None:
                            total_series = len(st.session_state.high_error_series)
                        # ì§„í–‰ë¥  ê³„ì‚°: ì™„ë£Œ/(ì „ì²´-ìŠ¤í‚µ)
                        processed_count = len(completed_series_set) + len(skipped_series_set)
                        current_progress = min(processed_count / max(total_series, 1), 1.0)
                        progress_bar.progress(current_progress)

                        with status.container():
                            st.info(f"""
                            ğŸ”„ ì¬í•™ìŠµ ì§„í–‰ ì¤‘...
                            - ì™„ë£Œ: {processed_count}/{total_series} ì‹œë¦¬ì¦ˆ
                            - ì§„í–‰ë¥ : {current_progress*100:.1f}%
                            """)

                        # ë¡œê·¸ ì—…ë°ì´íŠ¸
                        log.code('\n'.join(log_output[-15:]))
                
                # í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ í™•ì¸
                if process.returncode == 0:
                    # ë©”íƒ€ë°ì´í„° ì €ì¥
                    meta_file = retrain_dir / f"retrain_meta_{eval_year}{eval_month:02d}.json"
                    meta_data = {
                        "eval_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "target_month": f"{eval_year}-{eval_month:02d}",
                        "total_series": len(st.session_state.high_error_series),
                        "retrain_series": len(st.session_state.high_error_series),
                        "metrics_before": st.session_state.current_eval_metrics
                    }
                    
                    with open(meta_file, 'w', encoding='utf-8') as f:
                        json.dump(meta_data, f, indent=2, ensure_ascii=False)
                    
                    # ì™„ë£Œ ìƒíƒœ í‘œì‹œ
                    elapsed_time = time.time() - start_time
                    with status.container():
                        st.success(f"""
                        âœ… ì¬í•™ìŠµ ì™„ë£Œ!
                        - ì´ {total_series}ê°œ ì‹œë¦¬ì¦ˆ ì¬í•™ìŠµ ì™„ë£Œ
                        - ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ
                        """)
                    
                    with st.spinner("ì¬í•™ìŠµ í›„ ì˜ˆì¸¡ ë° EWS ì ìˆ˜ ìƒì„± ì¤‘..."):
                        # ì˜ˆì¸¡ ìƒì„±
                        forecast_cmd = [
                            sys.executable,
                            "batch.py",
                            "forecast",
                            "--month-new", f"{eval_year}-{eval_month+1:02d}"
                        ]
                        forecast_result = subprocess.run(forecast_cmd)
                        if forecast_result.returncode == 0:
                            # EWS ì ìˆ˜ ê³„ì‚°
                            ews_cmd = [
                                sys.executable,
                                "batch.py",
                                "ews",
                                "--month", f"{eval_year}-{eval_month+1:02d}"
                            ]
                            ews_result = subprocess.run(ews_cmd)
                            if ews_result.returncode == 0:
                                st.success("âœ… ì¬í•™ìŠµ, ì˜ˆì¸¡, EWS ì ìˆ˜ ìƒì„±ê¹Œì§€ ëª¨ë‘ ì™„ë£Œ!")
                            else:
                                st.error("âŒ EWS ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨")
                        else:
                            st.error("âŒ ìƒˆë¡œìš´ ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨")
                        # ìƒˆë¡œê³ ì¹¨ ì œê±°: ì„±ê³µ/ì‹¤íŒ¨ ë©”ì‹œì§€ ìœ ì§€
                else:
                    with status.container():
                        st.error("âŒ ì¬í•™ìŠµ ì‹¤íŒ¨")
                        error_output = process.stderr.read()
                        st.code(error_output)
            
            except Exception as e:
                with status.container():
                    st.error(f"âŒ ì¬í•™ìŠµ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                import traceback
                st.code(traceback.format_exc())

# Tab 4: Reconcile ë³´ì •
with tab4:
    st.header("ğŸ”§ Reconcile ë³´ì •")
    
    # ë…„/ì›” ì„ íƒ
    col_date1, col_date2, col_date3 = st.columns([1, 1, 2])
    with col_date1:
        current_year = datetime.now().year
        reconcile_year = st.selectbox("ì—°ë„", range(2024, current_year + 2), key="reconcile_year")
    with col_date2:
        reconcile_month = st.selectbox("ì›”", range(1, 13), key="reconcile_month")
    with col_date3:
        st.info(f"**Reconcile ëŒ€ìƒ ì›”:** {reconcile_year}-{reconcile_month:02d}")
    
    month_key = f"{reconcile_year}-{reconcile_month:02d}"
    
    month_dir = Path(f"artifacts/incremental/{reconcile_year}{reconcile_month:02d}")
    reconcile_dir = Path(f"artifacts/reconcile/{reconcile_year}{reconcile_month:02d}")
    
    # ì²˜ë¦¬ ê²°ê³¼ í™•ì¸
    predict_vs_actual = month_dir / f"predict_vs_actual_{reconcile_year}{reconcile_month:02d}.csv"
    
    if predict_vs_actual.exists():
        st.success(f"âœ… {month_key} ì²˜ë¦¬ ê²°ê³¼ ì¡´ì¬")
        
        # KPI í™•ì¸
        df_compare = pd.read_csv(predict_vs_actual, encoding='utf-8-sig')
        
        # MAPE ê³„ì‚°
        valid_mask = df_compare['claim_count'] > 0
        if valid_mask.sum() > 0:
            mape = (df_compare[valid_mask]['abs_error'] / df_compare[valid_mask]['claim_count']).mean()
        else:
            mape = np.nan
        
        # Bias ê³„ì‚°
        bias = df_compare['error'].mean() / df_compare['claim_count'].mean() if df_compare['claim_count'].mean() > 0 else np.nan
        
        # KPI í†µê³¼ ì—¬ë¶€ ê³„ì‚°
        mape_pass = mape < 0.20 if not np.isnan(mape) else False
        bias_pass = abs(bias) < 0.05 if not np.isnan(bias) else False
        kpi_pass = mape_pass and bias_pass
        
        st.subheader("ğŸ“Š í˜„ì¬ KPI")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("MAPE", f"{mape:.2%}", delta=f"ëª©í‘œ: <20%", delta_color="inverse" if not mape_pass else "normal")
        
        with col2:
            st.metric("|Bias|", f"{abs(bias):.4f}", delta=f"ëª©í‘œ: <0.05", delta_color="inverse" if not bias_pass else "normal")
        
        with col3:
            st.metric("MAE", f"{df_compare['abs_error'].mean():.2f}")
        
        with col4:
            if kpi_pass:
                st.success("âœ… KPI í†µê³¼")
            else:
                st.error("âŒ KPI ë¯¸ë‹¬")
        
        st.markdown("---")
        
        # Reconcile ì‹¤í–‰
        st.subheader("ğŸš€ ë³´ì • ì‹¤í–‰")
        
        col1, col2, col3 = st.columns([1, 1, 2])
        
        with col1:
            stage = st.selectbox(
                "ë³´ì • ë‹¨ê³„",
                ['all', 'bias', 'seasonal', 'optuna'],
                index=0,
                help="all: ëª¨ë“  ë‹¨ê³„ ìˆœì°¨ ì‹¤í–‰, bias: Bias Mapë§Œ, seasonal: ê³„ì ˆì„± ì¬ì¶”ì •ë§Œ, optuna: Optuna íŠœë‹ë§Œ"
            )
        
        with col2:
            run_reconcile = st.button("ğŸ”§ Reconcile ì‹¤í–‰", type="primary", width='stretch', key="run_reconcile")
        
        stage_descriptions = {
            'all': 'ëª¨ë“  ë‹¨ê³„ ìˆœì°¨ ì‹¤í–‰ (Bias Map â†’ Seasonal â†’ Optuna)',
            'bias': 'Stage 1: Bias Map - ì£¼ê°„ í‰ê·  ì˜¤ì°¨ ë³´ì •',
            'seasonal': 'Stage 2: Seasonal Recalibration - ìµœê·¼ 2ë…„ ê³„ì ˆì„± ì¬ì¶”ì •',
            'optuna': 'Stage 3: Optuna Tuning - í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”'
        }
        
        with col3:
            st.info(stage_descriptions[stage])
        
        if run_reconcile:
            st.markdown("---")
            st.subheader("â³ Reconcile ì‹¤í–‰ ì¤‘...")
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            log_container = st.expander("ğŸ” ìƒì„¸ ë¡œê·¸", expanded=True)
            
            try:
                status_text.text(f"ì‹¤í–‰ ì¤‘: {stage} ë‹¨ê³„...")
                progress_bar.progress(30)
                
                cmd = [
                    sys.executable, "reconcile_pipeline.py",
                    "--year", str(reconcile_year),
                    "--month", str(reconcile_month),
                    "--stage", stage
                ]
                
                with log_container:
                    st.code(f"ì‹¤í–‰: {' '.join(cmd)}", language="bash")
                
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    cwd=Path.cwd()
                )
                
                with log_container:
                    if result.stdout:
                        st.text("STDOUT:")
                        st.code(result.stdout, language="text")
                    if result.stderr:
                        st.text("STDERR:")
                        st.code(result.stderr, language="text")
                
                if result.returncode == 0:
                    progress_bar.progress(100)
                    status_text.text("âœ… ì™„ë£Œ!")
                    st.success("ğŸ‰ Reconcile ë³´ì • ì™„ë£Œ!")
                    
                    # ê²°ê³¼ í‘œì‹œ
                    summary_file = reconcile_dir / f"reconcile_summary_{reconcile_year}{reconcile_month:02d}.json"
                    
                    if summary_file.exists():
                        with open(summary_file, 'r', encoding='utf-8') as f:
                            summary = json.load(f)
                        
                        st.subheader("ğŸ“Š ë³´ì • ê²°ê³¼")
                        
                        # ì´ˆê¸° vs ìµœì¢… KPI
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown("**ì´ˆê¸° KPI**")
                            initial = summary['initial_kpi']
                            st.metric("MAPE", f"{initial.get('MAPE', 0):.2%}")
                            st.metric("|Bias|", f"{abs(initial.get('Bias', 0)):.4f}")
                            st.metric("MAE", f"{initial.get('MAE', 0):.2f}")
                        
                        with col2:
                            st.markdown("**ìµœì¢… KPI**")
                            if summary.get('final_kpi'):
                                final = summary['final_kpi']
                                st.metric("MAPE", f"{final.get('MAPE', 0):.2%}")
                                st.metric("|Bias|", f"{abs(final.get('Bias', 0)):.4f}")
                                st.metric("MAE", f"{final.get('MAE', 0):.2f}")
                        
                        # í†µê³¼ ì—¬ë¶€
                        if summary.get('pass'):
                            st.success("âœ… KPI ëª©í‘œ ë‹¬ì„±!")
                        else:
                            st.warning("âš ï¸ KPI ë¯¸ë‹¬ - ì¶”ê°€ ì¡°ì¹˜ í•„ìš”")
                        
                        # ì‹¤í–‰ëœ ë‹¨ê³„
                        if summary.get('stages_run'):
                            st.markdown("**ì‹¤í–‰ëœ ë‹¨ê³„**")
                            for stage_result in summary['stages_run']:
                                with st.expander(f"ğŸ“Œ {stage_result['stage']}"):
                                    st.json(stage_result['improvement'])
                else:
                    progress_bar.progress(0)
                    status_text.text("âŒ ì‹¤íŒ¨")
                    st.error(f"Reconcile ì‹¤í–‰ ì‹¤íŒ¨ (exit code: {result.returncode})")
            
            except Exception as e:
                progress_bar.progress(0)
                status_text.text("âŒ ì˜¤ë¥˜")
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                with log_container:
                    st.code(traceback.format_exc(), language="text")
        
        # ê¸°ì¡´ Reconcile ê²°ê³¼ í‘œì‹œ
        if reconcile_dir.exists():
            st.markdown("---")
            st.subheader("ğŸ“ Reconcile ê²°ê³¼ íŒŒì¼")
            
            files = list(reconcile_dir.glob("*"))
            if files:
                for file in sorted(files):
                    col1, col2, col3 = st.columns([3, 1, 1])
                    with col1:
                        st.text(f"ğŸ“„ {file.name}")
                    with col2:
                        st.caption(f"{file.stat().st_size / 1024:.1f} KB")
                    with col3:
                        if file.suffix == '.csv':
                            if st.button(f"ë³´ê¸°", key=f"view_rec_{file.name}"):
                                df = pd.read_csv(file, encoding='utf-8-sig')
                                st.dataframe(df.head(100), width='stretch')
                        elif file.suffix == '.json':
                            if st.button(f"ë³´ê¸°", key=f"view_rec_{file.name}"):
                                with open(file, 'r', encoding='utf-8') as f:
                                    data = json.load(f)
                                st.json(data)
                        elif file.suffix == '.txt':
                            if st.button(f"ë³´ê¸°", key=f"view_rec_{file.name}"):
                                import chardet
                                with open(file, 'rb') as f:
                                    raw = f.read()
                                    encoding = chardet.detect(raw)['encoding'] or 'utf-8'
                                    content = raw.decode(encoding, errors='replace')
                                st.text(content)
    else:
        st.info(f"{month_key} ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € Tab 3ì—ì„œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì„¸ìš”.")

# Tab 5: í†µê³„
with tab5:
    st.header("ğŸ“Š í†µê³„")
    
    # ì¦ë¶„ ë””ë ‰í† ë¦¬ í™•ì¸
    incremental_dir = Path("artifacts/incremental")
    
    # ì„œë¸Œíƒ­: ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬ / ì„±ëŠ¥ íŠ¸ë Œë“œ
    stat_tab1, stat_tab2 = st.tabs(["ğŸ“… ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬", "ğŸ“ˆ ì„±ëŠ¥ íŠ¸ë Œë“œ"])
    
    # ì„œë¸Œíƒ­ 1: ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬
    with stat_tab1:
        st.subheader("ğŸ“¥ ë°ì´í„° ì—…ë¡œë“œ ì´ë ¥")
        
        # ì¦ë¶„ ë””ë ‰í† ë¦¬ ì „ì²´ ìŠ¤ìº”
        incremental_dirs = list(incremental_dir.glob("*"))
        
        if not incremental_dirs:
            st.info("ì•„ì§ ì—…ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ì—…ë¡œë“œ ì´ë ¥ ë°ì´í„° ìˆ˜ì§‘
            upload_history = []
            
            for inc_dir in sorted(incremental_dirs, reverse=True):
                if not inc_dir.is_dir():
                    continue
                
                try:
                    year = int(inc_dir.name[:4])
                    month = int(inc_dir.name[4:6])
                    
                    # ë©”íƒ€ë°ì´í„° íŒŒì¼
                    meta_file = inc_dir / f"retrain_meta_{year}{month:02d}.json"
                    if meta_file.exists():
                        with open(meta_file, 'r', encoding='utf-8') as f:
                            meta_data = json.load(f)
                    else:
                        meta_data = None
                    
                    # ì˜ˆì¸¡-ì‹¤ì œ ë¹„êµ íŒŒì¼
                    # ì—…ë¡œë“œí•œ csvì˜ ì´ ì‹œë¦¬ì¦ˆ ìˆ˜

                    # ì‹œë¦¬ì¦ˆ ìˆ˜ëŠ” retrain_meta_YYYYMM.jsonì˜ total_series ê°’ ì‚¬ìš©
                    meta_file = inc_dir / f"retrain_meta_{year}{month:02d}.json"
                    if meta_file.exists():
                        with open(meta_file, 'r', encoding='utf-8') as f:
                            meta_data = json.load(f)
                        n_series = meta_data.get('total_series', 0)
                        metrics = meta_data.get('metrics_before', {})
                        mae = metrics.get('mae', None)
                        wmape = metrics.get('wmape', None)
                    else:
                        n_series = 0
                        mae = None
                        wmape = None

                    # ì „ì²´ ì„±ëŠ¥ ë©”íŠ¸ë¦­ì—ì„œ MAE, WMAPE ê°€ì ¸ì˜¤ê¸°
                    meta_file = inc_dir / f"retrain_meta_{year}{month:02d}.json"
                    if meta_file.exists():
                        with open(meta_file, 'r', encoding='utf-8') as f:
                            meta_data = json.load(f)
                        metrics = meta_data.get('metrics_before', {})
                        mae = metrics.get('mae', None)
                        wmape = metrics.get('wmape', None)
                    else:
                        mae = None
                        wmape = None
                    
                    # ì¬í•™ìŠµ ë¦¬ìŠ¤íŠ¸
                    retrain_file = inc_dir / f"retrain_series_{year}{month:02d}.txt"
                    if retrain_file.exists():
                        import chardet
                        with open(retrain_file, 'rb') as f:
                            raw = f.read()
                            encoding = chardet.detect(raw)['encoding'] or 'utf-8'
                            lines = raw.decode(encoding, errors='replace').splitlines()
                            n_retrain = len(lines)
                    else:
                        n_retrain = 0
                    
                    upload_history.append({
                        'year': year,
                        'month': month,
                        'date': meta_data['eval_date'] if meta_data else None,
                        'n_series': n_series,
                        'mae': mae,
                        'wmape': wmape,
                        'n_retrain': n_retrain
                    })
                
                except Exception as e:
                    st.error(f"ë””ë ‰í† ë¦¬ {inc_dir.name} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            
            if upload_history:
                # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
                df_history = pd.DataFrame(upload_history)
                df_history['period'] = df_history.apply(
                    lambda x: f"{x['year']}-{x['month']:02d}", axis=1
                )
                # ìµœì‹ ìˆœ ì •ë ¬
                df_history = df_history.sort_values(['year', 'month'], ascending=[False, False])
                # session_stateì— ì €ì¥
                st.session_state.df_history = df_history
                # í…Œì´ë¸” í‘œì‹œ
                st.dataframe(
                    df_history[['period', 'date', 'n_series', 'mae', 'wmape', 'n_retrain']].rename(columns={
                        'period': 'ëŒ€ìƒ ì›”',
                        'date': 'í‰ê°€ ì¼ì‹œ',
                        'n_series': 'ì‹œë¦¬ì¦ˆ ìˆ˜',
                        'mae': 'MAE',
                        'wmape': 'WMAPE(%)',
                        'n_retrain': 'ì¬í•™ìŠµ'
                    }).style.format({
                        'ì‹œë¦¬ì¦ˆ ìˆ˜': lambda x: f"{int(x)}" if x is not None else "N/A",
                        'ì¬í•™ìŠµ': lambda x: f"{int(x)}" if x is not None else "N/A",
                        'MAE': lambda x: f"{x:.2f}" if x is not None else "N/A",
                        'WMAPE(%)': lambda x: f"{x:.1f}%" if x is not None else "N/A"
                    }),
                    width='stretch'
                )
    
    # ì„œë¸Œíƒ­ 2: ì„±ëŠ¥ íŠ¸ë Œë“œ
    with stat_tab2:
        st.subheader("ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ì¶”ì´")
        
        if not incremental_dirs:
            st.info("ì•„ì§ ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        elif 'df_history' not in st.session_state:
            st.warning("ì—…ë¡œë“œ ì´ë ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬ íƒ­ì„ í™•ì¸í•˜ì„¸ìš”.")
        else:
            df_history = st.session_state.df_history
            # ì‹œê³„ì—´ ê·¸ë˜í”„
            fig = go.Figure()
            # WMAPE ì¶”ì´
            if not df_history['wmape'].isna().all():
                fig.add_trace(go.Scatter(
                    x=df_history['period'],
                    y=df_history['wmape'],
                    name='WMAPE(%)',
                    line=dict(color='royalblue', width=2),
                    mode='lines+markers'
                ))
            # MAE ì¶”ì´
            if not df_history['mae'].isna().all():
                fig.add_trace(go.Scatter(
                    x=df_history['period'],
                    y=df_history['mae'],
                    name='MAE',
                    line=dict(color='firebrick', width=2, dash='dot'),
                    mode='lines+markers',
                    yaxis='y2'
                ))
            # ì¬í•™ìŠµ ê±´ìˆ˜ (ë§‰ëŒ€)
            fig.add_trace(go.Bar(
                x=df_history['period'],
                y=df_history['n_retrain'],
                name='ì¬í•™ìŠµ ê±´ìˆ˜',
                marker_color='lightgray',
                opacity=0.5,
                yaxis='y3'
            ))
            # ë ˆì´ì•„ì›ƒ
            fig.update_layout(
                title='ì›”ë³„ ì˜ˆì¸¡ ì„±ëŠ¥ ë° ì¬í•™ìŠµ ì¶”ì´',
                xaxis=dict(title='ëŒ€ìƒ ì›”'),
                yaxis=dict(
                    title=dict(text='WMAPE(%)', font=dict(color='royalblue')),
                    tickfont=dict(color='royalblue')
                ),
                yaxis2=dict(
                    title=dict(text='MAE', font=dict(color='firebrick')),
                    tickfont=dict(color='firebrick'),
                    overlaying='y',
                    side='right'
                ),
                yaxis3=dict(
                    title=dict(text='ì¬í•™ìŠµ ê±´ìˆ˜', font=dict(color='gray')),
                    tickfont=dict(color='gray'),
                    overlaying='y',
                    side='right',
                    position=0.85
                ),
                showlegend=True,
                height=500
            )
            
            st.plotly_chart(fig, width='stretch')
            
            # ìš”ì•½ í†µê³„
            if len(df_history) > 1:
                st.markdown("### ğŸ“Š ì„±ëŠ¥ ìš”ì•½")
                
                # ìµœê·¼ 2ê°œì›” ë¹„êµ
                latest = df_history.iloc[0]
                prev = df_history.iloc[1]
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    wmape_change = latest['wmape'] - prev['wmape']
                    st.metric(
                        "WMAPE ë³€í™”",
                        f"{latest['wmape']:.1f}%",
                        f"{wmape_change:+.1f}%",
                        delta_color="inverse"
                    )
                
                with col2:
                    mae_change = latest['mae'] - prev['mae']
                    st.metric(
                        "MAE ë³€í™”",
                        f"{latest['mae']:.2f}",
                        f"{mae_change:+.2f}",
                        delta_color="inverse"
                    )
                
                with col3:
                    retrain_change = latest['n_retrain'] - prev['n_retrain']
                    st.metric(
                        "ì¬í•™ìŠµ ê±´ìˆ˜ ë³€í™”",
                        f"{latest['n_retrain']}ê±´",
                        f"{retrain_change:+d}ê±´",
                        delta_color="inverse"
                    )
    
    if incremental_dir.exists():
        month_dirs = [d for d in incremental_dir.iterdir() if d.is_dir()]
        
        if month_dirs:
            st.subheader(f"ì²˜ë¦¬ëœ ì›”: {len(month_dirs)}ê°œ")
            
            # ì›”ë³„ ìš”ì•½ ë¡œë“œ
            summaries = []
            for month_dir in sorted(month_dirs):
                summary_files = list(month_dir.glob("summary_*.json"))
                if summary_files:
                    with open(summary_files[0], 'r', encoding='utf-8') as f:
                        summary = json.load(f)
                        summaries.append(summary)
            
            if summaries:
                df_summary = pd.DataFrame(summaries)
                
                # ì›”ë³„ íŠ¸ë Œë“œ
                if 'year' in df_summary.columns and 'month' in df_summary.columns:
                    df_summary['month_key'] = df_summary['year'].astype(str) + '-' + df_summary['month'].astype(str).str.zfill(2)
                    df_summary = df_summary.sort_values('month_key')
                    
                    st.line_chart(df_summary.set_index('month_key')[['total_records', 'series_count']])
                
                # ì „ì²´ í†µê³„
                st.dataframe(df_summary, width='stretch')
        else:
            st.info("ì²˜ë¦¬ëœ ì›”ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì¦ë¶„í•™ìŠµ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

# í‘¸í„°
st.markdown("---")
st.caption("CJ Quality-Cycles - ì›”ë³„ ì¦ë¶„í•™ìŠµ ì‹œìŠ¤í…œ v1.0")
