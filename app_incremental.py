"""
Streamlit ì›”ë³„ ì¦ë¶„í•™ìŠµ UI
ì›”ë³„ ë°ì´í„° ì—…ë¡œë“œ â†’ Lag í•„í„°ë§ â†’ ì˜ˆì¸¡ ë¹„êµ â†’ ì¬í•™ìŠµ
"""
import streamlit as st
import pandas as pd
import numpy as np
import subprocess
import json
from pathlib import Path
from datetime import datetime
import sys

st.set_page_config(page_title="í’ˆì§ˆ í´ë ˆì„ ê´€ë¦¬ ì‹œìŠ¤í…œ", layout="wide", page_icon="ğŸ“Š")

st.title("ğŸ“Š í’ˆì§ˆ í´ë ˆì„ ì˜ˆì¸¡ ê´€ë¦¬ ì‹œìŠ¤í…œ")
st.markdown("**ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ | ì›”ë³„ ë°ì´í„° ì—…ë¡œë“œ | ì¦ë¶„í•™ìŠµ | Reconcile ë³´ì •**")

# ì‚¬ì´ë“œë°” - ì„¤ì •
st.sidebar.header("âš™ï¸ ì„¤ì •")

# ì—°ë„/ì›” ì„ íƒ
current_year = datetime.now().year
selected_year = st.sidebar.selectbox("ì—°ë„", range(2024, current_year + 2))
selected_month = st.sidebar.selectbox("ì›”", range(1, 13))
month_key = f"{selected_year}-{selected_month:02d}"

st.sidebar.markdown("---")
st.sidebar.info(f"**ëŒ€ìƒ ì›”:** {month_key}")

# Lag í†µê³„ íŒŒì¼ í™•ì¸
lag_stats_path = Path("artifacts/metrics/lag_stats_from_raw.csv")
if lag_stats_path.exists():
    st.sidebar.success(f"âœ… Lag í†µê³„ íŒŒì¼ ì¡´ì¬")
    lag_stats = pd.read_csv(lag_stats_path)
    st.sidebar.caption(f"ì œí’ˆë²”ì£¼2: {len(lag_stats):,}ê°œ")
else:
    st.sidebar.error("âŒ Lag í†µê³„ íŒŒì¼ ì—†ìŒ")
    st.error("lag_stats_from_raw.csv íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤. tools/lag_analyzer.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    st.stop()

# ë©”ì¸ ì˜ì—­
tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ”® ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ", "ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ", "ğŸ“ˆ ì²˜ë¦¬ ê²°ê³¼", "ğŸ”§ Reconcile ë³´ì •", "ğŸ“Š í†µê³„"])

# Tab 1: ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ
with tab1:
    st.header("ğŸ”® í•™ìŠµëœ ëª¨ë¸ ê¸°ë°˜ ì˜ˆì¸¡")
    st.markdown("**í˜„ì¬ í•™ìŠµëœ ëª¨ë¸ë¡œ í–¥í›„ 6ê°œì›” í´ë ˆì„ ì˜ˆì¸¡**")
    
    # ëª¨ë¸ ë° ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸
    models_dir = Path("artifacts/models/base_2021_2023")
    features_dir = Path("data/features")
    
    if not models_dir.exists() or not features_dir.exists():
        st.warning("âš ï¸ í•™ìŠµëœ ëª¨ë¸ ë˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.info("ë¨¼ì € Base í•™ìŠµì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        st.code("python batch.py train --mode base --workers 4", language="bash")
    else:
        # ëª¨ë¸ íŒŒì¼ ê°œìˆ˜ í™•ì¸
        model_files = list(models_dir.glob("*.pkl"))
        
        if not model_files:
            st.error("âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.success(f"âœ… {len(model_files)}ê°œì˜ í•™ìŠµëœ ì‹œë¦¬ì¦ˆ ëª¨ë¸ ë°œê²¬")
            
            # ì‹œë¦¬ì¦ˆ ë©”íƒ€ë°ì´í„° ë¡œë“œ
            @st.cache_data
            def load_series_metadata():
                """ëª¨ë“  ì‹œë¦¬ì¦ˆì˜ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
                metadata = []
                
                for json_file in features_dir.glob("*.json"):
                    if json_file.name == "_summary.json":
                        continue
                        
                    try:
                        with open(json_file, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        
                        # JSON êµ¬ì¡°: {series_id, plant, product_cat2, mid_category, data: [{year, week, claim_count, ...}]}
                        data_records = data.get('data', [])
                        
                        if data_records:
                            last_record = data_records[-1]
                            last_week = f"{last_record['year']}-W{last_record['week']:02d}"
                        else:
                            last_week = None
                        
                        metadata.append({
                            'plant': data.get('plant', 'Unknown'),
                            'product_cat2': data.get('product_cat2', 'Unknown'),
                            'mid_category': data.get('mid_category', 'Unknown'),
                            'series_id': data.get('series_id', 'Unknown'),
                            'total_records': len(data_records),
                            'last_week': last_week,
                            'json_file': str(json_file)
                        })
                    except Exception as e:
                        continue
                
                return pd.DataFrame(metadata)
            
            metadata_df = load_series_metadata()
            
            if metadata_df.empty:
                st.warning("âš ï¸ ì‹œë¦¬ì¦ˆ ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # Base ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸
                if models_dir.exists() and len(list(models_dir.glob("*.pkl"))) > 0:
                    model_count = len(list(models_dir.glob("*.pkl")))
                    st.success(f"âœ… Base ëª¨ë¸ ë°œê²¬: {model_count:,}ê°œ")
                    
                    st.info("**ë©”íƒ€ë°ì´í„° ìƒì„± ë°©ë²•:**")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("**1ï¸âƒ£ ìˆ˜ë™ ìƒì„± (í„°ë¯¸ë„)**")
                        st.code("python generate_series_json.py", language="bash")
                        st.caption("ëª¨ë“  ì‹œë¦¬ì¦ˆì˜ ë©”íƒ€ë°ì´í„°ë¥¼ í•œë²ˆì— ìƒì„±")
                    
                    with col2:
                        st.markdown("**2ï¸âƒ£ ìë™ ìƒì„± (ê¶Œì¥)**")
                        st.markdown("ğŸ‘‰ `ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ` íƒ­ìœ¼ë¡œ ì´ë™")
                        st.caption("ì›”ë³„ ë°ì´í„° ì—…ë¡œë“œ ì‹œ ìë™ìœ¼ë¡œ ìƒì„±ë¨")
                else:
                    st.info("**ë¨¼ì € Base í•™ìŠµì„ ì‹¤í–‰í•˜ì„¸ìš”:**")
                    st.code("python batch.py train --mode base --workers 4", language="bash")
                    st.caption("2021-2023 ë°ì´í„°ë¡œ Base ëª¨ë¸ í•™ìŠµ")
            else:
                st.subheader("ğŸ¯ ì˜ˆì¸¡ ì‹œë¦¬ì¦ˆ ì„ íƒ")
                
                # Top 5 EWS ìœ„í—˜ ì‹œë¦¬ì¦ˆ ê³„ì‚°
                st.markdown("### ï¿½ EWS ìœ„í—˜ë„ Top 5")
                st.caption("ëª¨ë¸ ì˜ˆì¸¡ ê¸°ë°˜: ì˜ˆì¸¡ í™•ì‹¤ë„ Ã— EWS ì„ê³„ê°’ ê·¼ì ‘ë„")
                
                with st.spinner("Top 5 ìœ„í—˜ ì‹œë¦¬ì¦ˆ ë¶„ì„ ì¤‘..."):
                    ews_candidates = []
                    models_dir = Path("artifacts/models")
                    
                    # ë””ë²„ê¹… ì •ë³´
                    total_series = len(metadata_df)
                    processed = 0
                    skipped_no_data = 0
                    skipped_no_model = 0
                    skipped_low_ratio = 0
                    errors = 0
                    
                    # ì„¤ì •
                    FORECAST_WEEKS = 4  # 4ì£¼ ì˜ˆì¸¡
                    EWS_THRESHOLD_MULTIPLIER = 1.5  # ê³¼ê±° í‰ê· ì˜ 1.5ë°° ì´ìƒì´ë©´ ê²½ê³ 
                    
                    for idx, row in metadata_df.iterrows():
                        try:
                            # JSON ë°ì´í„° ë¡œë“œ
                            with open(row['json_file'], 'r', encoding='utf-8') as f:
                                json_data = json.load(f)
                            
                            data_records = json_data.get('data', [])
                            if len(data_records) < 52:  # ìµœì†Œ 1ë…„ ë°ì´í„° í•„ìš”
                                skipped_no_data += 1
                                continue
                            
                            # ëª¨ë¸ íŒŒì¼ ë¡œë“œ
                            series_id = row['series_id']
                            safe_filename = (series_id.replace('/', '_').replace('\\', '_').replace(':', '_')
                                           .replace('|', '_').replace('?', '_').replace('*', '_')
                                           .replace('<', '_').replace('>', '_').replace('"', '_'))
                            model_path = models_dir / f"{safe_filename}.pkl"
                            
                            if not model_path.exists():
                                skipped_no_model += 1
                                continue
                            
                            # ëª¨ë¸ ë¡œë“œ
                            import pickle
                            with open(model_path, 'rb') as f:
                                model_result = pickle.load(f)
                            
                            if isinstance(model_result, dict):
                                fitted_model = model_result.get('model')
                            else:
                                fitted_model = model_result
                            
                            if fitted_model is None:
                                skipped_no_model += 1
                                continue
                            
                            # ì˜ˆì¸¡ ìƒì„± (4ì£¼)
                            forecast_obj = fitted_model.get_forecast(steps=FORECAST_WEEKS)
                            forecast_mean = forecast_obj.predicted_mean
                            forecast_ci_obj = forecast_obj.conf_int(alpha=0.05)  # 95% ì‹ ë¢°êµ¬ê°„
                            
                            # ì˜ˆì¸¡ê°’ ë° ì‹ ë¢°êµ¬ê°„
                            yhat_values = forecast_mean if isinstance(forecast_mean, np.ndarray) else forecast_mean.values
                            yhat_lower = forecast_ci_obj.iloc[:, 0].values if hasattr(forecast_ci_obj, 'iloc') else forecast_ci_obj[:, 0]
                            yhat_upper = forecast_ci_obj.iloc[:, 1].values if hasattr(forecast_ci_obj, 'iloc') else forecast_ci_obj[:, 1]
                            
                            # ìŒìˆ˜ ì²˜ë¦¬
                            yhat_values = np.maximum(yhat_values, 0)
                            yhat_lower = np.maximum(yhat_lower, 0)
                            yhat_upper = np.maximum(yhat_upper, 0)
                            
                            # ì˜ˆì¸¡ í‰ê· 
                            forecast_avg = yhat_values.mean()
                            
                            # ê³¼ê±° í‰ê·  (ìµœê·¼ 26ì£¼)
                            recent_data = data_records[-26:] if len(data_records) >= 26 else data_records
                            historical_avg = sum(r['claim_count'] for r in recent_data) / len(recent_data)
                            
                            # 1. ì˜ˆì¸¡ í™•ì‹¤ë„ (Prediction Confidence)
                            # ì‹ ë¢°êµ¬ê°„ í­ì˜ ì—­ìˆ˜ (ì¢ì„ìˆ˜ë¡ í™•ì‹¤)
                            ci_width = (yhat_upper - yhat_lower).mean()
                            if ci_width > 0 and forecast_avg > 0:
                                confidence_score = 1 / (1 + ci_width / (forecast_avg + 0.1))  # 0~1 ì‚¬ì´
                            else:
                                confidence_score = 0
                            
                            # 2. EWS Score (Early Warning Score)
                            # ì˜ˆì¸¡ê°’ì´ ê³¼ê±° í‰ê·  ëŒ€ë¹„ ì–¼ë§ˆë‚˜ ë†’ì€ì§€
                            if historical_avg > 0:
                                ews_ratio = forecast_avg / historical_avg
                                # EWS ì„ê³„ê°’(1.5ë°°) ê·¼ì ‘ë„
                                ews_proximity = abs(ews_ratio - EWS_THRESHOLD_MULTIPLIER) / EWS_THRESHOLD_MULTIPLIER
                                ews_score = 1 / (1 + ews_proximity)  # ì„ê³„ê°’ì— ê°€ê¹Œìš¸ìˆ˜ë¡ 1
                            else:
                                ews_ratio = 0
                                ews_score = 0
                            
                            # 3. ì¢…í•© ìœ„í—˜ë„ ì ìˆ˜
                            # ì˜ˆì¸¡ì´ í™•ì‹¤í•˜ê³ (confidence_score ë†’ìŒ) + EWS ì„ê³„ê°’ì— ê°€ê¹Œì›€(ews_score ë†’ìŒ)
                            risk_score = confidence_score * ews_score * (1 + ews_ratio * 0.1)  # ì˜ˆì¸¡ê°’ë„ ë°˜ì˜
                            
                            # ì˜ˆì¸¡ê°’ì´ ì„ê³„ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´ ì œì™¸
                            if ews_ratio < 1.0:
                                skipped_low_ratio += 1
                                continue
                            
                            processed += 1
                            
                            ews_candidates.append({
                                'series_id': series_id,
                                'plant': row['plant'],
                                'product_cat2': row['product_cat2'],
                                'mid_category': row['mid_category'],
                                'forecast_avg': forecast_avg,
                                'historical_avg': historical_avg,
                                'ews_ratio': ews_ratio,
                                'confidence_score': confidence_score,
                                'ews_score': ews_score,
                                'risk_score': risk_score,
                                'json_file': row['json_file']
                            })
                        except Exception as e:
                            errors += 1
                            continue
                    
                    # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
                    with st.expander("ğŸ” ë¶„ì„ ìƒì„¸ ì •ë³´"):
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("ì´ ì‹œë¦¬ì¦ˆ", total_series)
                        with col2:
                            st.metric("ì„±ê³µ", processed)
                        with col3:
                            st.metric("ë°ì´í„° ë¶€ì¡±", skipped_no_data)
                        with col4:
                            st.metric("ëª¨ë¸ ì—†ìŒ", skipped_no_model)
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("EWS < 1.0", skipped_low_ratio)
                        with col2:
                            st.metric("ì—ëŸ¬", errors)
                        with col3:
                            st.metric("í›„ë³´", len(ews_candidates))
                    
                    if ews_candidates:
                        top_df = pd.DataFrame(ews_candidates).sort_values('risk_score', ascending=False).head(5)
                        
                        # í…Œì´ë¸” í‘œì‹œ
                        display_top = top_df[['plant', 'product_cat2', 'mid_category', 'forecast_avg', 'historical_avg', 'ews_ratio', 'risk_score']].copy()
                        display_top.columns = ['í”ŒëœíŠ¸', 'ì œí’ˆë²”ì£¼2', 'ì¤‘ë¶„ë¥˜', '4ì£¼ ì˜ˆì¸¡ í‰ê· ', 'ê³¼ê±° í‰ê· ', 'EWS ë¹„ìœ¨', 'ìœ„í—˜ë„']
                        display_top['4ì£¼ ì˜ˆì¸¡ í‰ê· '] = display_top['4ì£¼ ì˜ˆì¸¡ í‰ê· '].round(2)
                        display_top['ê³¼ê±° í‰ê· '] = display_top['ê³¼ê±° í‰ê· '].round(2)
                        display_top['EWS ë¹„ìœ¨'] = display_top['EWS ë¹„ìœ¨'].round(2)
                        display_top['ìœ„í—˜ë„'] = display_top['ìœ„í—˜ë„'].round(3)
                        
                        st.dataframe(display_top, use_container_width=True, hide_index=True)
                        
                        st.caption("**ìœ„í—˜ë„**: ì˜ˆì¸¡ í™•ì‹¤ë„ Ã— EWS ì„ê³„ê°’ ê·¼ì ‘ë„ (ë†’ì„ìˆ˜ë¡ ìœ„í—˜)")
                        st.caption("**EWS ë¹„ìœ¨**: ì˜ˆì¸¡ê°’ / ê³¼ê±° í‰ê·  (1.5ë°° ì´ìƒì´ë©´ ê²½ê³ )")
                    else:
                        st.info("EWS ìœ„í—˜ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                st.markdown("---")
                
                # ì‹œë¦¬ì¦ˆ ì„ íƒ UI - ê³„ì¸µì  í•„í„°ë§
                st.markdown("### ğŸ” ì‹œë¦¬ì¦ˆ ê²€ìƒ‰ ë° ì„ íƒ")
                
                col1, col2, col3 = st.columns(3)
                
                # 1ë‹¨ê³„: í”ŒëœíŠ¸ ì„ íƒ
                with col1:
                    plants = sorted(metadata_df['plant'].unique().tolist())
                    selected_plant = st.selectbox("í”ŒëœíŠ¸", plants, key="forecast_plant")
                
                # í”ŒëœíŠ¸ í•„í„°ë§ ì ìš©
                filtered_by_plant = metadata_df[metadata_df['plant'] == selected_plant]
                
                # 2ë‹¨ê³„: ì œí’ˆë²”ì£¼2 ì„ íƒ
                with col2:
                    categories = sorted(filtered_by_plant['product_cat2'].unique().tolist())
                    selected_category = st.selectbox("ì œí’ˆë²”ì£¼2", categories, key="forecast_cat2")
                
                # ì œí’ˆë²”ì£¼2 í•„í„°ë§ ì ìš©
                filtered_by_cat2 = filtered_by_plant[filtered_by_plant['product_cat2'] == selected_category]
                
                # 3ë‹¨ê³„: ì¤‘ë¶„ë¥˜ ì„ íƒ
                with col3:
                    mid_categories = sorted(filtered_by_cat2['mid_category'].unique().tolist())
                    selected_mid = st.selectbox("ì¤‘ë¶„ë¥˜", mid_categories, key="forecast_mid")
                
                # ìµœì¢… í•„í„°ë§
                final_filtered = filtered_by_cat2[filtered_by_cat2['mid_category'] == selected_mid]
                
                # ì‹œë¦¬ì¦ˆê°€ ì„ íƒë˜ì—ˆëŠ”ì§€ í™•ì¸
                if len(final_filtered) > 0:
                    series_info = final_filtered.iloc[0]
                    series_id = series_info['series_id']
                    
                    st.info(f"âœ… ì„ íƒëœ ì‹œë¦¬ì¦ˆ: **{series_id}**")
                    
                    # ì˜ˆì¸¡ ì„¤ì •
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        horizon_weeks = st.slider("ì˜ˆì¸¡ ê¸°ê°„ (ì£¼)", 4, 26, 24, help="6ê°œì›” = 24ì£¼", key="horizon")
                    with col2:
                        ci_choice = st.selectbox("ì‹ ë¢°êµ¬ê°„", ["95%", "99%"], index=0, key="ci")
                        ci = 0.99 if ci_choice == "99%" else 0.95
                        
                        # ì˜ˆì¸¡ ì‹¤í–‰
                        if st.button("ğŸ”® ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
                            with st.spinner(f"{series_id} ì˜ˆì¸¡ ì¤‘..."):
                                try:
                                    # JSON ë°ì´í„° ë¡œë“œ
                                    import pickle
                                    from datetime import timedelta
                                    import plotly.graph_objects as go
                                    
                                    with open(series_info['json_file'], 'r', encoding='utf-8') as f:
                                        json_data = json.load(f)
                                    
                                    # JSON êµ¬ì¡°: data = [{year, week, claim_count, ...}]
                                    data_records = json_data.get('data', [])
                                    
                                    if not data_records:
                                        st.error(f"ì‹œë¦¬ì¦ˆ {series_id}ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                    else:
                                        # DataFrame ìƒì„±
                                        df_hist = pd.DataFrame(data_records)
                                        df_hist['week_date'] = pd.to_datetime(
                                            df_hist['year'].astype(str) + '-W' + df_hist['week'].astype(str).str.zfill(2) + '-1',
                                            format='%Y-W%W-%w'
                                        )
                                        df_hist = df_hist.rename(columns={'claim_count': 'y'})
                                        df_hist = df_hist.sort_values('week_date')
                                        df_hist = df_hist.sort_values('week_date')
                                        
                                        # ëª¨ë¸ íŒŒì¼ ë¡œë“œ
                                        # series_idì—ì„œ | êµ¬ë¶„ìë¡œ íŒŒì¼ëª… ìƒì„±
                                        safe_filename = (series_id.replace('/', '_').replace('\\', '_').replace(':', '_')
                                                       .replace('|', '_').replace('?', '_').replace('*', '_')
                                                       .replace('<', '_').replace('>', '_').replace('"', '_'))
                                        model_path = models_dir / f"{safe_filename}.pkl"
                                        
                                        st.info(f"ğŸ” ì°¾ëŠ” ëª¨ë¸ íŒŒì¼: `{model_path.name}`")
                                        
                                        if model_path.exists():
                                            with open(model_path, 'rb') as f:
                                                model_result = pickle.load(f)
                                            
                                            # ëª¨ë¸ì—ì„œ í•™ìŠµëœ ëª¨ë¸ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
                                            if isinstance(model_result, dict):
                                                fitted_model = model_result.get('model')
                                            else:
                                                fitted_model = model_result
                                            
                                            # ì˜ˆì¸¡ ìƒì„±
                                            forecast_obj = fitted_model.get_forecast(steps=horizon_weeks)
                                            forecast_mean = forecast_obj.predicted_mean
                                            forecast_ci_obj = forecast_obj.conf_int(alpha=1-ci)
                                            
                                            # ë§ˆì§€ë§‰ ì£¼ì°¨ ì´í›„ ë‚ ì§œ ìƒì„±
                                            last_week = df_hist['week_date'].iloc[-1]
                                            future_weeks = [last_week + timedelta(weeks=i+1) for i in range(horizon_weeks)]
                                            
                                            # numpy arrayë¥¼ í™•ì¸í•˜ê³  ì ì ˆíˆ ë³€í™˜
                                            yhat_values = forecast_mean if isinstance(forecast_mean, np.ndarray) else forecast_mean.values
                                            yhat_lower_values = forecast_ci_obj.iloc[:, 0].values if hasattr(forecast_ci_obj, 'iloc') else forecast_ci_obj[:, 0]
                                            yhat_upper_values = forecast_ci_obj.iloc[:, 1].values if hasattr(forecast_ci_obj, 'iloc') else forecast_ci_obj[:, 1]
                                            
                                            # ì‹ ë¢°êµ¬ê°„ ìŒìˆ˜ ì²˜ë¦¬ (í´ë ˆì„ì€ ìŒìˆ˜ê°€ ë  ìˆ˜ ì—†ìŒ)
                                            yhat_lower_values = np.maximum(yhat_lower_values, 0)
                                            yhat_values = np.maximum(yhat_values, 0)
                                            yhat_upper_values = np.maximum(yhat_upper_values, 0)
                                            
                                            df_forecast = pd.DataFrame({
                                                'week': future_weeks,
                                                'yhat': yhat_values,
                                                'yhat_lower': yhat_lower_values,
                                                'yhat_upper': yhat_upper_values
                                            })
                                            
                                            # ë©”íŠ¸ë¦­ í‘œì‹œ
                                            col1, col2, col3, col4 = st.columns(4)
                                            with col1:
                                                st.metric("í•™ìŠµ ë°ì´í„°", f"{len(df_hist)}ì£¼")
                                            with col2:
                                                avg_claims = df_hist['y'].mean()
                                                st.metric("í‰ê·  í´ë ˆì„", f"{avg_claims:.1f}ê±´/ì£¼")
                                            with col3:
                                                last_claim = df_hist['y'].iloc[-1]
                                                st.metric("ìµœê·¼ í´ë ˆì„", f"{last_claim:.0f}ê±´")
                                            with col4:
                                                forecast_avg = df_forecast['yhat'].mean()
                                                change = ((forecast_avg - avg_claims) / avg_claims * 100) if avg_claims > 0 else 0
                                                st.metric("ì˜ˆì¸¡ í‰ê· ", f"{forecast_avg:.1f}ê±´", f"{change:+.1f}%")
                                            
                                            # ì°¨íŠ¸ ìƒì„±
                                            st.subheader("ğŸ“ˆ ì˜ˆì¸¡ ì°¨íŠ¸")
                                            
                                            fig = go.Figure()
                                            
                                            # ê³¼ê±° ë°ì´í„°
                                            fig.add_trace(go.Scatter(
                                                x=df_hist['week_date'],
                                                y=df_hist['y'],
                                                mode='lines+markers',
                                                name='ì‹¤ì œ ë°ì´í„°',
                                                line=dict(color='#1f77b4', width=2),
                                                marker=dict(size=4)
                                            ))
                                            
                                            # ì˜ˆì¸¡ê°’
                                            fig.add_trace(go.Scatter(
                                                x=df_forecast['week'],
                                                y=df_forecast['yhat'],
                                                mode='lines+markers',
                                                name='ì˜ˆì¸¡',
                                                line=dict(color='#ff7f0e', width=2, dash='dash'),
                                                marker=dict(size=6)
                                            ))
                                            
                                            # ì‹ ë¢°êµ¬ê°„
                                            fig.add_trace(go.Scatter(
                                                x=df_forecast['week'].tolist() + df_forecast['week'].tolist()[::-1],
                                                y=df_forecast['yhat_upper'].tolist() + df_forecast['yhat_lower'].tolist()[::-1],
                                                fill='toself',
                                                fillcolor='rgba(255, 127, 14, 0.2)',
                                                line=dict(color='rgba(255,255,255,0)'),
                                                name=f'{ci_choice} ì‹ ë¢°êµ¬ê°„',
                                                showlegend=True
                                            ))
                                            
                                            fig.update_layout(
                                                title=f"{series_id} - {horizon_weeks}ì£¼ ì˜ˆì¸¡",
                                                xaxis_title="ì£¼ì°¨",
                                                yaxis_title="í´ë ˆì„ ê±´ìˆ˜",
                                                hovermode='x unified',
                                                height=500,
                                                yaxis=dict(dtick=1),  # Yì¶• ì •ìˆ˜ ë‹¨ìœ„
                                                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                                            )
                                            
                                            st.plotly_chart(fig, width='stretch')
                                            
                                            # ì˜ˆì¸¡ í…Œì´ë¸”
                                            st.subheader("ğŸ“‹ ì˜ˆì¸¡ ìƒì„¸")
                                            
                                            df_forecast_display = df_forecast.copy()
                                            df_forecast_display['week'] = df_forecast_display['week'].dt.strftime('%Y-%m-%d')
                                            df_forecast_display['yhat'] = df_forecast_display['yhat'].round(1)
                                            df_forecast_display['yhat_lower'] = df_forecast_display['yhat_lower'].round(1)
                                            df_forecast_display['yhat_upper'] = df_forecast_display['yhat_upper'].round(1)
                                            df_forecast_display.columns = ['ì£¼ì°¨', 'ì˜ˆì¸¡ê°’', 'í•˜í•œ', 'ìƒí•œ']
                                            
                                            st.dataframe(df_forecast_display, width='stretch', hide_index=True)
                                            
                                            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                                            csv = df_forecast.to_csv(index=False, encoding='utf-8-sig')
                                            st.download_button(
                                                label="ğŸ“¥ ì˜ˆì¸¡ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                                                data=csv,
                                                file_name=f"forecast_{series_id}_{datetime.now().strftime('%Y%m%d')}.csv",
                                                mime="text/csv"
                                            )
                                        
                                        else:
                                            st.error(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {safe_filename}.pkl")
                                
                                except Exception as e:
                                    st.error(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
                                    st.exception(e)

# Tab 2: ë°ì´í„° ì—…ë¡œë“œ
with tab2:
    st.header("1ï¸âƒ£ ì›”ë³„ ë°ì´í„° ì—…ë¡œë“œ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        uploaded_file = st.file_uploader(
            f"**{month_key} ì›”ë³„ ë°ì´í„° CSV ì—…ë¡œë“œ**",
            type=['csv'],
            help="ë°œìƒì¼ì ê¸°ì¤€ 1ê°œì›” ë°ì´í„° (í”ŒëœíŠ¸, ì œí’ˆë²”ì£¼2, ì¤‘ë¶„ë¥˜(ë³´ì •), ë°œìƒì¼ì, ì œì¡°ì¼ì, count ì»¬ëŸ¼ í•„ìˆ˜)"
        )
    
    with col2:
        st.markdown("**í•„ìˆ˜ ì»¬ëŸ¼**")
        st.code("""
í”ŒëœíŠ¸
ì œí’ˆë²”ì£¼2
ì¤‘ë¶„ë¥˜(ë³´ì •)
ë°œìƒì¼ì
ì œì¡°ì¼ì
count
        """, language="text")
    
    if uploaded_file is not None:
        # ì„ì‹œ ì €ì¥
        temp_dir = Path("artifacts/temp")
        temp_dir.mkdir(parents=True, exist_ok=True)
        temp_path = temp_dir / f"upload_{month_key.replace('-', '')}.csv"
        
        with open(temp_path, 'wb') as f:
            f.write(uploaded_file.getvalue())
        
        # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
        st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
        
        try:
            df_preview = pd.read_csv(temp_path, encoding='utf-8-sig', nrows=10)
            st.subheader("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            st.dataframe(df_preview, width='stretch')
            
            # ì „ì²´ ë°ì´í„° í†µê³„
            df_full = pd.read_csv(temp_path, encoding='utf-8-sig')
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ì´ ë ˆì½”ë“œ", f"{len(df_full):,}ê±´")
            with col2:
                st.metric("ì‹œë¦¬ì¦ˆ ìˆ˜", f"{df_full.groupby(['í”ŒëœíŠ¸', 'ì œí’ˆë²”ì£¼2', 'ì¤‘ë¶„ë¥˜(ë³´ì •)']).ngroups:,}ê°œ")
            with col3:
                if 'ë°œìƒì¼ì' in df_full.columns:
                    df_full['ë°œìƒì¼ì'] = pd.to_datetime(df_full['ë°œìƒì¼ì'])
                    date_range = f"{df_full['ë°œìƒì¼ì'].min().date()} ~ {df_full['ë°œìƒì¼ì'].max().date()}"
                    st.metric("ë°œìƒì¼ì ë²”ìœ„", date_range)
            with col4:
                if 'count' in df_full.columns:
                    st.metric("ì´ í´ë ˆì„ ê±´ìˆ˜", f"{df_full['count'].sum():,}ê±´")
            
            st.markdown("---")
            
            # ì²˜ë¦¬ ë²„íŠ¼
            st.subheader("2ï¸âƒ£ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
            
            col1, col2, col3 = st.columns([1, 1, 2])
            
            with col1:
                run_pipeline = st.button("ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰", type="primary", width='stretch')
            
            with col2:
                show_command = st.checkbox("ëª…ë ¹ì–´ í‘œì‹œ", value=False)
            
            if show_command:
                with col3:
                    st.code(f"python batch.py process --upload {temp_path} --month {month_key}", language="bash")
            
            if run_pipeline:
                st.markdown("---")
                st.subheader("â³ ì²˜ë¦¬ ì¤‘...")
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                status_text = st.empty()
                
                # ë¡œê·¸ ì¶œë ¥ ì»¨í…Œì´ë„ˆ
                log_container = st.expander("ğŸ” ì‹¤ì‹œê°„ ë¡œê·¸", expanded=True)
                log_output = log_container.empty()
                
                try:
                    # batch.py process ì‹¤í–‰
                    status_text.info("ğŸ”„ íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
                    
                    cmd = [
                        sys.executable, "batch.py", "process",
                        "--upload", str(temp_path),
                        "--month", month_key
                    ]
                    
                    log_container.code(f"ì‹¤í–‰: {' '.join(cmd)}", language="bash")
                    
                    # ì‹¤ì‹œê°„ ì¶œë ¥ì„ ìœ„í•œ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
                    import io
                    process = subprocess.Popen(
                        cmd,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.STDOUT,
                        text=True,
                        cwd=Path.cwd(),
                        bufsize=1,
                        universal_newlines=True
                    )
                    
                    # ì‹¤ì‹œê°„ ë¡œê·¸ ìˆ˜ì§‘
                    output_lines = []
                    for line in iter(process.stdout.readline, ''):
                        if line:
                            output_lines.append(line.rstrip())
                            # ë§ˆì§€ë§‰ 50ì¤„ë§Œ í‘œì‹œ
                            display_lines = output_lines[-50:]
                            log_output.code('\n'.join(display_lines), language="text")
                            
                            # ìƒíƒœ ì—…ë°ì´íŠ¸
                            if "Step 1" in line or "Lag í•„í„°ë§" in line:
                                status_text.info("ğŸ”„ Step 1/4: Lag í•„í„°ë§ ì¤‘...")
                            elif "Step 2" in line or "ì£¼ê°„ ì§‘ê³„" in line:
                                status_text.info("ğŸ”„ Step 2/4: ì£¼ê°„ ì§‘ê³„ ë° JSON ì—…ë°ì´íŠ¸ ì¤‘...")
                            elif "Step 3" in line or "ì˜ˆì¸¡ ë¹„êµ" in line:
                                status_text.info("ğŸ”„ Step 3/4: ì˜ˆì¸¡ vs ì‹¤ì œ ë¹„êµ ì¤‘...")
                            elif "Step 4" in line or "ì¬í•™ìŠµ" in line:
                                status_text.info("ğŸ”„ Step 4/4: ëª¨ë¸ ì¬í•™ìŠµ ì¤‘...")
                    
                    process.wait()
                    result_code = process.returncode
                    
                    if result_code == 0:
                        status_text.success("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
                        st.success("ğŸ‰ ì›”ë³„ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì™„ë£Œ!")
                        
                        # ê²°ê³¼ í‘œì‹œ
                        month_dir = Path(f"artifacts/incremental/{selected_year}{selected_month:02d}")
                        summary_file = month_dir / f"summary_{selected_year}{selected_month:02d}.json"
                        
                        if summary_file.exists():
                            with open(summary_file, 'r', encoding='utf-8') as f:
                                summary = json.load(f)
                            
                            st.subheader("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("ì´ ë ˆì½”ë“œ", f"{summary.get('total_records', 0):,}ê±´")
                            with col2:
                                st.metric("ì‹œë¦¬ì¦ˆ ìˆ˜", f"{summary.get('series_count', 0):,}ê°œ")
                            with col3:
                                if summary.get('mean_error') is not None:
                                    st.metric("í‰ê·  ì˜¤ì°¨", f"{summary['mean_error']:.2f}")
                            with col4:
                                if summary.get('mae') is not None:
                                    st.metric("MAE", f"{summary['mae']:.2f}")
                            
                            st.info(f"ì²˜ë¦¬ ì‹œê°„: {summary.get('processed_at', 'N/A')}")
                    else:
                        status_text.error("âŒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨")
                        st.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨ (exit code: {result_code})")
                        st.info("ğŸ’¡ ìœ„ì˜ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”.")
                
                except Exception as e:
                    status_text.error("âŒ ì˜¤ë¥˜ ë°œìƒ")
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                    import traceback
                    with log_container:
                        st.code(traceback.format_exc(), language="text")
        
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

# Tab 3: ì²˜ë¦¬ ê²°ê³¼
with tab3:
    st.header("ğŸ“ˆ ì²˜ë¦¬ ê²°ê³¼")
    
    # ì›”ë³„ ê²°ê³¼ ë””ë ‰í† ë¦¬
    month_dir = Path(f"artifacts/incremental/{selected_year}{selected_month:02d}")
    
    if month_dir.exists():
        st.success(f"âœ… {month_key} ì²˜ë¦¬ ê²°ê³¼ ì¡´ì¬")
        
        # íŒŒì¼ ëª©ë¡
        files = list(month_dir.glob("*"))
        
        if files:
            st.subheader("ğŸ“ ìƒì„±ëœ íŒŒì¼")
            
            for file in sorted(files):
                col1, col2, col3 = st.columns([3, 1, 1])
                with col1:
                    st.text(f"ğŸ“„ {file.name}")
                with col2:
                    st.caption(f"{file.stat().st_size / 1024:.1f} KB")
                with col3:
                    if file.suffix == '.csv':
                        if st.button(f"ë³´ê¸°", key=f"view_{file.name}"):
                            df = pd.read_csv(file, encoding='utf-8-sig')
                            st.dataframe(df.head(100), width='stretch')
                    elif file.suffix == '.json':
                        if st.button(f"ë³´ê¸°", key=f"view_{file.name}"):
                            with open(file, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                            st.json(data)
            
            # ì˜ˆì¸¡-ì‹¤ì¸¡ ë¹„êµ íŒŒì¼ ìˆìœ¼ë©´ ì‹œê°í™”
            predict_vs_actual = month_dir / f"predict_vs_actual_{selected_year}{selected_month:02d}.csv"
            if predict_vs_actual.exists():
                st.markdown("---")
                st.subheader("ğŸ“Š ì˜ˆì¸¡ vs ì‹¤ì¸¡ ë¹„êµ")
                
                df_compare = pd.read_csv(predict_vs_actual, encoding='utf-8-sig')
                
                # í†µê³„
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("í‰ê·  ì˜¤ì°¨", f"{df_compare['error'].mean():.2f}")
                with col2:
                    st.metric("ì ˆëŒ€ ì˜¤ì°¨ í‰ê· ", f"{df_compare['abs_error'].mean():.2f}")
                with col3:
                    st.metric("í¼ì„¼íŠ¸ ì˜¤ì°¨ í‰ê· ", f"{df_compare['pct_error'].mean():.2f}%")
                with col4:
                    st.metric("ë¹„êµ ë ˆì½”ë“œ", f"{len(df_compare):,}ê±´")
                
                # ìƒìœ„ ì˜¤ì°¨ ì‹œë¦¬ì¦ˆ
                st.markdown("**ìƒìœ„ ì˜¤ì°¨ ì‹œë¦¬ì¦ˆ (Top 10)**")
                top_errors = df_compare.nlargest(10, 'abs_error')[['series_id', 'week', 'claim_count', 'y_pred', 'error', 'abs_error']]
                st.dataframe(top_errors, width='stretch')
        else:
            st.info("íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info(f"{month_key} ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê³  íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# Tab 4: Reconcile ë³´ì •
with tab4:
    st.header("ğŸ”§ Reconcile ë³´ì •")
    
    month_dir = Path(f"artifacts/incremental/{selected_year}{selected_month:02d}")
    reconcile_dir = Path(f"artifacts/reconcile/{selected_year}{selected_month:02d}")
    
    # ì²˜ë¦¬ ê²°ê³¼ í™•ì¸
    predict_vs_actual = month_dir / f"predict_vs_actual_{selected_year}{selected_month:02d}.csv"
    
    if predict_vs_actual.exists():
        st.success(f"âœ… {month_key} ì²˜ë¦¬ ê²°ê³¼ ì¡´ì¬")
        
        # KPI í™•ì¸
        df_compare = pd.read_csv(predict_vs_actual, encoding='utf-8-sig')
        
        # MAPE ê³„ì‚°
        valid_mask = df_compare['claim_count'] > 0
        if valid_mask.sum() > 0:
            mape = (df_compare[valid_mask]['abs_error'] / df_compare[valid_mask]['claim_count']).mean()
        else:
            mape = np.nan
        
        # Bias ê³„ì‚°
        bias = df_compare['error'].mean() / df_compare['claim_count'].mean() if df_compare['claim_count'].mean() > 0 else np.nan
        
        st.subheader("ğŸ“Š í˜„ì¬ KPI")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            mape_pass = mape < 0.20 if not np.isnan(mape) else False
            st.metric("MAPE", f"{mape:.2%}", delta=f"ëª©í‘œ: <20%", delta_color="inverse" if not mape_pass else "normal")
        
        with col2:
            bias_pass = abs(bias) < 0.05 if not np.isnan(bias) else False
            st.metric("|Bias|", f"{abs(bias):.4f}", delta=f"ëª©í‘œ: <0.05", delta_color="inverse" if not bias_pass else "normal")
        
        with col3:
            st.metric("MAE", f"{df_compare['abs_error'].mean():.2f}")
        
        with col4:
            kpi_pass = mape_pass and bias_pass
            if kpi_pass:
                st.success("âœ… KPI í†µê³¼")
            else:
                st.error("âŒ KPI ë¯¸ë‹¬")
        
        st.markdown("---")
        
        # Reconcile ì‹¤í–‰
        st.subheader("ğŸš€ ë³´ì • ì‹¤í–‰")
        
        col1, col2, col3 = st.columns([1, 1, 2])
        
        with col1:
            stage = st.selectbox(
                "ë³´ì • ë‹¨ê³„",
                ['all', 'bias', 'seasonal', 'optuna'],
                index=0,
                help="all: ëª¨ë“  ë‹¨ê³„ ìˆœì°¨ ì‹¤í–‰, bias: Bias Mapë§Œ, seasonal: ê³„ì ˆì„± ì¬ì¶”ì •ë§Œ, optuna: Optuna íŠœë‹ë§Œ"
            )
        
        with col2:
            run_reconcile = st.button("ğŸ”§ Reconcile ì‹¤í–‰", type="primary", width='stretch')
        
        stage_descriptions = {
            'all': 'ëª¨ë“  ë‹¨ê³„ ìˆœì°¨ ì‹¤í–‰ (Bias Map â†’ Seasonal â†’ Optuna)',
            'bias': 'Stage 1: Bias Map - ì£¼ê°„ í‰ê·  ì˜¤ì°¨ ë³´ì •',
            'seasonal': 'Stage 2: Seasonal Recalibration - ìµœê·¼ 2ë…„ ê³„ì ˆì„± ì¬ì¶”ì •',
            'optuna': 'Stage 3: Optuna Tuning - í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”'
        }
        
        with col3:
            st.info(stage_descriptions[stage])
        
        if run_reconcile:
            st.markdown("---")
            st.subheader("â³ Reconcile ì‹¤í–‰ ì¤‘...")
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            log_container = st.expander("ğŸ” ìƒì„¸ ë¡œê·¸", expanded=True)
            
            try:
                status_text.text(f"ì‹¤í–‰ ì¤‘: {stage} ë‹¨ê³„...")
                progress_bar.progress(30)
                
                cmd = [
                    sys.executable, "reconcile_pipeline.py",
                    "--year", str(selected_year),
                    "--month", str(selected_month),
                    "--stage", stage
                ]
                
                with log_container:
                    st.code(f"ì‹¤í–‰: {' '.join(cmd)}", language="bash")
                
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    cwd=Path.cwd()
                )
                
                with log_container:
                    if result.stdout:
                        st.text("STDOUT:")
                        st.code(result.stdout, language="text")
                    if result.stderr:
                        st.text("STDERR:")
                        st.code(result.stderr, language="text")
                
                if result.returncode == 0:
                    progress_bar.progress(100)
                    status_text.text("âœ… ì™„ë£Œ!")
                    st.success("ğŸ‰ Reconcile ë³´ì • ì™„ë£Œ!")
                    
                    # ê²°ê³¼ í‘œì‹œ
                    summary_file = reconcile_dir / f"reconcile_summary_{selected_year}{selected_month:02d}.json"
                    
                    if summary_file.exists():
                        with open(summary_file, 'r', encoding='utf-8') as f:
                            summary = json.load(f)
                        
                        st.subheader("ğŸ“Š ë³´ì • ê²°ê³¼")
                        
                        # ì´ˆê¸° vs ìµœì¢… KPI
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown("**ì´ˆê¸° KPI**")
                            initial = summary['initial_kpi']
                            st.metric("MAPE", f"{initial.get('MAPE', 0):.2%}")
                            st.metric("|Bias|", f"{abs(initial.get('Bias', 0)):.4f}")
                            st.metric("MAE", f"{initial.get('MAE', 0):.2f}")
                        
                        with col2:
                            st.markdown("**ìµœì¢… KPI**")
                            if summary.get('final_kpi'):
                                final = summary['final_kpi']
                                st.metric("MAPE", f"{final.get('MAPE', 0):.2%}")
                                st.metric("|Bias|", f"{abs(final.get('Bias', 0)):.4f}")
                                st.metric("MAE", f"{final.get('MAE', 0):.2f}")
                        
                        # í†µê³¼ ì—¬ë¶€
                        if summary.get('pass'):
                            st.success("âœ… KPI ëª©í‘œ ë‹¬ì„±!")
                        else:
                            st.warning("âš ï¸ KPI ë¯¸ë‹¬ - ì¶”ê°€ ì¡°ì¹˜ í•„ìš”")
                        
                        # ì‹¤í–‰ëœ ë‹¨ê³„
                        if summary.get('stages_run'):
                            st.markdown("**ì‹¤í–‰ëœ ë‹¨ê³„**")
                            for stage_result in summary['stages_run']:
                                with st.expander(f"ğŸ“Œ {stage_result['stage']}"):
                                    st.json(stage_result['improvement'])
                else:
                    progress_bar.progress(0)
                    status_text.text("âŒ ì‹¤íŒ¨")
                    st.error(f"Reconcile ì‹¤í–‰ ì‹¤íŒ¨ (exit code: {result.returncode})")
            
            except Exception as e:
                progress_bar.progress(0)
                status_text.text("âŒ ì˜¤ë¥˜")
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                with log_container:
                    st.code(traceback.format_exc(), language="text")
        
        # ê¸°ì¡´ Reconcile ê²°ê³¼ í‘œì‹œ
        if reconcile_dir.exists():
            st.markdown("---")
            st.subheader("ğŸ“ Reconcile ê²°ê³¼ íŒŒì¼")
            
            files = list(reconcile_dir.glob("*"))
            if files:
                for file in sorted(files):
                    col1, col2, col3 = st.columns([3, 1, 1])
                    with col1:
                        st.text(f"ğŸ“„ {file.name}")
                    with col2:
                        st.caption(f"{file.stat().st_size / 1024:.1f} KB")
                    with col3:
                        if file.suffix == '.csv':
                            if st.button(f"ë³´ê¸°", key=f"view_rec_{file.name}"):
                                df = pd.read_csv(file, encoding='utf-8-sig')
                                st.dataframe(df.head(100), width='stretch')
                        elif file.suffix == '.json':
                            if st.button(f"ë³´ê¸°", key=f"view_rec_{file.name}"):
                                with open(file, 'r', encoding='utf-8') as f:
                                    data = json.load(f)
                                st.json(data)
                        elif file.suffix == '.txt':
                            if st.button(f"ë³´ê¸°", key=f"view_rec_{file.name}"):
                                with open(file, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                st.text(content)
    else:
        st.info(f"{month_key} ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € Tab 2ì—ì„œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì„¸ìš”.")

# Tab 5: í†µê³„
with tab5:
    st.header("ğŸ“Š ì „ì²´ í†µê³„")
    
    incremental_dir = Path("artifacts/incremental")
    
    if incremental_dir.exists():
        month_dirs = [d for d in incremental_dir.iterdir() if d.is_dir()]
        
        if month_dirs:
            st.subheader(f"ì²˜ë¦¬ëœ ì›”: {len(month_dirs)}ê°œ")
            
            # ì›”ë³„ ìš”ì•½ ë¡œë“œ
            summaries = []
            for month_dir in sorted(month_dirs):
                summary_files = list(month_dir.glob("summary_*.json"))
                if summary_files:
                    with open(summary_files[0], 'r', encoding='utf-8') as f:
                        summary = json.load(f)
                        summaries.append(summary)
            
            if summaries:
                df_summary = pd.DataFrame(summaries)
                
                # ì›”ë³„ íŠ¸ë Œë“œ
                if 'year' in df_summary.columns and 'month' in df_summary.columns:
                    df_summary['month_key'] = df_summary['year'].astype(str) + '-' + df_summary['month'].astype(str).str.zfill(2)
                    df_summary = df_summary.sort_values('month_key')
                    
                    st.line_chart(df_summary.set_index('month_key')[['total_records', 'series_count']])
                
                # ì „ì²´ í†µê³„
                st.dataframe(df_summary, width='stretch')
        else:
            st.info("ì²˜ë¦¬ëœ ì›”ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì¦ë¶„í•™ìŠµ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

# í‘¸í„°
st.markdown("---")
st.caption("CJ Quality-Cycles - ì›”ë³„ ì¦ë¶„í•™ìŠµ ì‹œìŠ¤í…œ v1.0")
