"""
Streamlit ì›”ë³„ ì¦ë¶„í•™ìŠµ UI
ì›”ë³„ ë°ì´í„° ì—…ë¡œë“œ â†’ Lag í•„í„°ë§ â†’ ì˜ˆì¸¡ ë¹„êµ â†’ ì¬í•™ìŠµ
"""
import streamlit as st
import pandas as pd
import numpy as np
import subprocess
import json
from pathlib import Path
from datetime import datetime
import sys

st.set_page_config(page_title="í’ˆì§ˆ í´ë ˆì„ ê´€ë¦¬ ì‹œìŠ¤í…œ", layout="wide", page_icon="ğŸ“Š")

st.title("ğŸ“Š í’ˆì§ˆ í´ë ˆì„ ì˜ˆì¸¡ ê´€ë¦¬ ì‹œìŠ¤í…œ")
st.markdown("**ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ | ì›”ë³„ ë°ì´í„° ì—…ë¡œë“œ | ì¦ë¶„í•™ìŠµ | Reconcile ë³´ì •**")

# ì‚¬ì´ë“œë°” - ì„¤ì •
st.sidebar.header("âš™ï¸ ì‹œìŠ¤í…œ ì •ë³´")

# Lag í†µê³„ íŒŒì¼ í™•ì¸
lag_stats_path = Path("artifacts/metrics/lag_stats_from_raw.csv")
if lag_stats_path.exists():
    st.sidebar.success(f"âœ… Lag í†µê³„ íŒŒì¼ ì¡´ì¬")
    lag_stats = pd.read_csv(lag_stats_path)
    st.sidebar.caption(f"ì œí’ˆë²”ì£¼2: {len(lag_stats):,}ê°œ")
else:
    st.sidebar.error("âŒ Lag í†µê³„ íŒŒì¼ ì—†ìŒ")
    st.error("lag_stats_from_raw.csv íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤. tools/lag_analyzer.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    st.stop()

# ë©”ì¸ ì˜ì—­
tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ”® ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ", "ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ", "ğŸ“ˆ ì²˜ë¦¬ ê²°ê³¼", "ğŸ”§ Reconcile ë³´ì •", "ğŸ“Š í†µê³„"])

# Tab 1: ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ
with tab1:
    st.header("ğŸ”® í•™ìŠµëœ ëª¨ë¸ ê¸°ë°˜ ì˜ˆì¸¡")
    st.markdown("**í˜„ì¬ í•™ìŠµëœ ëª¨ë¸ë¡œ í–¥í›„ 6ê°œì›” í´ë ˆì„ ì˜ˆì¸¡**")
    
    # ëª¨ë¸ ë° ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸
    models_dir = Path("artifacts/models/base_monthly")
    features_dir = Path("data/features")
    
    if not models_dir.exists() or not features_dir.exists():
        st.warning("âš ï¸ í•™ìŠµëœ ëª¨ë¸ ë˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.info("ë¨¼ì € Base í•™ìŠµì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        st.code("python batch.py train --mode base --workers 4", language="bash")
    else:
        # ëª¨ë¸ íŒŒì¼ ê°œìˆ˜ í™•ì¸
        model_files = list(models_dir.glob("*.pkl"))
        
        if not model_files:
            st.error("âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.success(f"âœ… {len(model_files)}ê°œì˜ í•™ìŠµëœ ì‹œë¦¬ì¦ˆ ëª¨ë¸ ë°œê²¬")
            
            # ì‹œë¦¬ì¦ˆ ë©”íƒ€ë°ì´í„° ë¡œë“œ
            @st.cache_data
            def load_series_metadata():
                """ëª¨ë“  ì‹œë¦¬ì¦ˆì˜ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
                metadata = []
                
                for json_file in features_dir.glob("*.json"):
                    if json_file.name == "_summary.json":
                        continue
                        
                    try:
                        with open(json_file, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        
                        # JSON êµ¬ì¡°: {series_id, plant, product_cat2, mid_category, data: [{year, month, claim_count, ...}]}
                        data_records = data.get('data', [])
                        
                        if data_records:
                            last_record = data_records[-1]
                            last_month = f"{last_record['year']}-{last_record['month']:02d}"
                        else:
                            last_month = None
                        
                        metadata.append({
                            'plant': data.get('plant', 'Unknown'),
                            'product_cat2': data.get('product_cat2', 'Unknown'),
                            'mid_category': data.get('mid_category', 'Unknown'),
                            'series_id': data.get('series_id', 'Unknown'),
                            'total_records': len(data_records),
                            'last_month': last_month,
                            'json_file': str(json_file)
                        })
                    except Exception as e:
                        continue
                
                return pd.DataFrame(metadata)
            
            metadata_df = load_series_metadata()
            
            if metadata_df.empty:
                st.warning("âš ï¸ ì‹œë¦¬ì¦ˆ ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # Base ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸
                if models_dir.exists() and len(list(models_dir.glob("*.pkl"))) > 0:
                    model_count = len(list(models_dir.glob("*.pkl")))
                    st.success(f"âœ… Base ëª¨ë¸ ë°œê²¬: {model_count:,}ê°œ")
                    
                    st.info("**ë©”íƒ€ë°ì´í„° ìƒì„± ë°©ë²•:**")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("**1ï¸âƒ£ ìˆ˜ë™ ìƒì„± (í„°ë¯¸ë„)**")
                        st.code("python generate_series_json.py", language="bash")
                        st.caption("ëª¨ë“  ì‹œë¦¬ì¦ˆì˜ ë©”íƒ€ë°ì´í„°ë¥¼ í•œë²ˆì— ìƒì„±")
                    
                    with col2:
                        st.markdown("**2ï¸âƒ£ ìë™ ìƒì„± (ê¶Œì¥)**")
                        st.markdown("ğŸ‘‰ `ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ` íƒ­ìœ¼ë¡œ ì´ë™")
                        st.caption("ì›”ë³„ ë°ì´í„° ì—…ë¡œë“œ ì‹œ ìë™ìœ¼ë¡œ ìƒì„±ë¨")
                else:
                    st.info("**ë¨¼ì € Base í•™ìŠµì„ ì‹¤í–‰í•˜ì„¸ìš”:**")
                    st.code("python batch.py train --mode base --workers 4", language="bash")
                    st.caption("2021-2023 ë°ì´í„°ë¡œ Base ëª¨ë¸ í•™ìŠµ")
                st.subheader("ğŸ¯ ì˜ˆì¸¡ ì‹œë¦¬ì¦ˆ ì„ íƒ")
                
                # EWS ìœ„í—˜ë„ Top 5 í‘œì‹œ
                st.markdown("### âš ï¸ EWS ìœ„í—˜ë„ Top 5")
                st.caption("6ê°œì›” ì˜ˆì¸¡ ê¸°ë°˜ ìƒëŒ€ì  ìœ„í—˜ë„ ì ìˆ˜ (ì¦ê°€ìœ¨, ë³€ë™ì„±, ê³„ì ˆì„±, ê°€ì†ë„ ì¢…í•©)")
                
                # EWS ì ìˆ˜ ë¡œë“œ ë˜ëŠ” ê³„ì‚°
                ews_file = Path("artifacts/metrics/ews_scores.csv")
                
                if ews_file.exists():
                    df_ews = pd.read_csv(ews_file)
                    top5 = df_ews.head(5)
                    
                    # Top 5 í…Œì´ë¸” í‘œì‹œ
                    display_data = []
                    for _, row in top5.iterrows():
                        # ì‹œë¦¬ì¦ˆ ì •ë³´ íŒŒì‹±
                        parts = row['series_id'].split('|')
                        plant = parts[0] if len(parts) > 0 else ''
                        product = parts[1] if len(parts) > 1 else ''
                        category = parts[2] if len(parts) > 2 else ''
                        
                        # MAPE ê¸°ë°˜ ì‹ ë¢°ë„ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
                        mape = row.get('growth_score', 0)  # ì„ì‹œë¡œ growth_score ì‚¬ìš©
                        confidence_pct = max(0, 100 - mape)
                        
                        display_data.append({
                            'ë­í‚¹': f"ğŸ”¥ {int(row['rank'])}ìœ„",
                            'ì‹œë¦¬ì¦ˆ': f"{plant} | {product}",
                            'ì¤‘ë¶„ë¥˜': category,
                            'EWSì ìˆ˜': f"{row['total_score']:.1f}",
                            'ì‹ ë¢°ë„': f"{confidence_pct:.0f}%",
                            'ì˜ˆìƒì‹œì ': f"2024-{int(row.get('forecast_month', 1)):02d}",
                            'ì˜ˆìƒê±´ìˆ˜': f"{row['forecast_max']:.1f}ê±´"
                        })
                    
                    df_display = pd.DataFrame(display_data)
                    st.dataframe(df_display, use_container_width=True, hide_index=True)
                    
                    # ìƒì„¸ ì •ë³´ (í™•ì¥ ê°€ëŠ¥)
                    with st.expander("ğŸ“Š ìœ„í—˜ë„ ì ìˆ˜ êµ¬ì„± ë³´ê¸°"):
                        for _, row in top5.iterrows():
                            st.markdown(f"**[{int(row['rank'])}ìœ„] {row['series_id']}** - ì¢…í•© {row['total_score']:.1f}ì ")
                            
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("ì¦ê°€ìœ¨", f"{row['growth_score']:.1f}", 
                                         f"{row['growth_rate_pct']:+.0f}%")
                            with col2:
                                st.metric("ë³€ë™ì„±", f"{row['volatility_score']:.1f}")
                            with col3:
                                st.metric("ê³„ì ˆì„±", f"{row['seasonality_score']:.1f}")
                            with col4:
                                st.metric("ê°€ì†ë„", f"{row['acceleration_score']:.1f}")
                            
                            st.caption(f"í‰ê· : {row['historical_mean']:.1f} â†’ {row['forecast_mean']:.1f} ê±´/ì›” (ìµœëŒ€: {row['forecast_max']:.1f})")
                            st.markdown("---")
                else:
                    st.warning("âš ï¸ EWS ì ìˆ˜ê°€ ê³„ì‚°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    st.info("ì˜ˆì¸¡ ìƒì„± í›„ EWS ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì„¸ìš”:")
                    st.code("python src/ews_scoring.py --forecast artifacts/forecasts/2024/forecast_2024_01.parquet", language="bash")
                
                st.markdown("---")
                
                # ì‹œë¦¬ì¦ˆ í•„í„°ë§ UI
                st.markdown("### ğŸ”® í–¥í›„ 6ê°œì›” í´ë ˆì„ ì˜ˆì¸¡")
                
                col1, col2, col3 = st.columns(3)
                st.markdown("---")
                
                # ì‹œë¦¬ì¦ˆ ì„ íƒ UI - ê³„ì¸µì  í•„í„°ë§
                st.markdown("### ï¿½ í–¥í›„ 6ê°œì›” í´ë ˆì„ ì˜ˆì¸¡")
                
                col1, col2, col3, col4 = st.columns(4)
                
                # 1ë‹¨ê³„: í”ŒëœíŠ¸ ì„ íƒ
                with col1:
                    plants = sorted(metadata_df['plant'].unique().tolist())
                    selected_plant = st.selectbox("í”ŒëœíŠ¸", plants, key="forecast_plant")
                
                # í”ŒëœíŠ¸ í•„í„°ë§ ì ìš©
                filtered_by_plant = metadata_df[metadata_df['plant'] == selected_plant]
                
                # 2ë‹¨ê³„: ì œí’ˆë²”ì£¼2 ì„ íƒ
                with col2:
                    categories = sorted(filtered_by_plant['product_cat2'].unique().tolist())
                    selected_category = st.selectbox("ì œí’ˆë²”ì£¼2", categories, key="forecast_cat2")
                
                # ì œí’ˆë²”ì£¼2 í•„í„°ë§ ì ìš©
                filtered_by_cat2 = filtered_by_plant[filtered_by_plant['product_cat2'] == selected_category]
                
                # 3ë‹¨ê³„: ì¤‘ë¶„ë¥˜ ì„ íƒ
                with col3:
                    mid_categories = sorted(filtered_by_cat2['mid_category'].unique().tolist())
                    selected_mid = st.selectbox("ì¤‘ë¶„ë¥˜", mid_categories, key="forecast_mid")
                
                # 4ë‹¨ê³„: ì‹ ë¢°êµ¬ê°„ ì„ íƒ
                with col4:
                    ci_choice = st.selectbox("ì‹ ë¢°êµ¬ê°„", ["95%", "99%"], index=0, key="ci")
                    ci = 0.99 if ci_choice == "99%" else 0.95
                
                # ìµœì¢… í•„í„°ë§
                final_filtered = filtered_by_cat2[filtered_by_cat2['mid_category'] == selected_mid]
                
                # ì‹œë¦¬ì¦ˆê°€ ì„ íƒë˜ì—ˆëŠ”ì§€ í™•ì¸
                if len(final_filtered) > 0:
                    series_info = final_filtered.iloc[0]
                    series_id = series_info['series_id']
                    
                    st.info(f"âœ… ì„ íƒëœ ì‹œë¦¬ì¦ˆ: **{series_id}**")
                    
                    st.markdown("---")
                    
                    # ì˜ˆì¸¡ ì‹¤í–‰ ë²„íŠ¼ - 6ê°œì›” ê³ ì •
                    horizon_months = 6  # 6ê°œì›” ê³ ì •
                    if st.button("ğŸ”® ì˜ˆì¸¡ ì‹¤í–‰", type="primary", use_container_width=True):
                        with st.spinner(f"{series_id} ì˜ˆì¸¡ ì¤‘..."):
                            try:
                                # JSON ë°ì´í„° ë¡œë“œ
                                import pickle
                                from datetime import timedelta
                                from dateutil.relativedelta import relativedelta
                                import plotly.graph_objects as go
                                
                                with open(series_info['json_file'], 'r', encoding='utf-8') as f:
                                    json_data = json.load(f)
                                
                                # JSON êµ¬ì¡°: data = [{year, month, claim_count, ...}]
                                data_records = json_data.get('data', [])
                                
                                if not data_records:
                                    st.error(f"ì‹œë¦¬ì¦ˆ {series_id}ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                else:
                                    # DataFrame ìƒì„±
                                    df_hist = pd.DataFrame(data_records)
                                    df_hist['month_date'] = pd.to_datetime(
                                        df_hist['year'].astype(str) + '-' + df_hist['month'].astype(str).str.zfill(2) + '-01'
                                    )
                                    df_hist = df_hist.rename(columns={'claim_count': 'y'})
                                    df_hist = df_hist.sort_values('month_date')
                                    
                                    # ëª¨ë¸ íŒŒì¼ ë¡œë“œ
                                    # series_idì—ì„œ | êµ¬ë¶„ìë¡œ íŒŒì¼ëª… ìƒì„±
                                    safe_filename = (series_id.replace('/', '_').replace('\\', '_').replace(':', '_')
                                                   .replace('|', '_').replace('?', '_').replace('*', '_')
                                                   .replace('<', '_').replace('>', '_').replace('"', '_'))
                                    model_path = models_dir / f"{safe_filename}.pkl"
                                    
                                    st.info(f"ğŸ” ì°¾ëŠ” ëª¨ë¸ íŒŒì¼: `{model_path.name}`")
                                    
                                    if model_path.exists():
                                        with open(model_path, 'rb') as f:
                                            model_result = pickle.load(f)
                                        
                                        # ì›”ë³„ ëª¨ë¸: paramsë¥¼ SARIMAXì— ì§ì ‘ ì ìš©
                                        from statsmodels.tsa.statespace.sarimax import SARIMAX
                                        
                                        # í•™ìŠµ ë°ì´í„° ë²”ìœ„ ê²°ì •: 2021ë…„ë¶€í„° ìµœì‹  ë°ì´í„°ê¹Œì§€
                                        # (2011-2020ì€ ëŒ€ë¶€ë¶„ 0ì´ë¯€ë¡œ ì œì™¸)
                                        df_train = df_hist[df_hist['month_date'].dt.year >= 2021].copy()
                                        
                                        if len(df_train) < 12:
                                            st.error(f"í›ˆë ¨ ë°ì´í„° ë¶€ì¡±: {len(df_train)}ê°œì›” (ìµœì†Œ 12ê°œì›” í•„ìš”)")
                                        else:
                                            y = df_train['y'].values
                                            
                                            # SARIMAX ëª¨ë¸ ìƒì„± ë° íŒŒë¼ë¯¸í„° ì ìš©
                                            model = SARIMAX(
                                                y,
                                                order=model_result['model_spec']['order'],
                                                seasonal_order=model_result['model_spec']['seasonal_order'],
                                                enforce_stationarity=False,
                                                enforce_invertibility=False
                                            )
                                            
                                            params = np.array(model_result['params'])
                                            fitted_model = model.smooth(params)
                                            
                                            # ì˜ˆì¸¡ ìƒì„±
                                            forecast_mean = fitted_model.forecast(steps=horizon_months)
                                            
                                            # ë§ˆì§€ë§‰ ì›” ì´í›„ ë‚ ì§œ ìƒì„±
                                            last_month = df_train['month_date'].iloc[-1]
                                            future_months = [last_month + relativedelta(months=i+1) for i in range(horizon_months)]
                                            
                                            # ìŒìˆ˜ ì²˜ë¦¬ (í´ë ˆì„ì€ ìŒìˆ˜ê°€ ë  ìˆ˜ ì—†ìŒ)
                                            yhat_values = np.maximum(forecast_mean, 0)
                                            
                                            df_forecast = pd.DataFrame({
                                                'month': future_months,
                                                'yhat': yhat_values
                                            })
                                            
                                            # í•™ìŠµ ê¸°ê°„ í‘œì‹œ
                                            train_start_year = df_train['month_date'].dt.year.min()
                                            train_end_year = df_train['month_date'].dt.year.max()
                                            train_period = f"{train_start_year}-{train_end_year}" if train_start_year != train_end_year else str(train_start_year)
                                            
                                            # ë©”íŠ¸ë¦­ í‘œì‹œ
                                            col1, col2, col3, col4 = st.columns(4)
                                            with col1:
                                                st.metric("í•™ìŠµ ë°ì´í„°", f"{len(df_train)}ê°œì›” ({train_period})")
                                            with col2:
                                                avg_claims = df_train['y'].mean()
                                                st.metric("í‰ê·  í´ë ˆì„", f"{avg_claims:.1f}ê±´/ì›”")
                                            with col3:
                                                last_claim = df_train['y'].iloc[-1]
                                                last_month_str = df_train['month_date'].iloc[-1].strftime('%Y-%m')
                                                st.metric(f"ìµœê·¼ í´ë ˆì„ ({last_month_str})", f"{last_claim:.0f}ê±´")
                                            with col4:
                                                forecast_avg = df_forecast['yhat'].mean()
                                                change = ((forecast_avg - avg_claims) / avg_claims * 100) if avg_claims > 0 else 0
                                                st.metric("ì˜ˆì¸¡ í‰ê· ", f"{forecast_avg:.1f}ê±´", f"{change:+.1f}%")
                                            
                                            # ì°¨íŠ¸ ìƒì„±
                                            st.subheader("ğŸ“ˆ ì˜ˆì¸¡ ì°¨íŠ¸")
                                            
                                            fig = go.Figure()
                                            
                                            # í›ˆë ¨ ë°ì´í„° (2021-2023)
                                            fig.add_trace(go.Scatter(
                                                x=df_train['month_date'],
                                                y=df_train['y'],
                                                mode='lines+markers',
                                                name='ì‹¤ì œ ë°ì´í„° (2021-2023)',
                                                line=dict(color='#1f77b4', width=2),
                                                marker=dict(size=4)
                                            ))
                                            
                                            # ì˜ˆì¸¡ê°’
                                            fig.add_trace(go.Scatter(
                                                x=df_forecast['month'],
                                                y=df_forecast['yhat'],
                                                mode='lines+markers',
                                                name='ì˜ˆì¸¡',
                                                line=dict(color='#ff7f0e', width=2, dash='dash'),
                                                marker=dict(size=6)
                                            ))
                                            
                                            fig.update_layout(
                                                title=f"{series_id} - {horizon_months}ê°œì›” ì˜ˆì¸¡",
                                                xaxis_title="ì›”",
                                                yaxis_title="í´ë ˆì„ ê±´ìˆ˜",
                                                hovermode='x unified',
                                                height=500,
                                                yaxis=dict(dtick=1),  # Yì¶• ì •ìˆ˜ ë‹¨ìœ„
                                                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                                            )
                                            
                                            st.plotly_chart(fig, use_container_width=True)
                                            
                                            # ì˜ˆì¸¡ í…Œì´ë¸”
                                            st.subheader("ğŸ“‹ ì˜ˆì¸¡ ìƒì„¸")
                                            
                                            df_forecast_display = df_forecast.copy()
                                            df_forecast_display['month'] = df_forecast_display['month'].dt.strftime('%Y-%m')
                                            df_forecast_display['yhat'] = df_forecast_display['yhat'].round(1)
                                            df_forecast_display['yhat'] = df_forecast_display['yhat'].round(1)
                                            df_forecast_display.columns = ['ì›”', 'ì˜ˆì¸¡ê°’']
                                            
                                            st.dataframe(df_forecast_display, use_container_width=True, hide_index=True)
                                            
                                            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                                            csv = df_forecast.to_csv(index=False, encoding='utf-8-sig')
                                            st.download_button(
                                                label="ğŸ“¥ ì˜ˆì¸¡ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                                                data=csv,
                                                file_name=f"forecast_{series_id}_{datetime.now().strftime('%Y%m%d')}.csv",
                                                mime="text/csv",
                                                use_container_width=True
                                            )
                                    
                                    else:
                                        st.error(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {safe_filename}.pkl")
                            
                            except Exception as e:
                                st.error(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
                                st.exception(e)

# Tab 2: ë°ì´í„° ì—…ë¡œë“œ
with tab2:
    st.header("1ï¸âƒ£ ì›”ë³„ ë°ì´í„° ì—…ë¡œë“œ")
    
    # í•™ìŠµ ë°ì´í„° í˜„í™© í…Œì´ë¸”
    st.subheader("ğŸ“Š í•™ìŠµ ë°ì´í„° í˜„í™©")
    
    features_dir = Path("data/features")
    if features_dir.exists() and any(features_dir.glob("*.json")):
        with st.spinner("í•™ìŠµ ë°ì´í„° ë¶„ì„ ì¤‘..."):
            # ë…„/ì›”ë³„ ë°ì´í„° ìˆ˜ì§‘
            year_month_data = {}
            total_series = 0
            
            for json_file in features_dir.glob("*.json"):
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    records = data.get('data', [])
                    if not records:
                        continue
                    
                    total_series += 1
                    
                    # ê° ë ˆì½”ë“œì˜ year/month ìˆ˜ì§‘
                    for record in records:
                        year = record.get('year')
                        month = record.get('month')
                        
                        if year and month:
                            key = (year, month)
                            if key not in year_month_data:
                                year_month_data[key] = 0
                            year_month_data[key] += 1
                
                except Exception as e:
                    continue
            
            if year_month_data:
                # ë…„ë„ ì¶”ì¶œ ë° ì •ë ¬
                years = sorted(set(year for year, month in year_month_data.keys()))
                months = list(range(1, 13))
                
                # í…Œì´ë¸” ë°ì´í„° ìƒì„±
                table_data = []
                for month in months:
                    row = {'ì›”': f"{month}ì›”"}
                    for year in years:
                        count = year_month_data.get((year, month), 0)
                        # ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ (ì‹œë¦¬ì¦ˆ ìˆ˜ì˜ 80% ì´ìƒì´ë©´ ì¶©ë¶„)
                        threshold = total_series * 0.8
                        if count >= threshold:
                            status = "âœ…"
                        elif count >= threshold * 0.5:
                            status = "âš ï¸"
                        else:
                            status = "âŒ"
                        row[f"{year}ë…„"] = f"{status} {count}"
                    table_data.append(row)
                
                # DataFrame ìƒì„± ë° í‘œì‹œ
                df_status = pd.DataFrame(table_data)
                st.dataframe(df_status, use_container_width=True, hide_index=True)
                
                # ë²”ë¡€
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.caption(f"**ì´ ì‹œë¦¬ì¦ˆ**: {total_series:,}ê°œ")
                with col2:
                    st.caption("**âœ… ì¶©ë¶„**: â‰¥80% ì‹œë¦¬ì¦ˆ")
                with col3:
                    st.caption("**âš ï¸ ë³´í†µ**: 40-80% ì‹œë¦¬ì¦ˆ")
                with col4:
                    st.caption("**âŒ ë¶€ì¡±**: <40% ì‹œë¦¬ì¦ˆ")
            else:
                st.info("í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("Feature JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € Base í•™ìŠµì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    st.markdown("---")
    
    # ì—…ë¡œë“œí•  ë°ì´í„°ì˜ ë…„/ì›”ì€ CSVì—ì„œ ìë™ ê°ì§€
    st.subheader("2ï¸âƒ£ ì›”ë³„ ë°ì´í„° ì—…ë¡œë“œ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        uploaded_file = st.file_uploader(
            f"**CSV íŒŒì¼ ì—…ë¡œë“œ**",
            type=['csv'],
            help="ë°œìƒì¼ì ê¸°ì¤€ 1ê°œì›” ë°ì´í„° (í”ŒëœíŠ¸, ì œí’ˆë²”ì£¼2, ì¤‘ë¶„ë¥˜(ë³´ì •), ë°œìƒì¼ì, ì œì¡°ì¼ì, count ì»¬ëŸ¼ í•„ìˆ˜)"
        )
    
    with col2:
        st.markdown("**í•„ìˆ˜ ì»¬ëŸ¼**")
        st.code("""
í”ŒëœíŠ¸
ì œí’ˆë²”ì£¼2
ì¤‘ë¶„ë¥˜(ë³´ì •)
ë°œìƒì¼ì
ì œì¡°ì¼ì
count
        """, language="text")
    
    if uploaded_file is not None:
        # ì„ì‹œ ì €ì¥
        temp_dir = Path("artifacts/temp")
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ë° ë…„/ì›” ìë™ ê°ì§€
        st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
        
        try:
            df_preview = pd.read_csv(uploaded_file, encoding='utf-8-sig', nrows=10)
            
            # ì „ì²´ ë°ì´í„° ë¡œë“œ
            uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ì´ˆê¸°í™”
            df_full = pd.read_csv(uploaded_file, encoding='utf-8-sig')
            
            # ë°œìƒì¼ìì—ì„œ ë…„/ì›” ìë™ ê°ì§€
            if 'ë°œìƒì¼ì' in df_full.columns:
                df_full['ë°œìƒì¼ì'] = pd.to_datetime(df_full['ë°œìƒì¼ì'])
                detected_year = df_full['ë°œìƒì¼ì'].dt.year.mode()[0]  # ìµœë¹ˆê°’
                detected_month = df_full['ë°œìƒì¼ì'].dt.month.mode()[0]  # ìµœë¹ˆê°’
                month_key = f"{detected_year}-{detected_month:02d}"
                
                st.info(f"ğŸ“… **ê°ì§€ëœ ëŒ€ìƒ ì›”:** {month_key}")
            else:
                st.error("'ë°œìƒì¼ì' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()
            
            # ì„ì‹œ íŒŒì¼ ì €ì¥
            temp_path = temp_dir / f"upload_{month_key.replace('-', '')}.csv"
            df_full.to_csv(temp_path, index=False, encoding='utf-8-sig')
            st.subheader("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            st.dataframe(df_preview, width='stretch')
            
            # ì „ì²´ ë°ì´í„° í†µê³„
            df_full = pd.read_csv(temp_path, encoding='utf-8-sig')
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ì´ ë ˆì½”ë“œ", f"{len(df_full):,}ê±´")
            with col2:
                st.metric("ì‹œë¦¬ì¦ˆ ìˆ˜", f"{df_full.groupby(['í”ŒëœíŠ¸', 'ì œí’ˆë²”ì£¼2', 'ì¤‘ë¶„ë¥˜(ë³´ì •)']).ngroups:,}ê°œ")
            with col3:
                if 'ë°œìƒì¼ì' in df_full.columns:
                    df_full['ë°œìƒì¼ì'] = pd.to_datetime(df_full['ë°œìƒì¼ì'])
                    date_range = f"{df_full['ë°œìƒì¼ì'].min().date()} ~ {df_full['ë°œìƒì¼ì'].max().date()}"
                    st.metric("ë°œìƒì¼ì ë²”ìœ„", date_range)
            with col4:
                if 'count' in df_full.columns:
                    st.metric("ì´ í´ë ˆì„ ê±´ìˆ˜", f"{df_full['count'].sum():,}ê±´")
            
            st.markdown("---")
            
            # ì²˜ë¦¬ ë²„íŠ¼
            st.subheader("2ï¸âƒ£ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
            
            col1, col2, col3 = st.columns([1, 1, 2])
            
            with col1:
                run_pipeline = st.button("ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰", type="primary", width='stretch')
            
            with col2:
                show_command = st.checkbox("ëª…ë ¹ì–´ í‘œì‹œ", value=False)
            
            if show_command:
                with col3:
                    st.code(f"python batch.py process --upload {temp_path} --month {month_key}", language="bash")
            
            if run_pipeline:
                st.markdown("---")
                st.subheader("â³ ì²˜ë¦¬ ì¤‘...")
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                status_text = st.empty()
                
                # ë¡œê·¸ ì¶œë ¥ ì»¨í…Œì´ë„ˆ
                log_container = st.expander("ğŸ” ì‹¤ì‹œê°„ ë¡œê·¸", expanded=True)
                log_output = log_container.empty()
                
                try:
                    # batch.py process ì‹¤í–‰
                    status_text.info("ğŸ”„ íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
                    
                    cmd = [
                        sys.executable, "batch.py", "process",
                        "--upload", str(temp_path),
                        "--month", month_key
                    ]
                    
                    log_container.code(f"ì‹¤í–‰: {' '.join(cmd)}", language="bash")
                    
                    # ì‹¤ì‹œê°„ ì¶œë ¥ì„ ìœ„í•œ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
                    import io
                    process = subprocess.Popen(
                        cmd,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.STDOUT,
                        text=True,
                        cwd=Path.cwd(),
                        bufsize=1,
                        universal_newlines=True
                    )
                    
                    # ì‹¤ì‹œê°„ ë¡œê·¸ ìˆ˜ì§‘
                    output_lines = []
                    for line in iter(process.stdout.readline, ''):
                        if line:
                            output_lines.append(line.rstrip())
                            # ë§ˆì§€ë§‰ 50ì¤„ë§Œ í‘œì‹œ
                            display_lines = output_lines[-50:]
                            log_output.code('\n'.join(display_lines), language="text")
                            
                            # ìƒíƒœ ì—…ë°ì´íŠ¸
                            if "Step 1" in line or "Lag í•„í„°ë§" in line:
                                status_text.info("ğŸ”„ Step 1/4: Lag í•„í„°ë§ ì¤‘...")
                            elif "Step 2" in line or "ì£¼ê°„ ì§‘ê³„" in line:
                                status_text.info("ğŸ”„ Step 2/4: ì£¼ê°„ ì§‘ê³„ ë° JSON ì—…ë°ì´íŠ¸ ì¤‘...")
                            elif "Step 3" in line or "ì˜ˆì¸¡ ë¹„êµ" in line:
                                status_text.info("ğŸ”„ Step 3/4: ì˜ˆì¸¡ vs ì‹¤ì œ ë¹„êµ ì¤‘...")
                            elif "Step 4" in line or "ì¬í•™ìŠµ" in line:
                                status_text.info("ğŸ”„ Step 4/4: ëª¨ë¸ ì¬í•™ìŠµ ì¤‘...")
                    
                    process.wait()
                    result_code = process.returncode
                    
                    if result_code == 0:
                        status_text.success("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
                        st.success("ğŸ‰ ì›”ë³„ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì™„ë£Œ!")
                        
                        # ê²°ê³¼ í‘œì‹œ (ìë™ ê°ì§€ëœ ë…„/ì›” ì‚¬ìš©)
                        month_dir = Path(f"artifacts/incremental/{detected_year}{detected_month:02d}")
                        summary_file = month_dir / f"summary_{detected_year}{detected_month:02d}.json"
                        
                        if summary_file.exists():
                            with open(summary_file, 'r', encoding='utf-8') as f:
                                summary = json.load(f)
                            
                            st.subheader("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("ì´ ë ˆì½”ë“œ", f"{summary.get('total_records', 0):,}ê±´")
                            with col2:
                                st.metric("ì‹œë¦¬ì¦ˆ ìˆ˜", f"{summary.get('series_count', 0):,}ê°œ")
                            with col3:
                                if summary.get('mean_error') is not None:
                                    st.metric("í‰ê·  ì˜¤ì°¨", f"{summary['mean_error']:.2f}")
                            with col4:
                                if summary.get('mae') is not None:
                                    st.metric("MAE", f"{summary['mae']:.2f}")
                            
                            st.info(f"ì²˜ë¦¬ ì‹œê°„: {summary.get('processed_at', 'N/A')}")
                    else:
                        status_text.error("âŒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨")
                        st.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨ (exit code: {result_code})")
                        st.info("ğŸ’¡ ìœ„ì˜ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”.")
                
                except Exception as e:
                    status_text.error("âŒ ì˜¤ë¥˜ ë°œìƒ")
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                    import traceback
                    with log_container:
                        st.code(traceback.format_exc(), language="text")
        
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

# Tab 3: ì²˜ë¦¬ ê²°ê³¼
with tab3:
    st.header("ğŸ“ˆ ì²˜ë¦¬ ê²°ê³¼")
    
    # ë…„/ì›” ì„ íƒ
    col_date1, col_date2, col_date3 = st.columns([1, 1, 2])
    with col_date1:
        current_year = datetime.now().year
        view_year = st.selectbox("ì—°ë„", range(2024, current_year + 2), key="view_year")
    with col_date2:
        view_month = st.selectbox("ì›”", range(1, 13), key="view_month")
    with col_date3:
        st.info(f"**ì¡°íšŒ ëŒ€ìƒ ì›”:** {view_year}-{view_month:02d}")
    
    month_key = f"{view_year}-{view_month:02d}"
    
    # ì›”ë³„ ê²°ê³¼ ë””ë ‰í† ë¦¬
    month_dir = Path(f"artifacts/incremental/{view_year}{view_month:02d}")
    
    if month_dir.exists():
        st.success(f"âœ… {month_key} ì²˜ë¦¬ ê²°ê³¼ ì¡´ì¬")
        
        # íŒŒì¼ ëª©ë¡
        files = list(month_dir.glob("*"))
        
        if files:
            st.subheader("ğŸ“ ìƒì„±ëœ íŒŒì¼")
            
            for file in sorted(files):
                col1, col2, col3 = st.columns([3, 1, 1])
                with col1:
                    st.text(f"ğŸ“„ {file.name}")
                with col2:
                    st.caption(f"{file.stat().st_size / 1024:.1f} KB")
                with col3:
                    if file.suffix == '.csv':
                        if st.button(f"ë³´ê¸°", key=f"view_{file.name}"):
                            df = pd.read_csv(file, encoding='utf-8-sig')
                            st.dataframe(df.head(100), width='stretch')
                    elif file.suffix == '.json':
                        if st.button(f"ë³´ê¸°", key=f"view_{file.name}"):
                            with open(file, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                            st.json(data)
            
            # ì˜ˆì¸¡-ì‹¤ì¸¡ ë¹„êµ íŒŒì¼ ìˆìœ¼ë©´ ì‹œê°í™”
            predict_vs_actual = month_dir / f"predict_vs_actual_{view_year}{view_month:02d}.csv"
            if predict_vs_actual.exists():
                st.markdown("---")
                st.subheader("ğŸ“Š ì˜ˆì¸¡ vs ì‹¤ì¸¡ ë¹„êµ")
                
                df_compare = pd.read_csv(predict_vs_actual, encoding='utf-8-sig')
                
                # í†µê³„
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("í‰ê·  ì˜¤ì°¨", f"{df_compare['error'].mean():.2f}")
                with col2:
                    st.metric("ì ˆëŒ€ ì˜¤ì°¨ í‰ê· ", f"{df_compare['abs_error'].mean():.2f}")
                with col3:
                    st.metric("í¼ì„¼íŠ¸ ì˜¤ì°¨ í‰ê· ", f"{df_compare['pct_error'].mean():.2f}%")
                with col4:
                    st.metric("ë¹„êµ ë ˆì½”ë“œ", f"{len(df_compare):,}ê±´")
                
                # ìƒìœ„ ì˜¤ì°¨ ì‹œë¦¬ì¦ˆ
                st.markdown("**ìƒìœ„ ì˜¤ì°¨ ì‹œë¦¬ì¦ˆ (Top 10)**")
                # month ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì œì™¸
                display_cols = ['series_id']
                if 'month' in df_compare.columns:
                    display_cols.append('month')
                display_cols.extend(['claim_count', 'y_pred', 'error', 'abs_error'])
                top_errors = df_compare.nlargest(10, 'abs_error')[display_cols]
                st.dataframe(top_errors, width='stretch')
        else:
            st.info("íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info(f"{month_key} ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê³  íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# Tab 4: Reconcile ë³´ì •
with tab4:
    st.header("ğŸ”§ Reconcile ë³´ì •")
    
    # ë…„/ì›” ì„ íƒ
    col_date1, col_date2, col_date3 = st.columns([1, 1, 2])
    with col_date1:
        current_year = datetime.now().year
        reconcile_year = st.selectbox("ì—°ë„", range(2024, current_year + 2), key="reconcile_year")
    with col_date2:
        reconcile_month = st.selectbox("ì›”", range(1, 13), key="reconcile_month")
    with col_date3:
        st.info(f"**Reconcile ëŒ€ìƒ ì›”:** {reconcile_year}-{reconcile_month:02d}")
    
    month_key = f"{reconcile_year}-{reconcile_month:02d}"
    
    month_dir = Path(f"artifacts/incremental/{reconcile_year}{reconcile_month:02d}")
    reconcile_dir = Path(f"artifacts/reconcile/{reconcile_year}{reconcile_month:02d}")
    
    # ì²˜ë¦¬ ê²°ê³¼ í™•ì¸
    predict_vs_actual = month_dir / f"predict_vs_actual_{reconcile_year}{reconcile_month:02d}.csv"
    
    if predict_vs_actual.exists():
        st.success(f"âœ… {month_key} ì²˜ë¦¬ ê²°ê³¼ ì¡´ì¬")
        
        # KPI í™•ì¸
        df_compare = pd.read_csv(predict_vs_actual, encoding='utf-8-sig')
        
        # MAPE ê³„ì‚°
        valid_mask = df_compare['claim_count'] > 0
        if valid_mask.sum() > 0:
            mape = (df_compare[valid_mask]['abs_error'] / df_compare[valid_mask]['claim_count']).mean()
        else:
            mape = np.nan
        
        # Bias ê³„ì‚°
        bias = df_compare['error'].mean() / df_compare['claim_count'].mean() if df_compare['claim_count'].mean() > 0 else np.nan
        
        # KPI í†µê³¼ ì—¬ë¶€ ê³„ì‚°
        mape_pass = mape < 0.20 if not np.isnan(mape) else False
        bias_pass = abs(bias) < 0.05 if not np.isnan(bias) else False
        kpi_pass = mape_pass and bias_pass
        
        st.subheader("ğŸ“Š í˜„ì¬ KPI")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("MAPE", f"{mape:.2%}", delta=f"ëª©í‘œ: <20%", delta_color="inverse" if not mape_pass else "normal")
        
        with col2:
            st.metric("|Bias|", f"{abs(bias):.4f}", delta=f"ëª©í‘œ: <0.05", delta_color="inverse" if not bias_pass else "normal")
        
        with col3:
            st.metric("MAE", f"{df_compare['abs_error'].mean():.2f}")
        
        with col4:
            if kpi_pass:
                st.success("âœ… KPI í†µê³¼")
            else:
                st.error("âŒ KPI ë¯¸ë‹¬")
        
        st.markdown("---")
        
        # Reconcile ì‹¤í–‰
        st.subheader("ğŸš€ ë³´ì • ì‹¤í–‰")
        
        col1, col2, col3 = st.columns([1, 1, 2])
        
        with col1:
            stage = st.selectbox(
                "ë³´ì • ë‹¨ê³„",
                ['all', 'bias', 'seasonal', 'optuna'],
                index=0,
                help="all: ëª¨ë“  ë‹¨ê³„ ìˆœì°¨ ì‹¤í–‰, bias: Bias Mapë§Œ, seasonal: ê³„ì ˆì„± ì¬ì¶”ì •ë§Œ, optuna: Optuna íŠœë‹ë§Œ"
            )
        
        with col2:
            run_reconcile = st.button("ğŸ”§ Reconcile ì‹¤í–‰", type="primary", width='stretch')
        
        stage_descriptions = {
            'all': 'ëª¨ë“  ë‹¨ê³„ ìˆœì°¨ ì‹¤í–‰ (Bias Map â†’ Seasonal â†’ Optuna)',
            'bias': 'Stage 1: Bias Map - ì£¼ê°„ í‰ê·  ì˜¤ì°¨ ë³´ì •',
            'seasonal': 'Stage 2: Seasonal Recalibration - ìµœê·¼ 2ë…„ ê³„ì ˆì„± ì¬ì¶”ì •',
            'optuna': 'Stage 3: Optuna Tuning - í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”'
        }
        
        with col3:
            st.info(stage_descriptions[stage])
        
        if run_reconcile:
            st.markdown("---")
            st.subheader("â³ Reconcile ì‹¤í–‰ ì¤‘...")
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            log_container = st.expander("ğŸ” ìƒì„¸ ë¡œê·¸", expanded=True)
            
            try:
                status_text.text(f"ì‹¤í–‰ ì¤‘: {stage} ë‹¨ê³„...")
                progress_bar.progress(30)
                
                cmd = [
                    sys.executable, "reconcile_pipeline.py",
                    "--year", str(reconcile_year),
                    "--month", str(reconcile_month),
                    "--stage", stage
                ]
                
                with log_container:
                    st.code(f"ì‹¤í–‰: {' '.join(cmd)}", language="bash")
                
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    cwd=Path.cwd()
                )
                
                with log_container:
                    if result.stdout:
                        st.text("STDOUT:")
                        st.code(result.stdout, language="text")
                    if result.stderr:
                        st.text("STDERR:")
                        st.code(result.stderr, language="text")
                
                if result.returncode == 0:
                    progress_bar.progress(100)
                    status_text.text("âœ… ì™„ë£Œ!")
                    st.success("ğŸ‰ Reconcile ë³´ì • ì™„ë£Œ!")
                    
                    # ê²°ê³¼ í‘œì‹œ
                    summary_file = reconcile_dir / f"reconcile_summary_{reconcile_year}{reconcile_month:02d}.json"
                    
                    if summary_file.exists():
                        with open(summary_file, 'r', encoding='utf-8') as f:
                            summary = json.load(f)
                        
                        st.subheader("ğŸ“Š ë³´ì • ê²°ê³¼")
                        
                        # ì´ˆê¸° vs ìµœì¢… KPI
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown("**ì´ˆê¸° KPI**")
                            initial = summary['initial_kpi']
                            st.metric("MAPE", f"{initial.get('MAPE', 0):.2%}")
                            st.metric("|Bias|", f"{abs(initial.get('Bias', 0)):.4f}")
                            st.metric("MAE", f"{initial.get('MAE', 0):.2f}")
                        
                        with col2:
                            st.markdown("**ìµœì¢… KPI**")
                            if summary.get('final_kpi'):
                                final = summary['final_kpi']
                                st.metric("MAPE", f"{final.get('MAPE', 0):.2%}")
                                st.metric("|Bias|", f"{abs(final.get('Bias', 0)):.4f}")
                                st.metric("MAE", f"{final.get('MAE', 0):.2f}")
                        
                        # í†µê³¼ ì—¬ë¶€
                        if summary.get('pass'):
                            st.success("âœ… KPI ëª©í‘œ ë‹¬ì„±!")
                        else:
                            st.warning("âš ï¸ KPI ë¯¸ë‹¬ - ì¶”ê°€ ì¡°ì¹˜ í•„ìš”")
                        
                        # ì‹¤í–‰ëœ ë‹¨ê³„
                        if summary.get('stages_run'):
                            st.markdown("**ì‹¤í–‰ëœ ë‹¨ê³„**")
                            for stage_result in summary['stages_run']:
                                with st.expander(f"ğŸ“Œ {stage_result['stage']}"):
                                    st.json(stage_result['improvement'])
                else:
                    progress_bar.progress(0)
                    status_text.text("âŒ ì‹¤íŒ¨")
                    st.error(f"Reconcile ì‹¤í–‰ ì‹¤íŒ¨ (exit code: {result.returncode})")
            
            except Exception as e:
                progress_bar.progress(0)
                status_text.text("âŒ ì˜¤ë¥˜")
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                with log_container:
                    st.code(traceback.format_exc(), language="text")
        
        # ê¸°ì¡´ Reconcile ê²°ê³¼ í‘œì‹œ
        if reconcile_dir.exists():
            st.markdown("---")
            st.subheader("ğŸ“ Reconcile ê²°ê³¼ íŒŒì¼")
            
            files = list(reconcile_dir.glob("*"))
            if files:
                for file in sorted(files):
                    col1, col2, col3 = st.columns([3, 1, 1])
                    with col1:
                        st.text(f"ğŸ“„ {file.name}")
                    with col2:
                        st.caption(f"{file.stat().st_size / 1024:.1f} KB")
                    with col3:
                        if file.suffix == '.csv':
                            if st.button(f"ë³´ê¸°", key=f"view_rec_{file.name}"):
                                df = pd.read_csv(file, encoding='utf-8-sig')
                                st.dataframe(df.head(100), width='stretch')
                        elif file.suffix == '.json':
                            if st.button(f"ë³´ê¸°", key=f"view_rec_{file.name}"):
                                with open(file, 'r', encoding='utf-8') as f:
                                    data = json.load(f)
                                st.json(data)
                        elif file.suffix == '.txt':
                            if st.button(f"ë³´ê¸°", key=f"view_rec_{file.name}"):
                                with open(file, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                st.text(content)
    else:
        st.info(f"{month_key} ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € Tab 2ì—ì„œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì„¸ìš”.")

# Tab 5: í†µê³„
with tab5:
    st.header("ğŸ“Š ì „ì²´ í†µê³„")
    
    incremental_dir = Path("artifacts/incremental")
    
    if incremental_dir.exists():
        month_dirs = [d for d in incremental_dir.iterdir() if d.is_dir()]
        
        if month_dirs:
            st.subheader(f"ì²˜ë¦¬ëœ ì›”: {len(month_dirs)}ê°œ")
            
            # ì›”ë³„ ìš”ì•½ ë¡œë“œ
            summaries = []
            for month_dir in sorted(month_dirs):
                summary_files = list(month_dir.glob("summary_*.json"))
                if summary_files:
                    with open(summary_files[0], 'r', encoding='utf-8') as f:
                        summary = json.load(f)
                        summaries.append(summary)
            
            if summaries:
                df_summary = pd.DataFrame(summaries)
                
                # ì›”ë³„ íŠ¸ë Œë“œ
                if 'year' in df_summary.columns and 'month' in df_summary.columns:
                    df_summary['month_key'] = df_summary['year'].astype(str) + '-' + df_summary['month'].astype(str).str.zfill(2)
                    df_summary = df_summary.sort_values('month_key')
                    
                    st.line_chart(df_summary.set_index('month_key')[['total_records', 'series_count']])
                
                # ì „ì²´ í†µê³„
                st.dataframe(df_summary, width='stretch')
        else:
            st.info("ì²˜ë¦¬ëœ ì›”ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì¦ë¶„í•™ìŠµ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

# í‘¸í„°
st.markdown("---")
st.caption("CJ Quality-Cycles - ì›”ë³„ ì¦ë¶„í•™ìŠµ ì‹œìŠ¤í…œ v1.0")
