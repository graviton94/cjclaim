"""
ë°œìƒì¼ì-ì œì¡°ì¼ì Lag ë¶„ì„ê¸° (ì œí’ˆë²”ì£¼2ë³„)
- 2021-2023 Base ë°ì´í„°ì—ì„œ lag í†µê³„ ì‚°ì¶œ
- ì›”ë³„ ë°ì´í„° ë¼ë²¨ë§ (normal/borderline/extreme)
- Retrain í›„ë³´ ì‹œë¦¬ì¦ˆ ì¶”ì¶œ
"""
import pandas as pd
import numpy as np
from pathlib import Path
import argparse
from datetime import datetime
import json


def calculate_lag_stats(df):
    """
    ì œí’ˆë²”ì£¼2ë³„ lag í†µê³„ ê³„ì‚°
    
    Returns:
        DataFrame: product_cat2, mu, sigma, p90, p95, n, use_global
    """
    # ë°œìƒì¼ì - ì œì¡°ì¼ì ê³„ì‚° (ì¼ ë‹¨ìœ„)
    df['lag_days'] = (pd.to_datetime(df['ë°œìƒì¼ì']) - pd.to_datetime(df['ì œì¡°ì¼ì'])).dt.days
    
    # ìŒìˆ˜ lag ì œê±° (ì œì¡°ì¼ì > ë°œìƒì¼ì â†’ ì˜ëª» ì ‘ìˆ˜ëœ ì¼€ì´ìŠ¤)
    df_invalid_negative = df[df['lag_days'] < 0]
    df_valid = df[df['lag_days'] >= 0].copy()
    
    print(f"ì´ ë ˆì½”ë“œ: {len(df):,}ê±´")
    print(f"ìœ íš¨ ë ˆì½”ë“œ: {len(df_valid):,}ê±´")
    print(f"âš ï¸  ì˜ëª» ì ‘ìˆ˜ ì œì™¸: {len(df_invalid_negative):,}ê±´ (ì œì¡°ì¼ì > ë°œìƒì¼ì, ìŒìˆ˜ lag)")
    
    # ì œí’ˆë²”ì£¼2ë³„ í†µê³„
    stats_list = []
    
    for product_cat2, group in df_valid.groupby('ì œí’ˆë²”ì£¼2'):
        lags = group['lag_days'].values
        n = len(lags)
        
        if n >= 30:  # ì¶©ë¶„í•œ ìƒ˜í”Œ
            mu = np.mean(lags)
            sigma = np.std(lags)
            p90 = np.percentile(lags, 90)
            p95 = np.percentile(lags, 95)
            use_global = False
        else:  # ì†Œí‘œë³¸ - ê¸€ë¡œë²Œ í†µê³„ ì‚¬ìš©
            use_global = True
            mu = None
            sigma = None
            p90 = None
            p95 = None
        
        stats_list.append({
            'product_cat2': product_cat2,
            'mu': mu,
            'sigma': sigma,
            'p90': p90,
            'p95': p95,
            'n': n,
            'use_global': use_global
        })
    
    stats_df = pd.DataFrame(stats_list)
    
    # ê¸€ë¡œë²Œ í†µê³„ ê³„ì‚° (ì†Œí‘œë³¸ìš©)
    global_mu = df_valid['lag_days'].mean()
    global_sigma = df_valid['lag_days'].std()
    global_p90 = df_valid['lag_days'].quantile(0.90)
    global_p95 = df_valid['lag_days'].quantile(0.95)
    
    # ì†Œí‘œë³¸ì— ê¸€ë¡œë²Œ í†µê³„ í• ë‹¹
    stats_df.loc[stats_df['use_global'] == True, 'mu'] = global_mu
    stats_df.loc[stats_df['use_global'] == True, 'sigma'] = global_sigma
    stats_df.loc[stats_df['use_global'] == True, 'p90'] = global_p90
    stats_df.loc[stats_df['use_global'] == True, 'p95'] = global_p95
    
    return stats_df


def label_and_filter(df, ref_stats):
    """
    ì›”ë³„ ë°ì´í„°ì— lag ë¼ë²¨ ë¶€ì—¬ ë° í•„í„°ë§
    
    Args:
        df: ìƒˆë¡œìš´ ì›” ë°ì´í„°
        ref_stats: ê¸°ì¤€ lag í†µê³„ DataFrame
    
    Returns:
        labeled_df: lag_class ì»¬ëŸ¼ ì¶”ê°€ëœ DataFrame
        candidates_df: retrain í›„ë³´ (normal + borderlineë§Œ)
    """
    # lag ê³„ì‚° (ë°œìƒì¼ì - ì œì¡°ì¼ì)
    df['lag_days'] = (pd.to_datetime(df['ë°œìƒì¼ì']) - pd.to_datetime(df['ì œì¡°ì¼ì'])).dt.days
    
    # ì´ˆê¸°í™”: ëª¨ë“  ë ˆì½”ë“œ extremeìœ¼ë¡œ ì‹œì‘
    df['lag_class'] = 'extreme'
    
    # âš ï¸ ìŒìˆ˜ lag (ì œì¡°ì¼ì > ë°œìƒì¼ì) â†’ ì˜ëª» ì ‘ìˆ˜ëœ ì¼€ì´ìŠ¤ë¡œ ë¶„ë¥˜
    invalid_negative_mask = df['lag_days'] < 0
    df.loc[invalid_negative_mask, 'lag_class'] = 'invalid_negative'
    
    print(f"\nâš ï¸  ì˜ëª» ì ‘ìˆ˜ ì¼€ì´ìŠ¤: {invalid_negative_mask.sum():,}ê±´ (ì œì¡°ì¼ì > ë°œìƒì¼ì)")
    
    # ìœ íš¨ ë ˆì½”ë“œ(lag >= 0)ì— ëŒ€í•´ì„œë§Œ ë¼ë²¨ë§
    valid_mask = df['lag_days'] >= 0
    print(f"\nâš ï¸  ì˜ëª» ì ‘ìˆ˜ ì¼€ì´ìŠ¤: {invalid_negative_mask.sum():,}ê±´ (ì œì¡°ì¼ì > ë°œìƒì¼ì)")
    
    # ìœ íš¨ ë ˆì½”ë“œ(lag >= 0)ì— ëŒ€í•´ì„œë§Œ ë¼ë²¨ë§
    valid_mask = df['lag_days'] >= 0
    
    # ì œí’ˆë²”ì£¼2ë³„ ë¼ë²¨ë§
    for idx in df[valid_mask].index:
        product_cat2 = df.loc[idx, 'ì œí’ˆë²”ì£¼2']
        lag = df.loc[idx, 'lag_days']
        
        # í•´ë‹¹ ì œí’ˆë²”ì£¼2ì˜ í†µê³„ ì°¾ê¸°
        stat = ref_stats[ref_stats['product_cat2'] == product_cat2]
        
        if len(stat) == 0:
            # í†µê³„ ì—†ìœ¼ë©´ ê¸€ë¡œë²Œ í†µê³„ ì‚¬ìš©
            global_stat = ref_stats[ref_stats['use_global'] == True].iloc[0]
            mu = global_stat['mu']
            sigma = global_stat['sigma']
        else:
            mu = stat.iloc[0]['mu']
            sigma = stat.iloc[0]['sigma']
        
        # Î¼+Ïƒ ê¸°ì¤€ ë¼ë²¨ë§
        if lag <= mu + sigma:
            df.loc[idx, 'lag_class'] = 'normal'
        elif lag <= mu + 2 * sigma:
            df.loc[idx, 'lag_class'] = 'borderline'
        else:
            df.loc[idx, 'lag_class'] = 'extreme'
    
    # ë¼ë²¨ ë¶„í¬ ì¶œë ¥
    print("\nğŸ“Š Lag ë¼ë²¨ ë¶„í¬:")
    label_counts = df['lag_class'].value_counts()
    print(label_counts)
    print(f"\në¹„ìœ¨:")
    label_pct = df['lag_class'].value_counts(normalize=True) * 100
    for label, pct in label_pct.items():
        print(f"  {label:20s}: {pct:5.1f}%")
    
    # normal + borderlineë§Œ í•™ìŠµ í›„ë³´ (invalid_negativeì™€ extreme ì œì™¸)
    candidates = df[df['lag_class'].isin(['normal', 'borderline'])].copy()
    
    print(f"\nâœ… í•™ìŠµ í›„ë³´: {len(candidates):,}ê±´ / {len(df):,}ê±´ ({len(candidates)/len(df)*100:.1f}%)")
    print(f"   - Normal:     {(df['lag_class'] == 'normal').sum():,}ê±´")
    print(f"   - Borderline: {(df['lag_class'] == 'borderline').sum():,}ê±´")
    print(f"\nâŒ í•™ìŠµ ì œì™¸: {len(df) - len(candidates):,}ê±´")
    print(f"   - Invalid (ìŒìˆ˜ lag): {(df['lag_class'] == 'invalid_negative').sum():,}ê±´")
    print(f"   - Extreme (Î¼+2Ïƒ ì´ˆê³¼): {(df['lag_class'] == 'extreme').sum():,}ê±´")
    
    # weight í• ë‹¹
    candidates['sample_weight'] = candidates['lag_class'].map({
        'normal': 1.0,
        'borderline': 0.5
    })
    
    return df, candidates


def main():
    parser = argparse.ArgumentParser(description='Lag ë¶„ì„ ë° ë¼ë²¨ë§')
    parser.add_argument('--input', required=True, help='ì…ë ¥ CSV íŒŒì¼')
    parser.add_argument('--ref', help='ê¸°ì¤€ lag í†µê³„ CSV (ë¼ë²¨ë§ ëª¨ë“œ)')
    parser.add_argument('--out', help='ì¶œë ¥ lag í†µê³„ CSV (í†µê³„ ì‚°ì¶œ ëª¨ë“œ)')
    parser.add_argument('--policy-out', help='ë¼ë²¨ë§ ê²°ê³¼ CSV (ë¼ë²¨ë§ ëª¨ë“œ)')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("Lag Analyzer - ì œí’ˆë²”ì£¼2ë³„ ë°œìƒì¼ì-ì œì¡°ì¼ì lag ë¶„ì„")
    print("=" * 80)
    
    # ì…ë ¥ íŒŒì¼ ì½ê¸°
    input_path = Path(args.input)
    print(f"\nì…ë ¥: {input_path}")
    
    # ì¸ì½”ë”© ìë™ ê°ì§€ ì‹œë„
    encodings = ['cp949', 'euc-kr', 'utf-8']
    df = None
    for enc in encodings:
        try:
            df = pd.read_csv(input_path, encoding=enc)
            print(f"ì¸ì½”ë”©: {enc}")
            break
        except:
            continue
    
    if df is None:
        raise ValueError(f"íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
    
    print(f"ë ˆì½”ë“œ: {len(df):,}ê±´")
    
    # ì»¬ëŸ¼ëª… ê³ ì • ë§¤í•‘ (ì¶”ê°€ ì»¬ëŸ¼ í—ˆìš©)
    expected_cols = ['ë°œìƒì¼ì', 'ì¤‘ë¶„ë¥˜', 'í”ŒëœíŠ¸', 'ì œí’ˆë²”ì£¼2', 'ì œì¡°ì¼ì', 'count']
    
    # ì»¬ëŸ¼ ìˆ˜ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ë©´ í‘œì¤€í™”
    if len(df.columns) == len(expected_cols):
        df.columns = expected_cols
        print(f"ì»¬ëŸ¼ëª… í‘œì¤€í™” ì™„ë£Œ: {df.columns.tolist()}")
    # ë” ë§ì€ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ (year, month ë“± ì¶”ê°€ ì»¬ëŸ¼ í¬í•¨)
    elif len(df.columns) > len(expected_cols):
        # í•„ìˆ˜ ì»¬ëŸ¼ì´ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
        missing_required = [col for col in expected_cols if col not in df.columns]
        if not missing_required:
            print(f"âœ… í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ì™„ë£Œ (ì¶”ê°€ ì»¬ëŸ¼ í¬í•¨: {[c for c in df.columns if c not in expected_cols]})")
        else:
            # ì²« 6ê°œê°€ í•„ìˆ˜ ì»¬ëŸ¼ ìˆœì„œë¼ê³  ê°€ì •
            df.columns = expected_cols + list(df.columns[len(expected_cols):])
            print(f"ì»¬ëŸ¼ëª… í‘œì¤€í™” ì™„ë£Œ (ì¶”ê°€ ì»¬ëŸ¼ ë³´ì¡´): {df.columns.tolist()}")
    else:
        print(f"ê²½ê³ : ì˜ˆìƒ ì»¬ëŸ¼ ìˆ˜({len(expected_cols)})ë³´ë‹¤ ì ìŠµë‹ˆë‹¤({len(df.columns)}).")
        print(f"í˜„ì¬ ì»¬ëŸ¼: {df.columns.tolist()}")
    
    # countë¥¼ í´ë ˆì„ê±´ìˆ˜ë¡œ ì‚¬ìš©
    if 'count' in df.columns and 'í´ë ˆì„ê±´ìˆ˜' not in df.columns:
        df['í´ë ˆì„ê±´ìˆ˜'] = df['count']

    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ (ë°œìƒì¼ì ì‚¬ìš©)
    required_cols = ['ì œì¡°ì¼ì', 'ë°œìƒì¼ì', 'ì œí’ˆë²”ì£¼2']
    missing = [col for col in required_cols if col not in df.columns]
    if missing:
        print(f"\ní˜„ì¬ ì»¬ëŸ¼: {df.columns.tolist()}")
        raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
    
    # ëª¨ë“œ ë¶„ê¸°
    if args.ref is None:
        # === í†µê³„ ì‚°ì¶œ ëª¨ë“œ ===
        print("\n[ëª¨ë“œ] í†µê³„ ì‚°ì¶œ")
        
        stats_df = calculate_lag_stats(df)
        
        print("\nì œí’ˆë²”ì£¼2ë³„ Lag í†µê³„:")
        print(stats_df.to_string())
        
        if args.out:
            out_path = Path(args.out)
            out_path.parent.mkdir(parents=True, exist_ok=True)
            stats_df.to_csv(out_path, index=False, encoding='utf-8-sig')
            print(f"\nâœ… í†µê³„ ì €ì¥: {out_path}")
        
        # ìš”ì•½ ì¶œë ¥
        print("\n" + "=" * 80)
        print("ìš”ì•½ í†µê³„:")
        print(f"ì œí’ˆë²”ì£¼2 ìˆ˜: {len(stats_df)}")
        print(f"ì†Œí‘œë³¸(<30) ì œí’ˆ: {stats_df['use_global'].sum()}ê°œ")
        print(f"\nì „ì²´ í‰ê·  lag: {stats_df['mu'].mean():.1f}ì¼")
        print(f"ì „ì²´ í‰ê·  sigma: {stats_df['sigma'].mean():.1f}ì¼")
        print("=" * 80)
    
    else:
        # === ë¼ë²¨ë§ ëª¨ë“œ ===
        print("\n[ëª¨ë“œ] ë¼ë²¨ë§ ë° í•„í„°ë§")
        
        ref_path = Path(args.ref)
        print(f"ê¸°ì¤€ í†µê³„: {ref_path}")
        
        ref_stats = pd.read_csv(ref_path)
        print(f"ê¸°ì¤€ ì œí’ˆë²”ì£¼2: {len(ref_stats)}ê°œ")
        
        labeled_df, candidates_df = label_and_filter(df, ref_stats)
        
        print(f"\ní•™ìŠµ í›„ë³´: {len(candidates_df):,}ê±´ / {len(df):,}ê±´ ({len(candidates_df)/len(df)*100:.1f}%)")
        
        if args.policy_out:
            out_path = Path(args.policy_out)
            out_path.parent.mkdir(parents=True, exist_ok=True)
            
            # ì „ì²´ ë¼ë²¨ë§ ê²°ê³¼ ì €ì¥
            labeled_df.to_csv(out_path, index=False, encoding='utf-8-sig')
            print(f"\nâœ… ë¼ë²¨ë§ ê²°ê³¼ ì €ì¥: {out_path}")
            
            # í›„ë³´ ëª©ë¡ë„ ë³„ë„ ì €ì¥
            candidates_path = out_path.parent / f"candidates_{out_path.stem}.csv"
            candidates_df.to_csv(candidates_path, index=False, encoding='utf-8-sig')
            print(f"âœ… í•™ìŠµ í›„ë³´ ì €ì¥: {candidates_path}")
        
        # ì‹œë¦¬ì¦ˆë³„ ìš”ì•½ (í‘œì¤€í™”ëœ ì»¬ëŸ¼ëª… ì‚¬ìš©)
        series_summary = candidates_df.groupby(['í”ŒëœíŠ¸', 'ì œí’ˆë²”ì£¼2', 'ì¤‘ë¶„ë¥˜']).agg({
            'count': 'sum',
            'sample_weight': 'mean',
            'lag_class': lambda x: (x == 'normal').sum()
        }).reset_index()
        series_summary.columns = ['í”ŒëœíŠ¸', 'ì œí’ˆë²”ì£¼2', 'ì¤‘ë¶„ë¥˜', 'ì´í´ë ˆì„', 'í‰ê· ê°€ì¤‘ì¹˜', 'normalê±´ìˆ˜']
        
        print("\nì‹œë¦¬ì¦ˆë³„ ìš”ì•½ (ìƒìœ„ 10ê°œ):")
        print(series_summary.nlargest(10, 'ì´í´ë ˆì„').to_string(index=False))


if __name__ == '__main__':
    main()
