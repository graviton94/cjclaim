"""
Optuna ê¸°ë°˜ SARIMAX í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

ì„±ëŠ¥ì´ ë‚®ì€ ì‹œë¦¬ì¦ˆì— ëŒ€í•´ ìë™ìœ¼ë¡œ ìµœì ì˜ SARIMAX íŒŒë¼ë¯¸í„°ë¥¼ íƒìƒ‰

ì‹¤í–‰ ì˜ˆì‹œ:
    python tools/run_optuna.py --candidates artifacts/metrics/tuning_candidates.csv
    python tools/run_optuna.py --candidates artifacts/metrics/tuning_candidates.csv --timeout 600 --n-trials 40
"""

import sys
import argparse
from pathlib import Path
import pandas as pd
import numpy as np
import warnings
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from concurrent.futures import ProcessPoolExecutor, as_completed
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.metrics import compute_mase, compute_mape

warnings.filterwarnings('ignore')


def objective(trial, y: np.ndarray, seasonal_period: int = 52) -> float:
    """
    Optuna ëª©í‘œ í•¨ìˆ˜ - SARIMAX íŒŒë¼ë¯¸í„° ìµœì í™”
    
    Args:
        trial: Optuna trial ê°ì²´
        y: ì‹œê³„ì—´ ë°ì´í„°
        seasonal_period: ê³„ì ˆ ì£¼ê¸°
    
    Returns:
        ê²€ì¦ MASE ê°’
    """
    from statsmodels.tsa.statespace.sarimax import SARIMAX
    
    # íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„
    p = trial.suggest_int('p', 0, 2)
    d = trial.suggest_int('d', 0, 2)
    q = trial.suggest_int('q', 0, 2)
    P = trial.suggest_int('P', 0, 2)
    D = trial.suggest_int('D', 0, 2)
    Q = trial.suggest_int('Q', 0, 2)
    
    # ë„ˆë¬´ ë³µì¡í•œ ëª¨ë¸ ë°©ì§€
    if (p + d + q + P + D + Q) > 8:
        return float('inf')
    
    try:
        # í•™ìŠµ/ê²€ì¦ ë¶„í•  (80/20)
        train_size = int(len(y) * 0.8)
        y_train = y[:train_size]
        y_val = y[train_size:]
        
        # ëª¨ë¸ í•™ìŠµ
        model = SARIMAX(
            y_train,
            order=(p, d, q),
            seasonal_order=(P, D, Q, seasonal_period),
            enforce_stationarity=False,
            enforce_invertibility=False
        )
        
        fitted = model.fit(disp=False, maxiter=100)
        
        # ê²€ì¦ ì˜ˆì¸¡
        forecast = fitted.forecast(steps=len(y_val))
        
        # MASE ê³„ì‚°
        mase = compute_mase(y_val, forecast, y_train, seasonal_period)
        
        # NaN ì²´í¬
        if np.isnan(mase) or np.isinf(mase):
            return float('inf')
        
        return mase
        
    except Exception as e:
        # ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨ ì‹œ í˜ë„í‹°
        return float('inf')


def tune_single_series(series_id: str,
                      y: np.ndarray,
                      timeout: int = 600,
                      n_trials: int = 40,
                      seasonal_period: int = 52) -> Dict:
    """
    ë‹¨ì¼ ì‹œë¦¬ì¦ˆ íŠœë‹
    
    Args:
        series_id: ì‹œë¦¬ì¦ˆ ID
        y: ì‹œê³„ì—´ ë°ì´í„°
        timeout: ìµœëŒ€ ì‹¤í–‰ ì‹œê°„ (ì´ˆ)
        n_trials: ìµœëŒ€ trial ìˆ˜
        seasonal_period: ê³„ì ˆ ì£¼ê¸°
    
    Returns:
        íŠœë‹ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    import optuna
    
    print(f"  ğŸ”§ íŠœë‹ ì‹œì‘: {series_id}")
    
    # Study ìƒì„±
    study = optuna.create_study(
        direction='minimize',
        sampler=optuna.samplers.TPESampler(seed=42)
    )
    
    # ìµœì í™” ì‹¤í–‰
    try:
        study.optimize(
            lambda trial: objective(trial, y, seasonal_period),
            n_trials=n_trials,
            timeout=timeout,
            show_progress_bar=False
        )
        
        # ê²°ê³¼ ì €ì¥
        result = {
            'series_id': series_id,
            'best_mase': study.best_value,
            'n_trials': len(study.trials),
            'best_params': study.best_params,
            'status': 'success',
        }
        
        print(f"  âœ“ ì™„ë£Œ: {series_id} - MASE: {study.best_value:.4f}")
        
    except Exception as e:
        result = {
            'series_id': series_id,
            'best_mase': np.nan,
            'n_trials': 0,
            'best_params': {},
            'status': f'failed: {str(e)}',
        }
        print(f"  âœ— ì‹¤íŒ¨: {series_id} - {str(e)}")
    
    return result


def tune_series_parallel(candidates_df: pd.DataFrame,
                         curated_path: Path,
                         timeout: int = 600,
                         n_trials: int = 40,
                         max_workers: int = 6,
                         max_series: int = None) -> pd.DataFrame:
    """
    ë³‘ë ¬ë¡œ ì—¬ëŸ¬ ì‹œë¦¬ì¦ˆ íŠœë‹
    
    Args:
        candidates_df: íŠœë‹ í›„ë³´ ì‹œë¦¬ì¦ˆ ë°ì´í„°í”„ë ˆì„
        curated_path: Curated ë°ì´í„° ê²½ë¡œ
        timeout: ì‹œë¦¬ì¦ˆë‹¹ ìµœëŒ€ ì‹œê°„ (ì´ˆ)
        n_trials: ì‹œë¦¬ì¦ˆë‹¹ trial ìˆ˜
        max_workers: ë³‘ë ¬ ì‘ì—…ì ìˆ˜
        max_series: ìµœëŒ€ íŠœë‹ ì‹œë¦¬ì¦ˆ ìˆ˜ (None = ì „ì²´)
    
    Returns:
        íŠœë‹ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
    """
    # ë°ì´í„° ë¡œë“œ
    if not curated_path.exists():
        raise FileNotFoundError(f"Curated ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {curated_path}")
    
    full_data = pd.read_parquet(curated_path)
    
    # ìš°ì„ ìˆœìœ„ ì •ë ¬
    candidates_df = candidates_df.sort_values('priority_score', ascending=False)
    
    if max_series:
        candidates_df = candidates_df.head(max_series)
    
    print(f"\n{'='*70}")
    print(f"Optuna íŠœë‹ ì‹œì‘: {len(candidates_df)}ê°œ ì‹œë¦¬ì¦ˆ")
    print(f"ë³‘ë ¬ ì‘ì—…ì: {max_workers}, Timeout: {timeout}ì´ˆ, Trials: {n_trials}")
    print(f"{'='*70}\n")
    
    # íŠœë‹ ì‘ì—… ì¤€ë¹„
    tasks = []
    for _, row in candidates_df.iterrows():
        series_id = row['series_id']
        series_data = full_data[full_data['series_id'] == series_id]['y'].values
        
        if len(series_data) < 52:
            print(f"  âš ï¸  ë°ì´í„° ë¶€ì¡±: {series_id} ({len(series_data)}ì£¼)")
            continue
        
        tasks.append((series_id, series_data, timeout, n_trials, 52))
    
    # ë³‘ë ¬ ì‹¤í–‰
    results = []
    
    # ìˆœì°¨ ì‹¤í–‰ (ê°„ë‹¨í•œ ë²„ì „)
    for series_id, y, timeout, n_trials, period in tasks:
        result = tune_single_series(series_id, y, timeout, n_trials, period)
        results.append(result)
    
    # ë³‘ë ¬ ì‹¤í–‰ (ì„ íƒì  - ì£¼ì„ ì²˜ë¦¬)
    # with ProcessPoolExecutor(max_workers=max_workers) as executor:
    #     futures = {
    #         executor.submit(tune_single_series, *task): task[0]
    #         for task in tasks
    #     }
    #     
    #     for future in as_completed(futures):
    #         series_id = futures[future]
    #         try:
    #             result = future.result()
    #             results.append(result)
    #         except Exception as e:
    #             print(f"  âœ— ì˜¤ë¥˜: {series_id} - {e}")
    
    return pd.DataFrame(results)


def save_tuned_params(results_df: pd.DataFrame,
                     output_path: Path,
                     year: int = None):
    """
    íŠœë‹ëœ íŒŒë¼ë¯¸í„° ì €ì¥
    
    Args:
        results_df: íŠœë‹ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        output_path: ì¶œë ¥ ë””ë ‰í† ë¦¬
        year: ì—°ë„ (ì„ íƒ)
    """
    output_path.mkdir(parents=True, exist_ok=True)
    
    # ì„±ê³µí•œ íŠœë‹ ê²°ê³¼ë§Œ í•„í„°ë§
    success_df = results_df[results_df['status'] == 'success'].copy()
    
    if len(success_df) == 0:
        print("âš ï¸  ì„±ê³µí•œ íŠœë‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # íŒŒë¼ë¯¸í„° JSON ë³€í™˜
    params_list = []
    for _, row in success_df.iterrows():
        params_list.append({
            'series_id': row['series_id'],
            'params': row['best_params'],
            'mase': row['best_mase'],
        })
    
    # JSON ì €ì¥
    year_suffix = f"_{year}" if year else ""
    json_file = output_path / f'tuned_params{year_suffix}.json'
    
    with open(json_file, 'w') as f:
        json.dump(params_list, f, indent=2)
    
    print(f"\nâœ… íŠœë‹ íŒŒë¼ë¯¸í„° ì €ì¥: {json_file}")
    print(f"   ì„±ê³µ: {len(success_df)}ê°œ ì‹œë¦¬ì¦ˆ")


def generate_tuning_report(results_df: pd.DataFrame,
                          candidates_df: pd.DataFrame,
                          output_path: Path,
                          year: int = None):
    """
    íŠœë‹ ë³´ê³ ì„œ ìƒì„±
    
    Args:
        results_df: íŠœë‹ ê²°ê³¼
        candidates_df: ì›ë³¸ í›„ë³´ ë¦¬ìŠ¤íŠ¸
        output_path: ì¶œë ¥ ê²½ë¡œ
        year: ì—°ë„ (ì„ íƒ)
    """
    output_path.mkdir(parents=True, exist_ok=True)
    
    year_suffix = f"_{year}" if year else ""
    report_file = output_path / f'optuna_tuning_report{year_suffix}.md'
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(f"# Optuna íŠœë‹ ë³´ê³ ì„œ\n\n")
        if year:
            f.write(f"**ì—°ë„**: {year}\n")
        f.write(f"**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("---\n\n")
        
        # 1. ì „ì²´ ìš”ì•½
        f.write("## ğŸ“Š ì „ì²´ ìš”ì•½\n\n")
        f.write(f"- **íŠœë‹ ëŒ€ìƒ**: {len(candidates_df)}ê°œ ì‹œë¦¬ì¦ˆ\n")
        f.write(f"- **íŠœë‹ ì™„ë£Œ**: {len(results_df)}ê°œ ì‹œë¦¬ì¦ˆ\n")
        
        success_count = (results_df['status'] == 'success').sum()
        f.write(f"- **ì„±ê³µ**: {success_count}ê°œ\n")
        f.write(f"- **ì‹¤íŒ¨**: {len(results_df) - success_count}ê°œ\n\n")
        
        # 2. ì„±ëŠ¥ ê°œì„ 
        success_df = results_df[results_df['status'] == 'success'].copy()
        
        if len(success_df) > 0:
            f.write("## ğŸ¯ ì„±ëŠ¥ ê°œì„ \n\n")
            
            # í›„ë³´ ë¦¬ìŠ¤íŠ¸ì™€ ë³‘í•©
            merged = success_df.merge(
                candidates_df[['series_id', 'mape', 'mase']],
                on='series_id',
                how='left',
                suffixes=('_tuned', '_original')
            )
            
            if 'mase_original' in merged.columns:
                merged['mase_improvement'] = (
                    (merged['mase_original'] - merged['best_mase']) / merged['mase_original'] * 100
                )
                
                f.write(f"- **í‰ê·  MASE ê°œì„ **: {merged['mase_improvement'].mean():.2f}%\n")
                f.write(f"- **ìµœëŒ€ MASE ê°œì„ **: {merged['mase_improvement'].max():.2f}%\n\n")
                
                # Top ê°œì„  ì‹œë¦¬ì¦ˆ
                f.write("### Top 10 ê°œì„  ì‹œë¦¬ì¦ˆ\n\n")
                f.write("| Series ID | ì›ë³¸ MASE | íŠœë‹ í›„ MASE | ê°œì„ ìœ¨ (%) |\n")
                f.write("|-----------|-----------|--------------|------------|\n")
                
                top_improved = merged.nlargest(10, 'mase_improvement')
                for _, row in top_improved.iterrows():
                    f.write(f"| {row['series_id']} | {row['mase_original']:.4f} | {row['best_mase']:.4f} | {row['mase_improvement']:+.2f}% |\n")
                
                f.write("\n")
        
        # 3. íŒŒë¼ë¯¸í„° ë¶„í¬
        if len(success_df) > 0:
            f.write("## ğŸ”§ ìµœì  íŒŒë¼ë¯¸í„° ë¶„í¬\n\n")
            
            # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            params_df = pd.DataFrame([
                row['best_params'] for _, row in success_df.iterrows()
            ])
            
            f.write("| íŒŒë¼ë¯¸í„° | í‰ê·  | ìµœë¹ˆê°’ |\n")
            f.write("|----------|------|--------|\n")
            
            for col in ['p', 'd', 'q', 'P', 'D', 'Q']:
                if col in params_df.columns:
                    mean_val = params_df[col].mean()
                    mode_val = params_df[col].mode()[0] if len(params_df[col].mode()) > 0 else 0
                    f.write(f"| {col} | {mean_val:.2f} | {mode_val} |\n")
            
            f.write("\n")
        
        # 4. ì‹¤íŒ¨ ë¶„ì„
        failed_df = results_df[results_df['status'] != 'success']
        if len(failed_df) > 0:
            f.write("## âš ï¸ íŠœë‹ ì‹¤íŒ¨ ì‹œë¦¬ì¦ˆ\n\n")
            f.write(f"ì´ {len(failed_df)}ê°œ ì‹œë¦¬ì¦ˆ\n\n")
            
            f.write("| Series ID | ìƒíƒœ |\n")
            f.write("|-----------|------|\n")
            
            for _, row in failed_df.head(20).iterrows():
                f.write(f"| {row['series_id']} | {row['status']} |\n")
            
            f.write("\n")
        
        f.write("---\n\n")
        f.write("## ë‹¤ìŒ ë‹¨ê³„\n\n")
        f.write("1. **íŠœë‹ëœ íŒŒë¼ë¯¸í„° ì ìš©**: ì¬í•™ìŠµ ë° ì¬ì˜ˆì¸¡\n")
        f.write("2. **ì„±ëŠ¥ ì¬í‰ê°€**: ì‹¤ì¸¡ê°’ê³¼ ë¹„êµ\n")
        f.write("3. **í”„ë¡œë•ì…˜ ë°°í¬**: ê²€ì¦ í›„ ì ìš©\n\n")
    
    print(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_file}")


def main():
    parser = argparse.ArgumentParser(description='Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹')
    parser.add_argument('--candidates', type=str, required=True, help='íŠœë‹ í›„ë³´ CSV íŒŒì¼')
    parser.add_argument('--curated', type=str, default='data/curated/claims.parquet', help='Curated ë°ì´í„° ê²½ë¡œ')
    parser.add_argument('--timeout', type=int, default=600, help='ì‹œë¦¬ì¦ˆë‹¹ ìµœëŒ€ ì‹œê°„ (ì´ˆ)')
    parser.add_argument('--n-trials', type=int, default=40, help='ì‹œë¦¬ì¦ˆë‹¹ trial ìˆ˜')
    parser.add_argument('--max-workers', type=int, default=6, help='ë³‘ë ¬ ì‘ì—…ì ìˆ˜')
    parser.add_argument('--max-series', type=int, default=None, help='ìµœëŒ€ íŠœë‹ ì‹œë¦¬ì¦ˆ ìˆ˜')
    parser.add_argument('--year', type=int, default=None, help='ì—°ë„ (ì„ íƒ)')
    parser.add_argument('--output', type=str, default='artifacts/optuna', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    candidates_path = Path(args.candidates)
    curated_path = Path(args.curated)
    output_path = Path(args.output)
    
    # 1. í›„ë³´ ë¡œë“œ
    if not candidates_path.exists():
        print(f"âŒ íŠœë‹ í›„ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {candidates_path}")
        return
    
    candidates_df = pd.read_csv(candidates_path)
    print(f"ğŸ“‚ íŠœë‹ í›„ë³´ ë¡œë“œ: {len(candidates_df)}ê°œ ì‹œë¦¬ì¦ˆ")
    
    # 2. íŠœë‹ ì‹¤í–‰
    results_df = tune_series_parallel(
        candidates_df=candidates_df,
        curated_path=curated_path,
        timeout=args.timeout,
        n_trials=args.n_trials,
        max_workers=args.max_workers,
        max_series=args.max_series
    )
    
    # 3. ê²°ê³¼ ì €ì¥
    print(f"\n{'='*70}")
    print("ê²°ê³¼ ì €ì¥ ì¤‘...")
    print(f"{'='*70}\n")
    
    output_path.mkdir(parents=True, exist_ok=True)
    
    # ê²°ê³¼ CSV
    year_suffix = f"_{args.year}" if args.year else ""
    results_file = output_path / f'tuning_results{year_suffix}.csv'
    results_df.to_csv(results_file, index=False)
    print(f"âœ“ {results_file}")
    
    # íŒŒë¼ë¯¸í„° JSON
    save_tuned_params(results_df, output_path, args.year)
    
    # ë³´ê³ ì„œ
    generate_tuning_report(results_df, candidates_df, Path('reports'), args.year)
    
    # 4. ìš”ì•½
    print(f"\n{'='*70}")
    print("íŠœë‹ ì™„ë£Œ")
    print(f"{'='*70}\n")
    
    success_count = (results_df['status'] == 'success').sum()
    print(f"ì´ ì‹œë¦¬ì¦ˆ: {len(results_df)}")
    print(f"ì„±ê³µ: {success_count}ê°œ")
    print(f"ì‹¤íŒ¨: {len(results_df) - success_count}ê°œ")
    
    if success_count > 0:
        avg_mase = results_df[results_df['status'] == 'success']['best_mase'].mean()
        print(f"\ní‰ê·  íŠœë‹ í›„ MASE: {avg_mase:.4f}")
    
    print(f"\n{'='*70}\n")


if __name__ == '__main__':
    main()
