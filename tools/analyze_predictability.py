"""
ì˜ˆì¸¡ ê°€ëŠ¥ì„± ë¶„ì„ ë„êµ¬

í•™ìŠµëœ ëª¨ë¸ë“¤ì„ ë¶„ì„í•˜ì—¬:
1. ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì‹œë¦¬ì¦ˆ vs ë¶ˆê°€ëŠ¥í•œ ì‹œë¦¬ì¦ˆ ë¶„ë¥˜
2. ì§‘ì¤‘í•´ì•¼ í•  ì‹œë¦¬ì¦ˆ ì¶”ì²œ
3. ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±

ì‹¤í–‰ ì˜ˆì‹œ:
    python tools/analyze_predictability.py
    python tools/analyze_predictability.py --threshold 0.6
"""

import sys
import argparse
from pathlib import Path
import pandas as pd
import json
from datetime import datetime
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def load_all_models(models_dir: Path) -> pd.DataFrame:
    """ëª¨ë“  í•™ìŠµëœ ëª¨ë¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
    
    model_files = list(models_dir.glob("*.json"))
    
    if not model_files:
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {models_dir}")
    
    models_data = []
    
    for model_file in model_files:
        with open(model_file, 'r', encoding='utf-8') as f:
            model_data = json.load(f)
            
            # ì‹¤íŒ¨í•œ ëª¨ë¸ ìŠ¤í‚µ
            if model_data.get('status') == 'failed':
                continue
            
            models_data.append({
                'series_id': model_data['series_id'],
                'model_type': model_data['model_type'],
                'n_train_points': model_data['n_train_points'],
                'predictability_score': model_data.get('predictability_score', 0.5),
                'is_sparse': model_data['guard_results']['is_sparse'],
                'zero_ratio': model_data['guard_results']['zero_ratio'],
                'has_drift': model_data['guard_results']['has_drift'],
                'has_seasonality': model_data['guard_results']['has_seasonality'],
                'seasonality_strength': model_data['guard_results']['seasonality_strength'],
                'mean': model_data['historical_stats']['mean'],
                'std': model_data['historical_stats']['std'],
                'nonzero_pct': model_data['historical_stats']['nonzero_pct'],
            })
    
    return pd.DataFrame(models_data)


def classify_series(df: pd.DataFrame, 
                    high_threshold: float = 0.7,
                    low_threshold: float = 0.4) -> pd.DataFrame:
    """
    ì‹œë¦¬ì¦ˆë¥¼ ì˜ˆì¸¡ ê°€ëŠ¥ì„±ì— ë”°ë¼ ë¶„ë¥˜
    
    Args:
        df: ëª¨ë¸ ë°ì´í„°í”„ë ˆì„
        high_threshold: ë†’ì€ ì˜ˆì¸¡ ê°€ëŠ¥ì„± ì„ê³„ê°’
        low_threshold: ë‚®ì€ ì˜ˆì¸¡ ê°€ëŠ¥ì„± ì„ê³„ê°’
    
    Returns:
        ë¶„ë¥˜ ê²°ê³¼ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    df = df.copy()
    
    def get_category(score):
        if score >= high_threshold:
            return 'high'
        elif score >= low_threshold:
            return 'medium'
        else:
            return 'low'
    
    df['predictability_category'] = df['predictability_score'].apply(get_category)
    
    # ì§‘ì¤‘ ê¶Œì¥ í”Œë˜ê·¸
    df['focus_recommended'] = (
        (df['predictability_category'] == 'high') &
        (df['mean'] > df['mean'].quantile(0.25))  # ì¶©ë¶„í•œ ë³¼ë¥¨
    )
    
    return df


def generate_analysis_report(df: pd.DataFrame, 
                             output_path: Path,
                             high_threshold: float,
                             low_threshold: float):
    """ì˜ˆì¸¡ ê°€ëŠ¥ì„± ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
    
    output_path.mkdir(parents=True, exist_ok=True)
    report_file = output_path / 'predictability_analysis.md'
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# ì˜ˆì¸¡ ê°€ëŠ¥ì„± ë¶„ì„ ë³´ê³ ì„œ\n\n")
        f.write(f"**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("---\n\n")
        
        # 1. ì „ì²´ ìš”ì•½
        f.write("## ğŸ“Š ì „ì²´ ìš”ì•½\n\n")
        
        total = len(df)
        high_count = (df['predictability_category'] == 'high').sum()
        medium_count = (df['predictability_category'] == 'medium').sum()
        low_count = (df['predictability_category'] == 'low').sum()
        focus_count = df['focus_recommended'].sum()
        
        f.write(f"- **ì´ ì‹œë¦¬ì¦ˆ ìˆ˜**: {total:,}ê°œ\n")
        f.write(f"- **í‰ê·  ì˜ˆì¸¡ ê°€ëŠ¥ì„± ìŠ¤ì½”ì–´**: {df['predictability_score'].mean():.3f}\n\n")
        
        f.write("### ì˜ˆì¸¡ ê°€ëŠ¥ì„± ë¶„í¬\n\n")
        f.write(f"- ğŸŸ¢ **ë†’ìŒ** (â‰¥{high_threshold}): {high_count:,}ê°œ ({high_count/total*100:.1f}%)\n")
        f.write(f"- ğŸŸ¡ **ì¤‘ê°„** ({low_threshold}~{high_threshold}): {medium_count:,}ê°œ ({medium_count/total*100:.1f}%)\n")
        f.write(f"- ğŸ”´ **ë‚®ìŒ** (<{low_threshold}): {low_count:,}ê°œ ({low_count/total*100:.1f}%)\n\n")
        
        f.write(f"### ğŸ¯ ì§‘ì¤‘ ê¶Œì¥ ì‹œë¦¬ì¦ˆ\n\n")
        f.write(f"**{focus_count:,}ê°œ** ì‹œë¦¬ì¦ˆì— ì§‘ì¤‘í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n")
        f.write("(ë†’ì€ ì˜ˆì¸¡ ê°€ëŠ¥ì„± + ì¶©ë¶„í•œ ë³¼ë¥¨)\n\n")
        
        # 2. ëª¨ë¸ íƒ€ì…ë³„ ë¶„ì„
        f.write("## ğŸ”§ ëª¨ë¸ íƒ€ì…ë³„ ì˜ˆì¸¡ ê°€ëŠ¥ì„±\n\n")
        
        model_analysis = df.groupby('model_type').agg({
            'predictability_score': ['mean', 'count'],
            'series_id': 'count'
        }).round(3)
        
        f.write("| ëª¨ë¸ íƒ€ì… | ì‹œë¦¬ì¦ˆ ìˆ˜ | í‰ê·  ìŠ¤ì½”ì–´ |\n")
        f.write("|----------|-----------|-------------|\n")
        
        for model_type in df['model_type'].unique():
            model_df = df[df['model_type'] == model_type]
            count = len(model_df)
            avg_score = model_df['predictability_score'].mean()
            f.write(f"| {model_type} | {count} | {avg_score:.3f} |\n")
        
        f.write("\n")
        
        # 3. ì§‘ì¤‘ ê¶Œì¥ ì‹œë¦¬ì¦ˆ ëª©ë¡
        f.write("## ğŸ¯ ì§‘ì¤‘ ê¶Œì¥ ì‹œë¦¬ì¦ˆ (Top 50)\n\n")
        
        focus_series = df[df['focus_recommended'] == True].sort_values(
            'predictability_score', ascending=False
        ).head(50)
        
        if len(focus_series) > 0:
            f.write("| ìˆœìœ„ | Series ID | ìŠ¤ì½”ì–´ | ëª¨ë¸ | í‰ê· ê°’ | ê³„ì ˆì„± |\n")
            f.write("|------|-----------|--------|------|--------|--------|\n")
            
            for rank, (_, row) in enumerate(focus_series.iterrows(), 1):
                seasonality = "âœ“" if row['has_seasonality'] else "âœ—"
                f.write(f"| {rank} | {row['series_id']} | {row['predictability_score']:.3f} | {row['model_type']} | {row['mean']:.1f} | {seasonality} |\n")
            
            f.write("\n")
        else:
            f.write("ì§‘ì¤‘ ê¶Œì¥ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤.\n\n")
        
        # 4. ë¬¸ì œ ì‹œë¦¬ì¦ˆ (ë‚®ì€ ì˜ˆì¸¡ ê°€ëŠ¥ì„±)
        f.write("## âš ï¸ ì˜ˆì¸¡ ì–´ë ¤ìš´ ì‹œë¦¬ì¦ˆ (ë‚®ì€ ìŠ¤ì½”ì–´ Top 30)\n\n")
        
        problem_series = df[df['predictability_category'] == 'low'].sort_values(
            'predictability_score'
        ).head(30)
        
        if len(problem_series) > 0:
            f.write("| Series ID | ìŠ¤ì½”ì–´ | ì£¼ìš” ë¬¸ì œ | ëª¨ë¸ |\n")
            f.write("|-----------|--------|-----------|------|\n")
            
            for _, row in problem_series.iterrows():
                issues = []
                if row['is_sparse']:
                    issues.append(f"í¬ì†Œ({row['zero_ratio']*100:.0f}%)")
                if row['has_drift']:
                    issues.append("ë“œë¦¬í”„íŠ¸")
                if not row['has_seasonality']:
                    issues.append("ê³„ì ˆì„±â†“")
                
                issue_str = ", ".join(issues) if issues else "-"
                f.write(f"| {row['series_id']} | {row['predictability_score']:.3f} | {issue_str} | {row['model_type']} |\n")
            
            f.write("\n")
        
        # 5. íŠ¹ì„±ë³„ ë¶„ì„
        f.write("## ğŸ“ˆ ì‹œë¦¬ì¦ˆ íŠ¹ì„± ë¶„ì„\n\n")
        
        f.write("### í¬ì†Œë„ ì˜í–¥\n\n")
        sparse_df = df.groupby('is_sparse')['predictability_score'].agg(['mean', 'count'])
        f.write(f"- í¬ì†Œ ì‹œë¦¬ì¦ˆ: í‰ê·  ìŠ¤ì½”ì–´ {sparse_df.loc[True, 'mean']:.3f} ({sparse_df.loc[True, 'count']}ê°œ)\n")
        f.write(f"- ë°€ì§‘ ì‹œë¦¬ì¦ˆ: í‰ê·  ìŠ¤ì½”ì–´ {sparse_df.loc[False, 'mean']:.3f} ({sparse_df.loc[False, 'count']}ê°œ)\n\n")
        
        f.write("### ê³„ì ˆì„± ì˜í–¥\n\n")
        seasonal_df = df.groupby('has_seasonality')['predictability_score'].agg(['mean', 'count'])
        f.write(f"- ê³„ì ˆì„± ìˆìŒ: í‰ê·  ìŠ¤ì½”ì–´ {seasonal_df.loc[True, 'mean']:.3f} ({seasonal_df.loc[True, 'count']}ê°œ)\n")
        f.write(f"- ê³„ì ˆì„± ì—†ìŒ: í‰ê·  ìŠ¤ì½”ì–´ {seasonal_df.loc[False, 'mean']:.3f} ({seasonal_df.loc[False, 'count']}ê°œ)\n\n")
        
        f.write("### ë“œë¦¬í”„íŠ¸ ì˜í–¥\n\n")
        drift_df = df.groupby('has_drift')['predictability_score'].agg(['mean', 'count'])
        if True in drift_df.index and False in drift_df.index:
            f.write(f"- ë“œë¦¬í”„íŠ¸ ìˆìŒ: í‰ê·  ìŠ¤ì½”ì–´ {drift_df.loc[True, 'mean']:.3f} ({drift_df.loc[True, 'count']}ê°œ)\n")
            f.write(f"- ë“œë¦¬í”„íŠ¸ ì—†ìŒ: í‰ê·  ìŠ¤ì½”ì–´ {drift_df.loc[False, 'mean']:.3f} ({drift_df.loc[False, 'count']}ê°œ)\n\n")
        
        # 6. ì¶”ì²œ ì‚¬í•­
        f.write("## ğŸ’¡ ì¶”ì²œ ì‚¬í•­\n\n")
        
        f.write(f"### ì¦‰ì‹œ í™œìš© ê°€ëŠ¥ ({high_count}ê°œ ì‹œë¦¬ì¦ˆ)\n")
        f.write(f"ë†’ì€ ì˜ˆì¸¡ ê°€ëŠ¥ì„± ì‹œë¦¬ì¦ˆëŠ” ì¦‰ì‹œ í”„ë¡œë•ì…˜ ì˜ˆì¸¡ì— í™œìš©í•˜ì„¸ìš”.\n\n")
        
        if medium_count > 0:
            f.write(f"### ê°œì„  í›„ í™œìš© ({medium_count}ê°œ ì‹œë¦¬ì¦ˆ)\n")
            f.write("ì¤‘ê°„ ì˜ˆì¸¡ ê°€ëŠ¥ì„± ì‹œë¦¬ì¦ˆëŠ” ë‹¤ìŒ ë°©ë²•ìœ¼ë¡œ ê°œì„ :\n")
            f.write("- Bias ë³´ì • ì ìš©\n")
            f.write("- Seasonal Recalibration\n")
            f.write("- Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n\n")
        
        if low_count > 0:
            f.write(f"### ëŒ€ì²´ ë°©ë²• ê³ ë ¤ ({low_count}ê°œ ì‹œë¦¬ì¦ˆ)\n")
            f.write("ë‚®ì€ ì˜ˆì¸¡ ê°€ëŠ¥ì„± ì‹œë¦¬ì¦ˆëŠ”:\n")
            f.write("- ë‹¨ìˆœ Naive ì˜ˆì¸¡ ì‚¬ìš©\n")
            f.write("- ë„ë©”ì¸ ì „ë¬¸ê°€ ì˜ê²¬ í™œìš©\n")
            f.write("- ì¶”ê°€ ì™¸ë¶€ ë³€ìˆ˜ ìˆ˜ì§‘ ê³ ë ¤\n\n")
        
        f.write("---\n\n")
        f.write("## ë‹¤ìŒ ë‹¨ê³„\n\n")
        f.write("1. **ì§‘ì¤‘ ì‹œë¦¬ì¦ˆ CSV ìƒì„±**: ë†’ì€ ì˜ˆì¸¡ ê°€ëŠ¥ì„± ì‹œë¦¬ì¦ˆ ëª©ë¡\n")
        f.write("2. **ë¬¸ì œ ì‹œë¦¬ì¦ˆ ë¶„ì„**: ì˜ˆì¸¡ ì–´ë ¤ìš´ ì‹œë¦¬ì¦ˆ ì›ì¸ íŒŒì•…\n")
        f.write("3. **ì„ íƒì  íŠœë‹**: ì¤‘ê°„ ì¹´í…Œê³ ë¦¬ ì‹œë¦¬ì¦ˆë§Œ Optuna ì ìš©\n\n")
    
    print(f"\nâœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_file}")


def save_category_lists(df: pd.DataFrame, output_path: Path):
    """ì¹´í…Œê³ ë¦¬ë³„ ì‹œë¦¬ì¦ˆ ëª©ë¡ CSV ì €ì¥"""
    
    output_path.mkdir(parents=True, exist_ok=True)
    
    # ì§‘ì¤‘ ê¶Œì¥ ì‹œë¦¬ì¦ˆ
    focus_series = df[df['focus_recommended'] == True].sort_values(
        'predictability_score', ascending=False
    )
    focus_file = output_path / 'focus_series.csv'
    focus_series[['series_id', 'predictability_score', 'model_type', 'mean', 'has_seasonality']].to_csv(
        focus_file, index=False
    )
    print(f"âœ“ ì§‘ì¤‘ ê¶Œì¥ ì‹œë¦¬ì¦ˆ: {focus_file} ({len(focus_series)}ê°œ)")
    
    # ë¬¸ì œ ì‹œë¦¬ì¦ˆ
    problem_series = df[df['predictability_category'] == 'low'].sort_values(
        'predictability_score'
    )
    problem_file = output_path / 'problem_series.csv'
    problem_series[['series_id', 'predictability_score', 'is_sparse', 'has_drift', 'has_seasonality']].to_csv(
        problem_file, index=False
    )
    print(f"âœ“ ë¬¸ì œ ì‹œë¦¬ì¦ˆ: {problem_file} ({len(problem_series)}ê°œ)")
    
    # ì „ì²´ ë¶„ë¥˜ ê²°ê³¼
    all_file = output_path / 'all_series_classified.csv'
    df.to_csv(all_file, index=False)
    print(f"âœ“ ì „ì²´ ë¶„ë¥˜ ê²°ê³¼: {all_file} ({len(df)}ê°œ)")


def main():
    parser = argparse.ArgumentParser(description='ì˜ˆì¸¡ ê°€ëŠ¥ì„± ë¶„ì„')
    parser.add_argument('--models-dir', type=str, default='artifacts/models', help='ëª¨ë¸ ë””ë ‰í† ë¦¬')
    parser.add_argument('--output', type=str, default='reports', help='ë³´ê³ ì„œ ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--high-threshold', type=float, default=0.7, help='ë†’ì€ ì˜ˆì¸¡ ê°€ëŠ¥ì„± ì„ê³„ê°’')
    parser.add_argument('--low-threshold', type=float, default=0.4, help='ë‚®ì€ ì˜ˆì¸¡ ê°€ëŠ¥ì„± ì„ê³„ê°’')
    
    args = parser.parse_args()
    
    models_dir = Path(args.models_dir)
    output_path = Path(args.output)
    
    print(f"\n{'='*70}")
    print("ì˜ˆì¸¡ ê°€ëŠ¥ì„± ë¶„ì„")
    print(f"{'='*70}\n")
    
    # 1. ëª¨ë¸ ë¡œë“œ
    print("ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    df = load_all_models(models_dir)
    print(f"   âœ“ {len(df)}ê°œ ì‹œë¦¬ì¦ˆ ë¡œë“œ ì™„ë£Œ\n")
    
    # 2. ë¶„ë¥˜
    print("ğŸ” ì‹œë¦¬ì¦ˆ ë¶„ë¥˜ ì¤‘...")
    df = classify_series(df, args.high_threshold, args.low_threshold)
    print(f"   âœ“ ë¶„ë¥˜ ì™„ë£Œ\n")
    
    # 3. í†µê³„ ì¶œë ¥
    print("ğŸ“Š ë¶„ë¥˜ ê²°ê³¼:")
    print(f"   ğŸŸ¢ ë†’ìŒ (â‰¥{args.high_threshold}): {(df['predictability_category']=='high').sum()}ê°œ")
    print(f"   ğŸŸ¡ ì¤‘ê°„ ({args.low_threshold}~{args.high_threshold}): {(df['predictability_category']=='medium').sum()}ê°œ")
    print(f"   ğŸ”´ ë‚®ìŒ (<{args.low_threshold}): {(df['predictability_category']=='low').sum()}ê°œ")
    print(f"   ğŸ¯ ì§‘ì¤‘ ê¶Œì¥: {df['focus_recommended'].sum()}ê°œ\n")
    
    # 4. ë³´ê³ ì„œ ìƒì„±
    print("ğŸ“ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
    generate_analysis_report(df, output_path, args.high_threshold, args.low_threshold)
    
    # 5. ì¹´í…Œê³ ë¦¬ë³„ ëª©ë¡ ì €ì¥
    print("\nğŸ’¾ ì¹´í…Œê³ ë¦¬ë³„ ëª©ë¡ ì €ì¥ ì¤‘...")
    save_category_lists(df, output_path)
    
    print(f"\n{'='*70}")
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print(f"{'='*70}\n")


if __name__ == '__main__':
    main()
