"""
ì˜ˆì¸¡ê°’ vs ì‹¤ì œê°’ ë¹„êµ í‰ê°€
- 2025ë…„ ë°ì´í„° ì—…ë¡œë“œ ì‹œ ê¸°ì¡´ ì˜ˆì¸¡ê³¼ ë¹„êµ
- ê° ì‹œë¦¬ì¦ˆë³„ ì˜ˆì¸¡ ì„±ëŠ¥ ê³„ì‚° ë° ì €ì¥
"""
import pandas as pd
import json
from pathlib import Path
import numpy as np
from datetime import datetime


def calculate_metrics(actual, predicted):
    """ì˜ˆì¸¡ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"""
    actual = np.array(actual)
    predicted = np.array(predicted)
    
    # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒ ë°©ì§€
    mask = actual != 0
    
    # MAPE (Mean Absolute Percentage Error)
    if mask.sum() > 0:
        mape = np.mean(np.abs((actual[mask] - predicted[mask]) / actual[mask])) * 100
    else:
        mape = None
    
    # MAE (Mean Absolute Error)
    mae = np.mean(np.abs(actual - predicted))
    
    # RMSE (Root Mean Squared Error)
    rmse = np.sqrt(np.mean((actual - predicted) ** 2))
    
    # RÂ² Score
    ss_res = np.sum((actual - predicted) ** 2)
    ss_tot = np.sum((actual - np.mean(actual)) ** 2)
    r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else None
    
    return {
        'mape': float(mape) if mape is not None else None,
        'mae': float(mae),
        'rmse': float(rmse),
        'r2': float(r2) if r2 is not None else None,
        'n_points': int(len(actual))
    }


def evaluate_predictions(year, output_path=None):
    """
    ê¸°ì¡´ ì˜ˆì¸¡ê°’ê³¼ ìƒˆë¡œ ì¶”ê°€ëœ ì‹¤ì œê°’ì„ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ í‰ê°€
    """
    print("=" * 80)
    print("ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€ ì‹œì‘")
    print("=" * 80)
    
    # ê²½ë¡œ ì„¤ì •
    curated_path = Path('data/curated/claims.parquet')
    models_dir = Path('artifacts/models')
    eval_dir = Path('artifacts/evaluations')
    eval_dir.mkdir(parents=True, exist_ok=True)
    
    if not curated_path.exists():
        print("âŒ Curated ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    if not models_dir.exists():
        print("âŒ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # Curated ë°ì´í„° ë¡œë“œ
    df = pd.read_parquet(curated_path)
    
    # í•´ë‹¹ ì—°ë„ ë°ì´í„°ë§Œ ì¶”ì¶œ (í‰ê°€ ëŒ€ìƒ)
    df_year = df[df['year'] == year].copy()
    
    if len(df_year) == 0:
        print(f"â„¹ï¸ {year}ë…„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“Š {year}ë…„ ë°ì´í„°: {len(df_year):,}í–‰")
    
    # ì£¼ì°¨ ë²”ìœ„ í™•ì¸
    weeks_year = sorted(df_year['week'].unique())
    print(f"ğŸ“… {year}ë…„ ì£¼ì°¨ ë²”ìœ„: W{min(weeks_year):02d} ~ W{max(weeks_year):02d} ({len(weeks_year)}ì£¼)")
    
    # ê° ì‹œë¦¬ì¦ˆë³„ í‰ê°€
    evaluations = []
    series_list = df_year['series_id'].unique()
    
    print(f"\nğŸ” {len(series_list)}ê°œ ì‹œë¦¬ì¦ˆ í‰ê°€ ì¤‘...")
    
    for i, series_id in enumerate(series_list, 1):
        if i % 100 == 0:
            print(f"  ì§„í–‰: {i}/{len(series_list)}")
        
        # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
        safe_filename = "".join(c if c.isalnum() or c in ('-', '_') else '_' for c in series_id)
        model_path = models_dir / f"{safe_filename}.json"
        
        if not model_path.exists():
            continue
        
        # ëª¨ë¸ ë°ì´í„° ë¡œë“œ
        try:
            with open(model_path, 'r', encoding='utf-8') as f:
                model_data = json.load(f)
        except:
            continue
        
        # ì˜ˆì¸¡ê°’ ì¶”ì¶œ
        if 'forecast' not in model_data:
            continue
        
        forecast = model_data['forecast']
        predicted_values = forecast['yhat']  # 26ì£¼ ì˜ˆì¸¡ê°’
        
        # ì‹¤ì œê°’ ì¶”ì¶œ (í•´ë‹¹ ì—°ë„ í•´ë‹¹ ì‹œë¦¬ì¦ˆ)
        df_series = df_year[df_year['series_id'] == series_id].copy()
        df_series = df_series.sort_values('week')
        
        actual_weeks = df_series['week'].tolist()
        actual_values = df_series['claim_count'].tolist()
        
        # ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ë§¤ì¹­ (ì£¼ì°¨ ê¸°ì¤€)
        # ì˜ˆì¸¡ì€ 2025-W01ë¶€í„° ì‹œì‘í•œë‹¤ê³  ê°€ì •
        matched_predicted = []
        matched_actual = []
        
        for week, actual_count in zip(actual_weeks, actual_values):
            # weekëŠ” 1ë¶€í„° ì‹œì‘ (2025-W01 = 1)
            pred_idx = week - 1  # 0-based index
            
            if 0 <= pred_idx < len(predicted_values):
                matched_predicted.append(predicted_values[pred_idx])
                matched_actual.append(actual_count)
        
        if len(matched_actual) == 0:
            continue
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        metrics = calculate_metrics(matched_actual, matched_predicted)
        
        evaluations.append({
            'series_id': series_id,
            'plant': series_id.split('|')[0] if '|' in series_id else 'Unknown',
            'product_cat2': series_id.split('|')[1] if '|' in series_id and len(series_id.split('|')) > 1 else 'Unknown',
            'mid_category': series_id.split('|')[2] if '|' in series_id and len(series_id.split('|')) > 2 else 'Unknown',
            'weeks_evaluated': actual_weeks,
            'actual_values': matched_actual,
            'predicted_values': matched_predicted,
            'metrics': metrics,
            'evaluation_date': datetime.now().isoformat()
        })
    
    print(f"\nâœ… {len(evaluations)}ê°œ ì‹œë¦¬ì¦ˆ í‰ê°€ ì™„ë£Œ")
    
    if len(evaluations) == 0:
        print("âš ï¸ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê²°ê³¼ ì €ì¥
    result = {
        'evaluation_date': datetime.now().isoformat(),
        'weeks_range': {'min': int(min(weeks_year)), 'max': int(max(weeks_year))},
        'n_series': len(evaluations),
        'evaluations': evaluations
    }
    
    if output_path:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
    else:
        eval_path = eval_dir / f"evaluation_{year}.json"
        with open(eval_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ í‰ê°€ ê²°ê³¼ ì €ì¥: {eval_path}")
    
    # ìš”ì•½ í†µê³„
    all_mapes = [e['metrics']['mape'] for e in evaluations if e['metrics']['mape'] is not None]
    all_maes = [e['metrics']['mae'] for e in evaluations]
    all_rmses = [e['metrics']['rmse'] for e in evaluations]
    
    print("\n" + "=" * 80)
    print("ğŸ“ˆ í‰ê°€ ìš”ì•½")
    print("=" * 80)
    print(f"í‰ê°€ ì‹œë¦¬ì¦ˆ: {len(evaluations)}ê°œ")
    print(f"í‰ê°€ ì£¼ì°¨: W{min(weeks_year):02d} ~ W{max(weeks_year):02d}")
    
    if all_mapes:
        print(f"\nMAPE í‰ê· : {np.mean(all_mapes):.2f}%")
        print(f"MAPE ì¤‘ì•™ê°’: {np.median(all_mapes):.2f}%")
    
    print(f"\nMAE í‰ê· : {np.mean(all_maes):.4f}")
    print(f"MAE ì¤‘ì•™ê°’: {np.median(all_maes):.4f}")
    
    print(f"\nRMSE í‰ê· : {np.mean(all_rmses):.4f}")
    print(f"RMSE ì¤‘ì•™ê°’: {np.median(all_rmses):.4f}")
    
    # Top/Bottom ì‹œë¦¬ì¦ˆ
    if all_mapes:
        sorted_by_mape = sorted(evaluations, key=lambda x: x['metrics']['mape'] if x['metrics']['mape'] is not None else float('inf'))
        
        print("\nğŸ† ì˜ˆì¸¡ ì •í™•ë„ Top 5:")
        for i, e in enumerate(sorted_by_mape[:5], 1):
            print(f"  {i}. {e['series_id']}: MAPE {e['metrics']['mape']:.2f}%")
        
        print("\nâš ï¸ ì˜ˆì¸¡ ì •í™•ë„ Bottom 5:")
        for i, e in enumerate(sorted_by_mape[-5:][::-1], 1):
            mape = e['metrics']['mape'] if e['metrics']['mape'] is not None else 'N/A'
            print(f"  {i}. {e['series_id']}: MAPE {mape if mape == 'N/A' else f'{mape:.2f}%'}")
    
    print("=" * 80)


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--year", type=int, required=True)
    parser.add_argument("--month", type=int, required=False)
    parser.add_argument("--output", type=str, required=True)
    args = parser.parse_args()
    evaluate_predictions(args.year, args.output)
