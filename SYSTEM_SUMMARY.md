# ì›”ë³„ ì¦ë¶„í•™ìŠµ ì‹œìŠ¤í…œ - EWS v2 Complete System

## ğŸ‰ ì‹œìŠ¤í…œ ê°œìš”

### âœ… EWS v2 ì£¼ìš” ì—…ê·¸ë ˆì´ë“œ

1. **5-Factor Early Warning System** - Growth/Confidence/Seasonality/Amplitude/Inflection ê¸°ë°˜ ìœ„í—˜ë„ í‰ê°€
2. **3-Metric KPI** - WMAPE/SMAPE/Bias í†µí•© í‰ê°€ (ê¸°ì¡´ ë‹¨ì¼ MAPE ëŒ€ì²´)
3. **Weight Learning** - Logistic Regression + Rolling 3-Fold CV ìë™ ìµœì í™”
4. **Manifest System** - Git commit, data hash, seed ê¸°ë°˜ ì¬í˜„ì„± ë³´ì¥
5. **Enhanced Sparse Filter** - avg<0.5 OR nonzero<30% ìë™ ì œì™¸
6. **Monthly Transition** - ì£¼ê°„(Weekly) â†’ ì›”ë³„(Monthly) ì™„ì „ ì „í™˜

### ğŸ“Š Fresh Start Configuration

- **í•™ìŠµ ê¸°ê°„**: 2021ë…„ 1ì›” ~ 2023ë…„ 12ì›” (ì›”ë³„ ë°ì´í„°)
- **ë°ì´í„° ê·œëª¨**: ~15ë§Œ rows (2021_raw: 5ë§Œ + 2022_raw: 5ë§Œ + 2023_raw: 5ë§Œ)
- **ë°ì´í„° ìœ„ì¹˜**:
  - Archive: `C:\cjclaim\data\` (ì‚¬ìš©ì ì—…ë¡œë“œ, ì˜êµ¬ ë³´ê´€)
  - Working: `quality-cycles\data\` (íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬, git-ignored)
- **ëª©í‘œ ì„±ëŠ¥**:
  - WMAPE Excellent: >30% of series (<20%)
  - F1 Score (EWS): â‰¥0.75
  - SMAPE Mean: <30%
  - Bias Mean: Â±10%

---

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡° (EWS v2)

```
quality-cycles/
â”œâ”€â”€ ğŸ“Š ë°ì´í„° ì¤€ë¹„ (Fresh Start)
â”‚   â”œâ”€â”€ merge_yearly_data.py               # â­ 2021+2022+2023 CSV ë³‘í•©
â”‚   â”œâ”€â”€ tools/lag_analyzer.py              # â­ Lag í•„í„°ë§ (Î¼+Ïƒ ë°©ì‹, Normal/Borderline/Extreme)
â”‚   â”œâ”€â”€ preprocess_to_curated.py           # ì›”ë³„ ì§‘ê³„ ë° ì „ì²˜ë¦¬
â”‚   â””â”€â”€ generate_series_json.py            # ì‹œë¦¬ì¦ˆë³„ JSON ìƒì„±
â”‚
â”œâ”€â”€ ğŸ§  ëª¨ë¸ í•™ìŠµ (3-Metric KPI)
â”‚   â”œâ”€â”€ train_base_models.py               # â­ Base í•™ìŠµ (WMAPE/SMAPE/Bias + Manifest)
â”‚   â””â”€â”€ train_incremental_models.py        # ì¦ë¶„í•™ìŠµ (Warm Start) [TODO: 3-Metric ì ìš©]
â”‚
â”œâ”€â”€ ğŸš¨ EWS v2 ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ src/ews_scoring_v2.py              # â­â­ 5-Factor Scoring Engine
â”‚   â”œâ”€â”€ src/metrics_v2.py                  # â­â­ 3-Metric KPI (WMAPE/SMAPE/Bias)
â”‚   â”œâ”€â”€ src/manifest.py                    # â­â­ Reproducibility Tracking
â”‚   â”œâ”€â”€ backtest_ews_weights.py            # â­ Weight Learning (Logistic + Rolling CV)
â”‚   â”‚
â”‚   â”œâ”€â”€ src/ews_scoring.py                 # [OLD v1] ë‹¨ì¼ ì ìˆ˜ ë°©ì‹
â”‚   â””â”€â”€ src/metrics.py                     # [OLD v1] MAPE ë‹¨ì¼ ì§€í‘œ
â”‚
â”œâ”€â”€ ğŸ”„ ì›”ë³„ ì¦ë¶„í•™ìŠµ
â”‚   â”œâ”€â”€ process_monthly_data.py            # ì›”ë³„ íŒŒì´í”„ë¼ì¸ (5ë‹¨ê³„)
â”‚   â”œâ”€â”€ generate_forecast_monthly.py       # ì˜ˆì¸¡ ìƒì„± (6ê°œì›” horizon)
â”‚   â””â”€â”€ reconcile_pipeline.py              # Reconcile ë³´ì • (3ë‹¨ê³„)
â”‚
â”œâ”€â”€ ğŸ® ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤
â”‚   â”œâ”€â”€ batch.py                           # í†µí•© CLI (train/forecast/reconcile/...)
â”‚   â”œâ”€â”€ app.py                             # ê¸°ì¡´ Streamlit UI
â”‚   â””â”€â”€ app_incremental.py                 # ì›”ë³„ ì¦ë¶„í•™ìŠµ UI
â”‚
â”œâ”€â”€ ï¿½ ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ tools/compare_forecast_actual.py   # ì˜ˆì¸¡-ì‹¤ì¸¡ ë¹„êµ ë¶„ì„
â”‚   â”œâ”€â”€ tools/run_optuna.py                # Hyperparameter Tuning
â”‚   â”œâ”€â”€ tools/validate_baseline.py         # Baseline ì„±ëŠ¥ ê²€ì¦
â”‚   â””â”€â”€ tools/analyze_predictability.py    # ì˜ˆì¸¡ ê°€ëŠ¥ì„± ë¶„ì„
â”‚
â”œâ”€â”€ ğŸ“ ë°ì´í„° (Fresh Start í›„)
â”‚   â”œâ”€â”€ data/raw/claims_merged.csv         # ë³‘í•©ëœ ì›ë³¸ (15ë§Œ rows)
â”‚   â”œâ”€â”€ data/curated/claims_filtered.csv   # Lag í•„í„°ë§ ì™„ë£Œ
â”‚   â””â”€â”€ data/features/series_*/            # JSON ì‹œê³„ì—´ ë°ì´í„°
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ ì‚°ì¶œë¬¼
â”‚   â”œâ”€â”€ artifacts/models/base_2021_2023/   # PKL ëª¨ë¸ + training_results.csv + kpi_summary.json + manifest.json
â”‚   â”œâ”€â”€ artifacts/forecasts/               # forecast_YYYY_MM.csv + ews_scores.csv
â”‚   â”œâ”€â”€ artifacts/metrics/                 # lag_stats_from_raw.csv (ì˜êµ¬ ê¸°ì¤€)
â”‚   â”œâ”€â”€ artifacts/metadata/                # threshold.json (learned weights)
â”‚   â””â”€â”€ artifacts/incremental/YYYYMM/      # ì›”ë³„ ì²˜ë¦¬ ê²°ê³¼
â”‚
â””â”€â”€ ğŸ“– ë¬¸ì„œ
    â”œâ”€â”€ README.md                          # â­ ì—…ë°ì´íŠ¸ ì™„ë£Œ (EWS v2 ë°˜ì˜)
    â”œâ”€â”€ SYSTEM_SUMMARY.md                  # â­ ë³¸ ë¬¸ì„œ (EWS v2 ë°˜ì˜)
    â”œâ”€â”€ docs/EWS_V2_UPGRADE.md             # EWS v2 ìƒì„¸ ê°€ì´ë“œ
    â”œâ”€â”€ docs/INCREMENTAL_LEARNING.md       # ì¦ë¶„í•™ìŠµ ì„¤ëª…ì„œ
    â””â”€â”€ docs/RECONCILE.md                  # Reconcile 3ë‹¨ê³„ ìƒì„¸
```

---

## ğŸš€ Complete Workflow (Fresh Start â†’ Incremental)

### Phase 1: ë°ì´í„° ì¤€ë¹„ (Fresh Start)

```powershell
# Step 1: ì—°ë„ë³„ CSV ë³‘í•© (ì‚¬ìš©ìê°€ C:\cjclaim\dataì— ì—…ë¡œë“œ í›„)
python merge_yearly_data.py `
  --input-dir C:\cjclaim\data `
  --output data/raw/claims_merged.csv

# ì¶œë ¥: data/raw/claims_merged.csv (~15ë§Œ rows, ì—°ë„ë³„ ë¶„í¬ ìš”ì•½)

# Step 2: Lag í•„í„°ë§ (Î¼+Ïƒ ê¸°ì¤€)
python tools/lag_analyzer.py `
  --input data/raw/claims_merged.csv `
  --output data/curated/claims_filtered.csv

# ì¶œë ¥:
# - data/curated/claims_filtered.csv (Normal + Borderline, ~95%)
# - artifacts/metrics/lag_stats_from_raw.csv (ì˜êµ¬ ê¸°ì¤€ í†µê³„)

# Step 3: ì›”ë³„ ì „ì²˜ë¦¬ ë° JSON ìƒì„±
python preprocess_to_curated.py --input data/curated/claims_filtered.csv
python generate_series_json.py

# ì¶œë ¥: data/features/series_*/*.json (ì œí’ˆë²”ì£¼2/ê³µì¥/ì„¸ë¶€ë‚´ìš©ë³„)
```

### Phase 2: Base Training (2021-2023)

```powershell
# 3-Metric KPI + Manifest + Sparse Filter
python train_base_models.py `
  --auto-optimize `
  --max-workers 4 `
  --seed 42

# ì¶œë ¥:
# âœ… artifacts/models/base_2021_2023/*.pkl (ëª¨ë¸ íŒŒì¼)
# âœ… artifacts/models/base_2021_2023/training_results.csv
#    â†’ series_id, wmape, smape, bias, sparse_flag, sparse_reason, nonzero_ratio
# âœ… artifacts/models/base_2021_2023/kpi_summary.json
#    â†’ {"excellent": 30%, "good": 25%, "fair": 20%, "poor": 15%, "sparse": 10%}
# âœ… artifacts/models/base_2021_2023/manifest.json
#    â†’ run_id, git_commit, data_hash, seed, duration, args
```

### Phase 3: EWS v2 Weight Learning

```powershell
# Step 1: 6ê°œì›” ì˜ˆì¸¡ ìƒì„±
python generate_forecast_monthly.py `
  --year 2024 `
  --month 1 `
  --horizon 6

# ì¶œë ¥: artifacts/forecasts/forecast_2024_01.csv (6ê°œì›” ì˜ˆì¸¡ + 95% CI)

# Step 2: Weight Learning (Rolling 3-Fold CV)
python backtest_ews_weights.py `
  --delta 0.3 `
  --horizon 6 `
  --output artifacts/metadata/threshold.json

# ì¶œë ¥: threshold.json
# {
#   "weights": {"ratio": 0.22, "conf": 0.14, "season": 0.32, "ampl": 0.16, "inflect": 0.16},
#   "f1_score": 0.78,
#   "pr_auc": 0.82,
#   "cv_results": {...}
# }

# Step 3: EWS 5-Factor Scoring
python -m src.ews_scoring_v2 `
  --forecast artifacts/forecasts/forecast_2024_01.csv `
  --threshold artifacts/metadata/threshold.json `
  --output artifacts/forecasts/ews_scores_2024_01.csv

# ì¶œë ¥: ews_scores.csv
# rank | series_id | ews_score | level | f1_ratio | f2_conf | f3_season | f4_ampl | f5_inflect | candidate | rationale
# 1    | ê³µì¥A|X|Y  | 0.823    | HIGH  | 2.3      | 0.65    | 0.71      | 0.58    | 0.62       | TRUE      | ì¦ê°€ìœ¨2.3x; ê°•í•œê³„ì ˆì„±0.71
```

### Phase 4: ì›”ë³„ ì¦ë¶„í•™ìŠµ (2024-01 ë°ì´í„° ì…ë ¥ ì‹œ)

```powershell
# ë°©ë²• A: Streamlit UI (ê¶Œì¥)
streamlit run app_incremental.py
# â†’ Tab 1: ì›”ë³„ CSV ì—…ë¡œë“œ
# â†’ Tab 2: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (Lag filter â†’ Compare â†’ Retrain)
# â†’ Tab 3: Reconcile ë³´ì • (í•„ìš” ì‹œ)
# â†’ Tab 4: ì „ì²´ í†µê³„ í™•ì¸

# ë°©ë²• B: CLI ìë™í™”
python batch.py process --upload data/claims_202401.csv --month 2024-01
python batch.py reconcile --month-new 2024-01 --stage-new all  # KPI ë¯¸ë‹¬ ì‹œ
python batch.py retrain --month 2024-01 --workers 4
python batch.py forecast --month-new 2024-02
```

---

## ğŸ“Š EWS v2 í•µì‹¬ ëª¨ë“ˆ ìƒì„¸

### 1. src/ews_scoring_v2.py - 5-Factor Scoring Engine

**5ê°€ì§€ ìœ„í—˜ ì§€í‘œ:**

```python
F1: Growth Ratio = mean(forecast[t+1:t+h]) / mean(actuals[t-12:t-1])
    â†’ ì˜ˆì¸¡ í‰ê· ì´ ê³¼ê±° í‰ê·  ëŒ€ë¹„ ëª‡ ë°° ì¦ê°€? (2.3ë°° = ìœ„í—˜)

F2: Confidence = 0.5Â·Ï€_compression + 0.5Â·coverage_80
    â†’ ì˜ˆì¸¡ êµ¬ê°„ì´ ì¢ê³ (í™•ì‹ ) ì‹¤ì œ ì»¤ë²„ë¦¬ì§€ë„ ë†’ì€ê°€?

F3: Seasonality = 1 - Var(residual) / Var(y)  # STL decomposition
    â†’ ê³„ì ˆì„±ì´ ê°•í• ìˆ˜ë¡ íŒ¨í„´ ë³€í™” ê°ì§€ ì¤‘ìš” (claimsëŠ” ê³„ì ˆì„± ë†’ìŒ)

F4: Amplitude = (max_seasonal - min_seasonal) / mean(y)
    â†’ ê³„ì ˆ ì§„í­ì´ í¬ë©´ í”¼í¬ ì‹œê¸° ëŒ€ì‘ í•„ìš”

F5: Rising-Inflection = 0.5Â·norm(acceleration) + 0.5Â·changepoint_prob
    â†’ ì¶”ì„¸ê°€ ê°€ì†ë˜ê±°ë‚˜ ë³€ê³¡ì  ìˆìœ¼ë©´ ì¡°ê¸° ê²½ë³´
```

**Combined Score:**
```python
EWS = Î£(w_i Â· normalize(F_i))  where Î£w_i = 1.0
```

**Candidate Filtering:**
- Seasonality â‰¥ 0.4 (ê³„ì ˆì„± ì¶©ë¶„)
- Amplitude â‰¥ 0.3 (ì§„í­ ì˜ë¯¸ìˆìŒ)
- í•„í„°ë§ëœ ì‹œë¦¬ì¦ˆë§Œ EWS ì ìˆ˜ ê³„ì‚° (ë…¸ì´ì¦ˆ ì œê±°)

**ì¶œë ¥ ì˜ˆì‹œ:**
```csv
rank,series_id,ews_score,level,f1_ratio,f2_conf,f3_season,f4_ampl,f5_inflect,candidate,rationale
1,ê³µì¥A|ì œí’ˆX|ì´ìŠˆY,0.823,HIGH,2.3,0.65,0.71,0.58,0.62,TRUE,ì¦ê°€ìœ¨2.3x; ê°•í•œê³„ì ˆì„±0.71; í°ì§„í­0.58
2,ê³µì¥B|ì œí’ˆZ|ì´ìŠˆW,0.756,MEDIUM,1.8,0.58,0.82,0.45,0.51,TRUE,ê°•í•œê³„ì ˆì„±0.82; ì¦ê°€ìœ¨1.8x
```

### 2. src/metrics_v2.py - 3-Metric KPI

**WMAPE (Weighted MAPE):**
```python
WMAPE = (Î£|actual - forecast|) / (Î£actuals[actuals > 0]) Ã— 100
```
- ì¥ì : ì˜(0) ë‚˜ëˆ—ì…ˆ íšŒí”¼, í° ê°’ì— ë” í° ê°€ì¤‘ì¹˜
- ë“±ê¸‰: Excellent(<20%), Good(20-50%), Fair(50-100%), Poor(>100%)

**SMAPE (Symmetric MAPE):**
```python
SMAPE = mean(|error| / ((|actual| + |forecast|) / 2)) Ã— 100
```
- ì¥ì : Over/Under-prediction ê· ë“± ì²˜ë¦¬
- ëª©í‘œ: <30%

**Bias:**
```python
Bias = Î£(forecast - actual) / Î£actual
```
- ì¥ì : ë°©í–¥ì„± ì˜¤ì°¨ ê°ì§€ (ê³¼ëŒ€ì˜ˆì¸¡ vs ê³¼ì†Œì˜ˆì¸¡)
- ëª©í‘œ: Â±10% ì´ë‚´

**í†µí•© ì„±ëŠ¥ ë¦¬í¬íŠ¸:**
```python
kpi_summary.json:
{
  "wmape_distribution": {
    "excellent": 32.5,  # <20%
    "good": 28.3,       # 20-50%
    "fair": 22.1,       # 50-100%
    "poor": 17.1        # >100%
  },
  "smape_mean": 28.4,
  "bias_mean": 0.06,
  "sparse_filtered": 10.2  # avg<0.5 OR nonzero<30%
}
```

### 3. src/manifest.py - Reproducibility Tracking

**ì¶”ì  í•­ëª©:**
```json
{
  "run_id": "train_20250112_143022",
  "git_commit": "a3f7b2c",
  "git_branch": "main",
  "data_fingerprint": "md5:7d8a3f...",
  "seed": 42,
  "args": {
    "auto_optimize": true,
    "max_workers": 4,
    "sparse_threshold": 0.5
  },
  "duration_seconds": 3247.5,
  "timestamp": "2025-01-12T14:30:22",
  "python_version": "3.13.0",
  "packages": {"statsmodels": "0.14.0", ...}
}
```

**ì‚¬ìš©ë²•:**
```python
from src.manifest import ManifestBuilder

builder = ManifestBuilder(
    run_id="train_20250112",
    data_path="data/curated/claims_filtered.csv"
)
builder.record_args({"auto_optimize": True, "seed": 42})
builder.finalize(output_path="artifacts/models/base_2021_2023/manifest.json")
```

### 4. backtest_ews_weights.py - Weight Learning

**ì•Œê³ ë¦¬ì¦˜: Logistic Regression + Rolling 3-Fold CV**

```python
# 1. Label ìƒì„± (ë¯¸ë˜ 6ê°œì›” í•©ê³„ê°€ ê³¼ê±° í‰ê·  ëŒ€ë¹„ ì¦ê°€?)
y_label = 1 if future_sum â‰¥ (1+Î´)Â·HÂ·mean(recent_12m) else 0

# 2. Rolling Window (3-Fold)
Train: 2021-01 ~ 2022-12 â†’ Validate: 2023-01 ~ 2023-06
Train: 2021-07 ~ 2023-06 â†’ Validate: 2023-07 ~ 2023-12
Train: 2022-01 ~ 2023-12 â†’ Validate: 2024-01 ~ 2024-06

# 3. Logistic Regression (5 features: F1~F5)
clf = LogisticRegression(penalty='l2', C=1.0, max_iter=500)
clf.fit(X_train, y_label_train)

# 4. Weights = abs(coefficients) / sum(abs(coefficients))
weights = normalize(abs(clf.coef_[0]))

# 5. í‰ê°€: F1 Score, PR-AUC
```

**ì¶œë ¥ (threshold.json):**
```json
{
  "weights": {
    "ratio": 0.22,     # F1 Growth
    "conf": 0.14,      # F2 Confidence
    "season": 0.32,    # F3 Seasonality (highest!)
    "ampl": 0.16,      # F4 Amplitude
    "inflect": 0.16    # F5 Inflection
  },
  "f1_score": 0.78,
  "pr_auc": 0.82,
  "cv_results": [
    {"fold": 1, "f1": 0.76, "pr_auc": 0.80},
    {"fold": 2, "f1": 0.79, "pr_auc": 0.83},
    {"fold": 3, "f1": 0.79, "pr_auc": 0.83}
  ]
}
```

---

## ğŸ”„ ì›”ë³„ íŒŒì´í”„ë¼ì¸ ìƒì„¸

### process_monthly_data.py (5ë‹¨ê³„)

```
Step 1: Lag í•„í„°ë§
  â”œâ”€ lag_analyzer.py í˜¸ì¶œ (Î¼+Ïƒ ê¸°ì¤€)
  â”œâ”€ lag_stats_from_raw.csv ê¸°ì¤€ ì ìš© (ì˜êµ¬ ë³´ì¡´ í†µê³„)
  â””â”€ Normal + Borderlineë§Œ ì„ íƒ (weight: 1.0, 0.5)

Step 2: ì›”ë³„ ì§‘ê³„ ë° JSON ì—…ë°ì´íŠ¸
  â”œâ”€ ë°œìƒì¼ì â†’ ì›” ë‹¨ìœ„ ê³„ì‚°
  â”œâ”€ ì‹œë¦¬ì¦ˆë³„ ì›”ë³„ ì§‘ê³„
  â””â”€ ê¸°ì¡´ JSON íŒŒì¼ ì—…ë°ì´íŠ¸ (ëˆ„ì  í•™ìŠµ ë°ì´í„°)

Step 3: ì˜ˆì¸¡-ì‹¤ì¸¡ ë¹„êµ
  â”œâ”€ ê¸°ì¡´ ì˜ˆì¸¡ íŒŒì¼ ë¡œë“œ (forecast_YYYY_MM.csv)
  â”œâ”€ ì‹¤ì¸¡ê³¼ ë¹„êµ
  â””â”€ ì˜¤ì°¨ ê³„ì‚° (WMAPE, SMAPE, Bias)

Step 4: ì¬í•™ìŠµ ì¤€ë¹„
  â”œâ”€ ëª¨ë¸ íŒŒì¼ í™•ì¸
  â”œâ”€ JSON ë°ì´í„° ë¡œë“œ
  â””â”€ ì¬í•™ìŠµ ìƒíƒœ ì €ì¥ (retrain_status_YYYYMM.json)

Step 5: ë¡œê·¸ ê¸°ë¡
  â”œâ”€ predict_vs_actual_YYYYMM.csv
  â”œâ”€ retrain_status_YYYYMM.json
  â””â”€ summary_YYYYMM.json
```

### reconcile_pipeline.py (3ë‹¨ê³„)

```
ì´ˆê¸° KPI ì²´í¬
  â”œâ”€ WMAPE < 20%?
  â””â”€ |Bias| < 0.05?
      â†“
  í†µê³¼? â†’ ì™„ë£Œ
      â†“
  ë¯¸ë‹¬ â†’ Stage 1: Bias Map (ì´ˆ ë‹¨ìœ„)
      â”œâ”€ ì›”ë³„ í‰ê·  ì˜¤ì°¨ ê³„ì‚°
      â”œâ”€ ì˜ˆì¸¡ê°’ ë³´ì • (y_pred + avg_bias)
      â””â”€ KPI ì¬ì²´í¬ â†’ í†µê³¼? â†’ ì™„ë£Œ
          â†“
      ë¯¸ë‹¬ â†’ Stage 2: Seasonal Recalibration (ë¶„ ë‹¨ìœ„)
          â”œâ”€ ìµœê·¼ 2ë…„ ê³„ì ˆì„± ì¬ì¶”ì • (STL)
          â”œâ”€ Seasonal adjustment ì ìš© (ë³´ìˆ˜ì  50%)
          â””â”€ KPI ì¬ì²´í¬ â†’ í†µê³¼? â†’ ì™„ë£Œ
              â†“
          ë¯¸ë‹¬ â†’ Stage 3: Optuna Tuning (ì‹œê°„ ë‹¨ìœ„)
              â”œâ”€ ìƒìœ„ 10% WMAPE ì‹œë¦¬ì¦ˆ ì„ ì •
              â”œâ”€ (p,d,q)(P,D,Q,s) ìµœì í™” (30ì´ˆ timeout)
              â””â”€ ìµœì¢… KPI í™•ì¸
```

---

## ğŸ“Š ì£¼ìš” ì‚°ì¶œë¬¼

### 1. í•™ìŠµ ëª¨ë¸ (Fresh Start í›„ ì—…ë°ì´íŠ¸ ì˜ˆì •)

- **ìœ„ì¹˜:** `artifacts/models/base_2021_2023/`
- **íŒŒì¼:**
  - `*.pkl` - SARIMA ëª¨ë¸ íŒŒì¼
  - `training_results.csv` - series_id, wmape, smape, bias, sparse_flag, sparse_reason, nonzero_ratio
  - `kpi_summary.json` - {"excellent": %, "good": %, "fair": %, "poor": %, "sparse": %}
  - `manifest.json` - run_id, git_commit, data_hash, seed, duration, args

### 2. Lag í†µê³„ (ì˜êµ¬ ë³´ì¡´)

- **íŒŒì¼:** `artifacts/metrics/lag_stats_from_raw.csv`
- **ë‚´ìš©:** 392ê°œ ì œí’ˆë²”ì£¼2ë³„ Î¼, Ïƒ, p90, p95
- **ìš©ë„:** ëª¨ë“  ì›”ë³„ ë°ì´í„° í•„í„°ë§ì˜ ì˜êµ¬ ê¸°ì¤€

### 3. EWS Weight Learning ê²°ê³¼

- **íŒŒì¼:** `artifacts/metadata/threshold.json`
- **ë‚´ìš©:**
  - `weights`: {ratio: 0.22, conf: 0.14, season: 0.32, ampl: 0.16, inflect: 0.16}
  - `f1_score`: 0.78 (ëª©í‘œ â‰¥0.75)
  - `pr_auc`: 0.82
  - `cv_results`: 3-Fold êµì°¨ê²€ì¦ ìƒì„¸

### 4. ì›”ë³„ ì²˜ë¦¬ ê²°ê³¼

```
artifacts/incremental/YYYYMM/
â”œâ”€â”€ candidates_YYYYMM.csv                  # í•„í„°ë§ëœ ë°ì´í„° (Normal+Borderline)
â”œâ”€â”€ predict_vs_actual_YYYYMM.csv           # ì˜ˆì¸¡-ì‹¤ì¸¡ ë¹„êµ (WMAPE/SMAPE/Bias)
â”œâ”€â”€ retrain_status_YYYYMM.json             # ì¬í•™ìŠµ ëŒ€ìƒ ì‹œë¦¬ì¦ˆ ëª©ë¡
â””â”€â”€ summary_YYYYMM.json                    # ì²˜ë¦¬ ìš”ì•½ (Total/Normal/Borderline/Extreme)
```

### 5. EWS Scores

```
artifacts/forecasts/ews_scores_YYYY_MM.csv
â”œâ”€â”€ rank            # ìœ„í—˜ë„ ìˆœìœ„ (1 = ìµœê³  ìœ„í—˜)
â”œâ”€â”€ series_id       # ê³µì¥|ì œí’ˆë²”ì£¼2|ì„¸ë¶€ë‚´ìš©
â”œâ”€â”€ ews_score       # 0.0~1.0 (weighted combination of 5 factors)
â”œâ”€â”€ level           # HIGH/MEDIUM/LOW
â”œâ”€â”€ f1_ratio        # Growth Ratio (ì˜ˆì¸¡/ê³¼ê±° í‰ê· )
â”œâ”€â”€ f2_conf         # Confidence (êµ¬ê°„ ì••ì¶• + ì»¤ë²„ë¦¬ì§€)
â”œâ”€â”€ f3_season       # Seasonality (1 - Var(resid)/Var(y))
â”œâ”€â”€ f4_ampl         # Amplitude (ê³„ì ˆ ì§„í­)
â”œâ”€â”€ f5_inflect      # Rising-Inflection (ê°€ì†ë„ + ë³€í™”ì )
â”œâ”€â”€ candidate       # TRUE/FALSE (Sâ‰¥0.4, Aâ‰¥0.3)
â””â”€â”€ rationale       # í•œê¸€ ì„¤ëª… (ì¦ê°€ìœ¨2.3x; ê°•í•œê³„ì ˆì„±0.71)
```

### 6. Reconcile ë³´ì • ê²°ê³¼

```
artifacts/reconcile/YYYYMM/
â”œâ”€â”€ reconcile_summary_YYYYMM.json          # ì „ì²´ ìš”ì•½ (stageë³„ ê°œì„ ìœ¨)
â”œâ”€â”€ predict_vs_actual_reconciled_YYYYMM.csv # ë³´ì •ëœ ë¹„êµ ë°ì´í„°
â”œâ”€â”€ improvement_report_YYYYMM.txt          # ê°œì„  ë¦¬í¬íŠ¸ (Before/After)
â””â”€â”€ bias_map.csv                           # Bias Map (ì‹œë¦¬ì¦ˆë³„ í‰ê·  ì˜¤ì°¨)
```

---

## ğŸ¯ KPI ëª©í‘œ (EWS v2)

### ëª¨ë¸ ì„±ëŠ¥

- **WMAPE Excellent**: >30% of series (<20% error)
- **SMAPE Mean**: <30%
- **Bias Mean**: Â±10% ì´ë‚´

### EWS ì„±ëŠ¥

- **F1 Score**: â‰¥0.75 (ìœ„í—˜ ì‹œë¦¬ì¦ˆ ì •í™• ì˜ˆì¸¡)
- **PR-AUC**: â‰¥0.80 (Precision-Recall ê³¡ì„  í•˜ ë©´ì )

### Sparse Filter

- **ì œì™¸ ë¹„ìœ¨**: ~35% (avg<0.5 OR nonzero<30%)
- **ëª©ì **: ë…¸ì´ì¦ˆ ì‹œë¦¬ì¦ˆ ì œì™¸ë¡œ í’ˆì§ˆ í–¥ìƒ

---

## ğŸ’¡ í•µì‹¬ íŠ¹ì§• (EWS v2)

### 1. Lag ê¸°ë°˜ í’ˆì§ˆ ê´€ë¦¬ (Î¼+Ïƒ ë°©ì‹)

**ê°œë…:** ì ‘ìˆ˜ì¼ì-ì œì¡°ì¼ì ê°„ê²©ì„ í’ˆì§ˆ ì§€í‘œë¡œ í™œìš©

```
Normal:     lag â‰¤ Î¼ + 1Ïƒ      (weight = 1.0, í•™ìŠµ ìš°ì„ )
Borderline: Î¼+1Ïƒ < lag â‰¤ Î¼+2Ïƒ (weight = 0.5, ë³´ì¡° í•™ìŠµ)
Extreme:    lag > Î¼ + 2Ïƒ      (ì œì™¸, ë…¸ì´ì¦ˆë¡œ ê°„ì£¼)
```

**íš¨ê³¼:**
- ~95% ë°ì´í„° ë³´ì¡´ (Normal+Borderline)
- ë…¸ì´ì¦ˆ ì œê±°ë¡œ ëª¨ë¸ í’ˆì§ˆ í–¥ìƒ
- ì˜êµ¬ ê¸°ì¤€ (lag_stats_from_raw.csv) ê¸°ë°˜ ì¼ê´€ì„± ë³´ì¥

### 2. 3-Metric KPI (ê¸°ì¡´ ë‹¨ì¼ MAPE ëŒ€ì²´)

**ì¥ì :**
- **WMAPE**: í° ê°’ì— ê°€ì¤‘ì¹˜ â†’ ì¤‘ìš” ì‹œë¦¬ì¦ˆ ì„±ëŠ¥ ìš°ì„ 
- **SMAPE**: Over/Under ê· ë“± ì²˜ë¦¬ â†’ í¸í–¥ ê°ì†Œ
- **Bias**: ë°©í–¥ì„± ì˜¤ì°¨ ê°ì§€ â†’ ê³¼ëŒ€/ê³¼ì†Œì˜ˆì¸¡ êµ¬ë¶„

**í†µí•© í‰ê°€:**
```python
Excellent: WMAPE<20% AND |Bias|<0.05
Good:      WMAPE<50% AND |Bias|<0.10
Fair:      WMAPE<100%
Poor:      WMAPEâ‰¥100% OR |Bias|â‰¥0.20
```

### 3. EWS 5-Factor Scoring

**ì² í•™:** ë‹¨ì¼ ì§€í‘œ ëŒ€ì‹  ë‹¤ì°¨ì› ìœ„í—˜ í‰ê°€

```
Growth (F1):      ì¦ê°€ì„¸ ê°ì§€
Confidence (F2):  ì˜ˆì¸¡ ì‹ ë¢°ë„
Seasonality (F3): íŒ¨í„´ ê°•ë„ (claimsëŠ” ê³„ì ˆì„± ë†’ìŒ)
Amplitude (F4):   í”¼í¬ ëŒ€ë¹„ í•„ìš”
Inflection (F5):  ì¶”ì„¸ ë³€ê³¡ì 
```

**ìë™ í•™ìŠµ:**
- Logistic Regressionìœ¼ë¡œ weights ìµœì í™”
- Rolling CVë¡œ ê³¼ì í•© ë°©ì§€
- Domain prior (seasonality ìš°ì„ ) ë°˜ì˜

### 4. ì¦ë¶„í•™ìŠµ (Incremental Learning)

**ì¥ì :**
- ìµœì‹  íŠ¸ë Œë“œ ë°˜ì˜ (ì›”ë³„ ì—…ë°ì´íŠ¸)
- ê³„ì‚° ë¹„ìš© ì ˆê° (Warm Start via start_params)
- ì§€ì†ì  ì„±ëŠ¥ ê°œì„  (ìƒˆ ë°ì´í„°ë¡œ ì¬í•™ìŠµ)

**ë°©ë²•:**
- JSON ê¸°ë°˜ ë°ì´í„° ëˆ„ì  (íŒŒì¼ I/O ìµœì†Œí™”)
- Sample Weights ì ìš© (Normal=1.0, Borderline=0.5)

### 5. Manifest System (Reproducibility)

**ì¶”ì  í•­ëª©:**
- Git commit hash (ì½”ë“œ ë²„ì „)
- Data fingerprint (MD5 hash)
- Random seed (ì¬í˜„ì„± ë³´ì¥)
- ì‹¤í–‰ ì¸ì (auto_optimize, workers ë“±)

**íš¨ê³¼:**
- ì‹¤í—˜ ì¬í˜„ ê°€ëŠ¥
- ì„±ëŠ¥ ë¹„êµ ê¸°ì¤€ ëª…í™•
- ë””ë²„ê¹… ì‹œê°„ ë‹¨ì¶•

---

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

- **ì–¸ì–´:** Python 3.13
- **ëª¨ë¸:** SARIMAX (statsmodels)
- **ë°ì´í„°:** Pandas, NumPy, Parquet
- **ë³‘ë ¬:** ProcessPoolExecutor
- **UI:** Streamlit
- **ìµœì í™”:** Optuna
- **EWS:** scikit-learn (Logistic Regression)
- **ë³€í™”ì :** ruptures (PELT)
- **ê³„ì ˆì„±:** statsmodels (STL decomposition)

---

## ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ (Fresh Start í›„ ì—…ë°ì´íŠ¸ ì˜ˆì •)

### Base Training ê²°ê³¼ (OLD - êµ¬ë²„ì „ í†µê³„, ì°¸ê³ ìš©)

| ì§€í‘œ | ê°’ |
|------|-----|
| í•™ìŠµ ì‹œë¦¬ì¦ˆ | 2,608ê°œ |
| ì„±ê³µ ëª¨ë¸ | 2,208ê°œ (84.7%) |
| ìŠ¤í‚µ | 136ê°œ (zero_variance) |
| ì‹¤íŒ¨ | 0ê°œ |
| í‰ê·  AIC | -738.25 |
| í•™ìŠµ ê¸°ê°„ | 2021-2023 (159ì£¼) â†’ ì›”ë³„ ì „í™˜ ì™„ë£Œ |

### Fresh Start ì˜ˆìƒ (EWS v2)

| ì§€í‘œ | ëª©í‘œ | ê·¼ê±° |
|------|------|------|
| í•™ìŠµ ì‹œë¦¬ì¦ˆ | ~ìˆ˜ì²œ ê°œ | Sparse filter 35% ì œì™¸ |
| WMAPE Excellent | >30% | Enhanced filter + 3-Metric |
| F1 Score (EWS) | â‰¥0.75 | Weight learning + 5-Factor |
| SMAPE Mean | <30% | Symmetric í‰ê°€ |
| Bias Mean | Â±10% | ë°©í–¥ì„± ì˜¤ì°¨ ì œì–´ |

---

## ğŸš§ í–¥í›„ ê°œì„ 

### train_incremental_models.py ì—…ë°ì´íŠ¸

- [ ] 3-Metric KPI ì ìš© (WMAPE/SMAPE/Bias)
- [ ] Manifest í†µí•© (ì¬í˜„ì„± ë³´ì¥)
- [ ] Enhanced Sparse Filter (avg<0.5 OR nonzero<30%)

### Reconcile Stage 2/3 ê°•í™”

- [x] Seasonal Recalibration êµ¬í˜„ ì™„ë£Œ (STL)
- [x] Optuna Tuning êµ¬í˜„ ì™„ë£Œ (ìƒìœ„ 10%)
- [ ] 3-Metric ê¸°ë°˜ KPI ê²Œì´íŠ¸ ì—…ë°ì´íŠ¸

### ìë™í™”

- [ ] ìŠ¤ì¼€ì¤„ëŸ¬ ì—°ë™ (ì›” 1íšŒ ìë™ ì‹¤í–‰)
- [ ] ì´ë©”ì¼ ì•Œë¦¼ (KPI ë¯¸ë‹¬ ë˜ëŠ” HIGH level EWS ë°œìƒ ì‹œ)
- [ ] ëŒ€ì‹œë³´ë“œ í†µí•© (EWS ì ìˆ˜ ì‹œê°í™”)

### Lag Filtering ë°©ë²• ì¬ê²€í† 

- [ ] tools/lag_analyzer.py (Î¼+Ïƒ ë°©ì‹, í˜„ì¬ ì‚¬ìš©)
- [ ] filter_normal_lag.py (IQR ë°©ì‹, ìƒì„±í–ˆìœ¼ë‚˜ ë¯¸ì‚¬ìš©)
- [ ] ë‘ ë°©ë²• ë¹„êµ ì‹¤í—˜ ë˜ëŠ” í†µí•© ê²°ì •

---

## ğŸ“ ë¬¸ì˜

í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì˜ëŠ” ì´ìŠˆ íŠ¸ë˜ì»¤ë¥¼ ì´ìš©í•´ì£¼ì„¸ìš”.

---

**Updated:** 2025-01-13 (EWS v2 ë°˜ì˜)  
**Version:** 2.0.0  
**Status:** Fresh Start Ready - ë°ì´í„° ì—…ë¡œë“œ ëŒ€ê¸° ì¤‘ ğŸš€

# Reconcile ë³´ì • (KPI ë¯¸ë‹¬ ì‹œ)
python batch.py reconcile --month-new 2024-01 --stage-new all
```

### 3ï¸âƒ£ ì§ì ‘ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

```bash
# ì›”ë³„ íŒŒì´í”„ë¼ì¸
python process_monthly_data.py --input data/claims_202401.csv --year 2024 --month 1

# Reconcile
python reconcile_pipeline.py --year 2024 --month 1 --stage all
```

---

## ğŸ”„ ì›”ë³„ íŒŒì´í”„ë¼ì¸ ìƒì„¸

### process_monthly_data.py (5ë‹¨ê³„)

```
Step 1: Lag í•„í„°ë§
  â”œâ”€ lag_analyzer.py í˜¸ì¶œ
  â”œâ”€ lag_stats_from_raw.csv ê¸°ì¤€ ì ìš©
  â””â”€ Normal + Borderlineë§Œ ì„ íƒ

Step 2: ì£¼ê°„ ì§‘ê³„ ë° JSON ì—…ë°ì´íŠ¸
  â”œâ”€ ë°œìƒì¼ì â†’ ì£¼ì°¨ ê³„ì‚°
  â”œâ”€ ì‹œë¦¬ì¦ˆë³„ ì£¼ê°„ ì§‘ê³„
  â””â”€ ê¸°ì¡´ JSON íŒŒì¼ ì—…ë°ì´íŠ¸

Step 3: ì˜ˆì¸¡-ì‹¤ì¸¡ ë¹„êµ
  â”œâ”€ ê¸°ì¡´ ì˜ˆì¸¡ íŒŒì¼ ë¡œë“œ
  â”œâ”€ ì‹¤ì¸¡ê³¼ ë¹„êµ
  â””â”€ ì˜¤ì°¨ ê³„ì‚° (MAPE, Bias, MAE)

Step 4: ì¬í•™ìŠµ ì¤€ë¹„
  â”œâ”€ ëª¨ë¸ íŒŒì¼ í™•ì¸
  â”œâ”€ JSON ë°ì´í„° ë¡œë“œ
  â””â”€ ì¬í•™ìŠµ ìƒíƒœ ì €ì¥

Step 5: ë¡œê·¸ ê¸°ë¡
  â”œâ”€ predict_vs_actual_YYYYMM.csv
  â”œâ”€ retrain_status_YYYYMM.json
  â””â”€ summary_YYYYMM.json
```

### reconcile_pipeline.py (3ë‹¨ê³„)

```
ì´ˆê¸° KPI ì²´í¬
  â”œâ”€ MAPE < 20%?
  â””â”€ |Bias| < 0.05?
      â†“
  í†µê³¼? â†’ ì™„ë£Œ
      â†“
  ë¯¸ë‹¬ â†’ Stage 1: Bias Map
      â”œâ”€ ì‹œë¦¬ì¦ˆë³„ í‰ê·  ì˜¤ì°¨ ê³„ì‚°
      â”œâ”€ ì˜ˆì¸¡ê°’ ë³´ì • (y_pred + avg_bias)
      â””â”€ KPI ì¬ì²´í¬ â†’ í†µê³¼? â†’ ì™„ë£Œ
          â†“
      ë¯¸ë‹¬ â†’ Stage 2: Seasonal Recalibration (êµ¬í˜„ ì˜ˆì •)
          â”œâ”€ ìµœê·¼ 2ë…„ ê³„ì ˆì„± ì¬ì¶”ì •
          â””â”€ KPI ì¬ì²´í¬ â†’ í†µê³¼? â†’ ì™„ë£Œ
              â†“
          ë¯¸ë‹¬ â†’ Stage 3: Optuna Tuning (êµ¬í˜„ ì˜ˆì •)
              â”œâ”€ ìƒìœ„ 10% ì‹œë¦¬ì¦ˆ ìµœì í™”
              â””â”€ ìµœì¢… KPI í™•ì¸
```

---

## ğŸ“Š ì£¼ìš” ì‚°ì¶œë¬¼

### 1. í•™ìŠµ ëª¨ë¸

- **ìœ„ì¹˜:** `artifacts/models/base_2021_2023/`
- **ê°œìˆ˜:** 2,208ê°œ PKL íŒŒì¼
- **ì„±ê³µë¥ :** 84.7%
- **í‰ê·  AIC:** -738.25

### 2. Lag í†µê³„ (ì˜êµ¬ ë³´ì¡´)

- **íŒŒì¼:** `artifacts/metrics/lag_stats_from_raw.csv`
- **ë‚´ìš©:** 392ê°œ ì œí’ˆë²”ì£¼2ë³„ Î¼, Ïƒ, p90, p95
- **ìš©ë„:** ëª¨ë“  ì›”ë³„ ë°ì´í„° í•„í„°ë§ì˜ ê¸°ì¤€

### 3. ì›”ë³„ ì²˜ë¦¬ ê²°ê³¼

```
artifacts/incremental/YYYYMM/
â”œâ”€â”€ candidates_YYYYMM.csv                  # í•„í„°ë§ëœ ë°ì´í„°
â”œâ”€â”€ predict_vs_actual_YYYYMM.csv           # ì˜ˆì¸¡-ì‹¤ì¸¡ ë¹„êµ
â”œâ”€â”€ retrain_status_YYYYMM.json             # ì¬í•™ìŠµ ìƒíƒœ
â””â”€â”€ summary_YYYYMM.json                    # ì²˜ë¦¬ ìš”ì•½
```

### 4. Reconcile ë³´ì • ê²°ê³¼

```
artifacts/reconcile/YYYYMM/
â”œâ”€â”€ reconcile_summary_YYYYMM.json          # ì „ì²´ ìš”ì•½
â”œâ”€â”€ predict_vs_actual_reconciled_YYYYMM.csv # ë³´ì •ëœ ë¹„êµ ë°ì´í„°
â”œâ”€â”€ improvement_report_YYYYMM.txt          # ê°œì„  ë¦¬í¬íŠ¸
â””â”€â”€ bias_map.csv                           # Bias Map
```

---

## ğŸ¯ KPI ëª©í‘œ

- **MAPE < 20%** (Mean Absolute Percentage Error)
- **|Bias| < 0.05** (ì ˆëŒ€ í¸í–¥)

### ë‹¬ì„± ì „ëµ

1. **Base Training:** 2021-2023 ê³ í’ˆì§ˆ ë°ì´í„°ë¡œ ê²¬ê³ í•œ ê¸°ë°˜ êµ¬ì¶•
2. **Lag í•„í„°ë§:** Normal-Lagë§Œ í•™ìŠµí•˜ì—¬ ë…¸ì´ì¦ˆ ì œê±°
3. **ì›”ë³„ ì¦ë¶„:** ìµœì‹  íŒ¨í„´ ë°˜ì˜
4. **Reconcile ë³´ì •:** KPI ë¯¸ë‹¬ ì‹œ ìë™ ë³´ì •

---

## ğŸ’¡ í•µì‹¬ íŠ¹ì§•

### 1. Lag ê¸°ë°˜ í’ˆì§ˆ ê´€ë¦¬

**ê°œë…:** ì ‘ìˆ˜ì¼ì-ì œì¡°ì¼ì ê°„ê²©ì„ í’ˆì§ˆ ì§€í‘œë¡œ í™œìš©

```
Normal:     lag â‰¤ Î¼ + 1Ïƒ  (weight = 1.0)
Borderline: Î¼+1Ïƒ < lag â‰¤ Î¼+2Ïƒ  (weight = 0.5)
Extreme:    lag > Î¼ + 2Ïƒ  (ì œì™¸)
```

**íš¨ê³¼:**
- 95.3% ë°ì´í„° ë³´ì¡´ (16,256/17,052ê±´)
- ë…¸ì´ì¦ˆ ì œê±°ë¡œ ëª¨ë¸ í’ˆì§ˆ í–¥ìƒ

### 2. ì¦ë¶„í•™ìŠµ (Incremental Learning)

**ì¥ì :**
- ìµœì‹  íŠ¸ë Œë“œ ë°˜ì˜
- ê³„ì‚° ë¹„ìš© ì ˆê°
- ì§€ì†ì  ì„±ëŠ¥ ê°œì„ 

**ë°©ë²•:**
- JSON ê¸°ë°˜ ë°ì´í„° ëˆ„ì 
- ì¬í•™ìŠµ ì‹œ start_params í™œìš© (warm start)

### 3. 3ë‹¨ê³„ Reconcile

**ì² í•™:** ë‹¨ìˆœí•œ ê²ƒë¶€í„° ë³µì¡í•œ ê²ƒ ìˆœì„œë¡œ

```
Stage 1 (ì´ˆ ë‹¨ìœ„) â†’ Stage 2 (ë¶„ ë‹¨ìœ„) â†’ Stage 3 (ì‹œê°„ ë‹¨ìœ„)
   Bias Map      â†’    Seasonal     â†’     Optuna
```

**íš¨ìœ¨ì„±:**
- ëŒ€ë¶€ë¶„ Stage 1ì—ì„œ í•´ê²° (17.8% ê°œì„ )
- í•„ìš”í•œ ê²½ìš°ë§Œ ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰

---

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

- **ì–¸ì–´:** Python 3.13
- **ëª¨ë¸:** SARIMAX (statsmodels)
- **ë°ì´í„°:** Pandas, NumPy, Parquet
- **ë³‘ë ¬:** ProcessPoolExecutor
- **UI:** Streamlit
- **ìµœì í™”:** Optuna (ì˜ˆì •)

---

## ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ

### Base Training ê²°ê³¼

| ì§€í‘œ | ê°’ |
|------|-----|
| í•™ìŠµ ì‹œë¦¬ì¦ˆ | 2,608ê°œ |
| ì„±ê³µ ëª¨ë¸ | 2,208ê°œ (84.7%) |
| ìŠ¤í‚µ | 136ê°œ (zero_variance) |
| ì‹¤íŒ¨ | 0ê°œ |
| í‰ê·  AIC | -738.25 |
| í•™ìŠµ ê¸°ê°„ | 2021-2023 (159ì£¼) |

### Reconcile Stage 1 ì˜ˆì‹œ

| ì§€í‘œ | Before | After | ê°œì„  |
|------|--------|-------|------|
| MAE | 12.45 | 10.23 | 17.8% â†“ |
| MAPE | 25.34% | 18.76% | 6.58%p â†“ |
| \|Bias\| | 0.0821 | 0.0342 | 0.0479 â†“ |

---

## ğŸš§ í–¥í›„ ê°œì„ 

### Stage 2: Seasonal Recalibration
- [ ] STL decomposition êµ¬í˜„
- [ ] ìµœê·¼ 2ë…„ seasonal ì¶”ì¶œ
- [ ] Seasonal adjustment ì ìš©

### Stage 3: Optuna Tuning
- [ ] íƒìƒ‰ ê³µê°„ ì •ì˜
- [ ] ë³‘ë ¬ ìµœì í™”
- [ ] Best params ìë™ ì €ì¥

### ìë™í™”
- [ ] ìŠ¤ì¼€ì¤„ëŸ¬ ì—°ë™ (ì›” 1íšŒ ìë™ ì‹¤í–‰)
- [ ] ì´ë©”ì¼ ì•Œë¦¼ (KPI ë¯¸ë‹¬ ì‹œ)
- [ ] ëŒ€ì‹œë³´ë“œ í†µí•©

---

## ğŸ“ ë¬¸ì˜

í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì˜ëŠ” ì´ìŠˆ íŠ¸ë˜ì»¤ë¥¼ ì´ìš©í•´ì£¼ì„¸ìš”.

---

**Generated:** 2025-11-04  
**Version:** 1.0.0  
**Status:** Production Ready âœ…
